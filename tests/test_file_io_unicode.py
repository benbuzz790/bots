"""Comprehensive tests for file I/O operations with unicode content.

This module tests file operations to ensure proper unicode handling and prevent
mojibake issues when reading/writing files with unicode content and filenames.

Tests cover:
- Reading/writing files with unicode content
- Unicode filenames
- Different encoding parameters
- Malformed unicode handling
- Large files with unicode
"""

from encoding_fixtures import UNICODE_TEST_STRINGS, assert_no_mojibake


class TestFileReadWriteUnicode:
    """Test reading and writing files with unicode content."""

    def test_write_and_read_unicode_content(self, tmp_path):
        """Test writing and reading file with unicode content."""
        test_file = tmp_path / "unicode_test.txt"
        content = UNICODE_TEST_STRINGS["mixed"]

        # Write unicode content
        test_file.write_text(content, encoding="utf-8")

        # Read it back
        read_content = test_file.read_text(encoding="utf-8")

        # Verify no mojibake
        assert_no_mojibake(read_content, ["âœ…", "ä¸­æ–‡", "ğŸ‰", "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©", "âŒ"])
        assert read_content == content

    def test_write_emoji_content(self, tmp_path):
        """Test writing and reading emoji characters."""
        test_file = tmp_path / "emoji_test.txt"
        emojis = [
            UNICODE_TEST_STRINGS["emoji_checkmark"],
            UNICODE_TEST_STRINGS["emoji_cross"],
            UNICODE_TEST_STRINGS["emoji_warning"],
            UNICODE_TEST_STRINGS["emoji_party"],
            UNICODE_TEST_STRINGS["emoji_memo"],
            UNICODE_TEST_STRINGS["emoji_wrench"],
        ]
        content = " ".join(emojis)

        # Write with explicit UTF-8
        with open(test_file, "w", encoding="utf-8") as f:
            f.write(content)

        # Read back
        with open(test_file, "r", encoding="utf-8") as f:
            read_content = f.read()

        # Verify all emojis present
        for emoji in emojis:
            assert emoji in read_content, f"Emoji {emoji} not found in {read_content!r}"

        assert_no_mojibake(read_content, emojis)

    def test_write_chinese_content(self, tmp_path):
        """Test writing and reading Chinese characters."""
        test_file = tmp_path / "chinese_test.txt"
        content = UNICODE_TEST_STRINGS["chinese"]

        test_file.write_text(content, encoding="utf-8")
        read_content = test_file.read_text(encoding="utf-8")

        assert "ä¸­æ–‡" in read_content
        assert read_content == content

    def test_write_arabic_content(self, tmp_path):
        """Test writing and reading Arabic characters."""
        test_file = tmp_path / "arabic_test.txt"
        content = UNICODE_TEST_STRINGS["arabic"]

        test_file.write_text(content, encoding="utf-8")
        read_content = test_file.read_text(encoding="utf-8")

        assert "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©" in read_content
        assert read_content == content

    def test_append_unicode_content(self, tmp_path):
        """Test appending unicode content to existing file."""
        test_file = tmp_path / "append_test.txt"

        # Write initial content
        test_file.write_text("Initial âœ…\n", encoding="utf-8")

        # Append more content
        with open(test_file, "a", encoding="utf-8") as f:
            f.write("Appended ğŸ‰\n")

        # Read all
        content = test_file.read_text(encoding="utf-8")

        assert "âœ…" in content
        assert "ğŸ‰" in content
        assert_no_mojibake(content, ["âœ…", "ğŸ‰"])


class TestUnicodeFilenames:
    """Test file operations with unicode filenames."""

    def test_create_file_with_emoji_filename(self, tmp_path):
        """Test creating file with emoji in filename."""
        filename = "test_âœ…_file.txt"
        test_file = tmp_path / filename

        # Write content
        test_file.write_text("Test content", encoding="utf-8")

        # Verify file exists
        assert test_file.exists()
        assert test_file.name == filename

        # Read content back
        content = test_file.read_text(encoding="utf-8")
        assert content == "Test content"

    def test_create_file_with_chinese_filename(self, tmp_path):
        """Test creating file with Chinese characters in filename."""
        filename = "æµ‹è¯•æ–‡ä»¶_ä¸­æ–‡.txt"
        test_file = tmp_path / filename

        test_file.write_text("Chinese filename test", encoding="utf-8")

        assert test_file.exists()
        assert "ä¸­æ–‡" in test_file.name

        # List directory and verify filename
        files = list(tmp_path.glob("*.txt"))
        assert len(files) == 1
        assert "ä¸­æ–‡" in files[0].name

    def test_create_file_with_arabic_filename(self, tmp_path):
        """Test creating file with Arabic characters in filename."""
        filename = "Ù…Ù„Ù_Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©.txt"
        test_file = tmp_path / filename

        test_file.write_text("Arabic filename test", encoding="utf-8")

        assert test_file.exists()
        assert "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©" in test_file.name

    def test_create_file_with_mixed_unicode_filename(self, tmp_path):
        """Test creating file with mixed unicode in filename."""
        filename = "test_âœ…_ä¸­æ–‡_ğŸ‰_Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©.txt"
        test_file = tmp_path / filename

        test_file.write_text("Mixed unicode filename", encoding="utf-8")

        assert test_file.exists()
        assert "âœ…" in test_file.name
        assert "ä¸­æ–‡" in test_file.name
        assert "ğŸ‰" in test_file.name

    def test_list_files_with_unicode_names(self, tmp_path):
        """Test listing directory with unicode filenames."""
        # Create multiple files with unicode names
        files = ["test_âœ….txt", "æµ‹è¯•_ä¸­æ–‡.txt", "emoji_ğŸ‰.txt"]

        for filename in files:
            (tmp_path / filename).write_text("content", encoding="utf-8")

        # List all files
        found_files = [f.name for f in tmp_path.glob("*.txt")]

        assert len(found_files) == 3
        for filename in files:
            assert filename in found_files


class TestDifferentEncodings:
    """Test file operations with different encoding parameters."""

    def test_utf8_encoding(self, tmp_path):
        """Test explicit UTF-8 encoding."""
        test_file = tmp_path / "utf8_test.txt"
        content = UNICODE_TEST_STRINGS["mixed"]

        with open(test_file, "w", encoding="utf-8") as f:
            f.write(content)

        with open(test_file, "r", encoding="utf-8") as f:
            read_content = f.read()

        assert read_content == content
        assert_no_mojibake(read_content, ["âœ…", "ä¸­æ–‡", "ğŸ‰"])

    def test_utf16_encoding(self, tmp_path):
        """Test UTF-16 encoding."""
        test_file = tmp_path / "utf16_test.txt"
        content = UNICODE_TEST_STRINGS["mixed"]

        with open(test_file, "w", encoding="utf-16") as f:
            f.write(content)

        with open(test_file, "r", encoding="utf-16") as f:
            read_content = f.read()

        assert read_content == content
        assert_no_mojibake(read_content, ["âœ…", "ä¸­æ–‡", "ğŸ‰"])

    def test_encoding_mismatch_detection(self, tmp_path):
        """Test that encoding mismatch causes issues (negative test)."""
        test_file = tmp_path / "mismatch_test.txt"
        content = "Test âœ…"

        # Write as UTF-8
        with open(test_file, "w", encoding="utf-8") as f:
            f.write(content)

        # Try to read as latin-1 (will cause issues with emoji)
        with open(test_file, "r", encoding="latin-1", errors="replace") as f:
            read_content = f.read()

        # Content should NOT match due to encoding mismatch
        assert read_content != content
        # The emoji will be replaced or garbled
        assert "âœ…" not in read_content or read_content != content

    def test_utf8_with_bom(self, tmp_path):
        """Test UTF-8 with BOM (Byte Order Mark)."""
        test_file = tmp_path / "utf8_bom_test.txt"
        content = UNICODE_TEST_STRINGS["mixed"]

        with open(test_file, "w", encoding="utf-8-sig") as f:
            f.write(content)

        # Read with BOM handling
        with open(test_file, "r", encoding="utf-8-sig") as f:
            read_content = f.read()

        assert read_content == content
        assert_no_mojibake(read_content, ["âœ…", "ä¸­æ–‡", "ğŸ‰"])

    def test_default_encoding_is_utf8(self, tmp_path):
        """Test that default encoding handles unicode properly."""
        test_file = tmp_path / "default_encoding_test.txt"
        content = "Test âœ… ä¸­æ–‡"

        # Write without explicit encoding (should use UTF-8 on modern Python)
        test_file.write_text(content)

        # Read without explicit encoding
        read_content = test_file.read_text()

        # Should work with unicode
        assert "âœ…" in read_content
        assert "ä¸­æ–‡" in read_content


class TestMalformedUnicode:
    """Test handling of malformed unicode data."""

    def test_read_with_errors_replace(self, tmp_path):
        """Test reading malformed unicode with errors='replace'."""
        test_file = tmp_path / "malformed_test.txt"

        # Write valid UTF-8
        test_file.write_bytes(b"Valid \xe2\x9c\x85")  # âœ… in UTF-8

        # Append invalid UTF-8 sequence
        with open(test_file, "ab") as f:
            f.write(b" Invalid \xff\xfe")

        # Read with error handling
        with open(test_file, "r", encoding="utf-8", errors="replace") as f:
            content = f.read()

        # Should have replacement character for invalid bytes
        assert "âœ…" in content
        assert "ï¿½" in content or "Invalid" in content

    def test_read_with_errors_ignore(self, tmp_path):
        """Test reading malformed unicode with errors='ignore'."""
        test_file = tmp_path / "malformed_ignore_test.txt"

        # Write mixed valid and invalid UTF-8
        test_file.write_bytes(b"Test \xe2\x9c\x85 \xff\xfe End")

        # Read with ignore
        with open(test_file, "r", encoding="utf-8", errors="ignore") as f:
            content = f.read()

        # Should have valid chars, invalid ones ignored
        assert "âœ…" in content
        assert "Test" in content
        assert "End" in content

    def test_write_surrogate_pairs(self, tmp_path):
        """Test handling of unicode surrogate pairs (emoji)."""
        test_file = tmp_path / "surrogate_test.txt"

        # Emoji that use surrogate pairs
        content = "ğŸ‰ ğŸ”§ ğŸ“"

        with open(test_file, "w", encoding="utf-8") as f:
            f.write(content)

        with open(test_file, "r", encoding="utf-8") as f:
            read_content = f.read()

        assert read_content == content
        assert "ğŸ‰" in read_content
        assert "ğŸ”§" in read_content
        assert "ğŸ“" in read_content


class TestLargeFilesWithUnicode:
    """Test operations on large files containing unicode."""

    def test_large_file_with_repeated_unicode(self, tmp_path):
        """Test reading/writing large file with repeated unicode."""
        test_file = tmp_path / "large_unicode_test.txt"

        # Create large content with unicode
        content = UNICODE_TEST_STRINGS["long_unicode"]  # âœ… * 100

        test_file.write_text(content, encoding="utf-8")
        read_content = test_file.read_text(encoding="utf-8")

        assert read_content == content
        assert read_content.count("âœ…") == 100

    def test_large_file_with_mixed_unicode(self, tmp_path):
        """Test large file with mixed unicode characters."""
        test_file = tmp_path / "large_mixed_test.txt"

        # Create large content with various unicode
        lines = []
        for i in range(1000):
            line = f"Line {i}: {UNICODE_TEST_STRINGS['mixed']}\n"
            lines.append(line)

        content = "".join(lines)

        test_file.write_text(content, encoding="utf-8")
        read_content = test_file.read_text(encoding="utf-8")

        assert read_content == content
        # Verify unicode preserved throughout
        assert read_content.count("âœ…") == 1000
        assert read_content.count("ğŸ‰") == 1000
        assert read_content.count("ä¸­æ–‡") == 1000

    def test_read_large_file_line_by_line(self, tmp_path):
        """Test reading large unicode file line by line."""
        test_file = tmp_path / "large_lines_test.txt"

        # Write lines with unicode
        lines = [f"Line {i}: âœ… Test ä¸­æ–‡\n" for i in range(100)]
        test_file.write_text("".join(lines), encoding="utf-8")

        # Read line by line
        with open(test_file, "r", encoding="utf-8") as f:
            read_lines = f.readlines()

        assert len(read_lines) == 100
        for line in read_lines:
            assert "âœ…" in line
            assert "ä¸­æ–‡" in line
            assert_no_mojibake(line, ["âœ…", "ä¸­æ–‡"])


class TestEdgeCases:
    """Test edge cases and error conditions."""

    def test_empty_file_with_unicode_name(self, tmp_path):
        """Test creating empty file with unicode name."""
        filename = "empty_âœ…_file.txt"
        test_file = tmp_path / filename

        test_file.touch()

        assert test_file.exists()
        assert test_file.stat().st_size == 0
        assert "âœ…" in test_file.name

    def test_overwrite_unicode_content(self, tmp_path):
        """Test overwriting file with different unicode content."""
        test_file = tmp_path / "overwrite_test.txt"

        # Write initial content
        test_file.write_text("Initial âœ…", encoding="utf-8")

        # Overwrite
        test_file.write_text("New ğŸ‰", encoding="utf-8")

        content = test_file.read_text(encoding="utf-8")
        assert "ğŸ‰" in content
        assert "âœ…" not in content

    def test_binary_mode_with_unicode(self, tmp_path):
        """Test writing unicode in binary mode."""
        test_file = tmp_path / "binary_unicode_test.txt"
        content = "Test âœ…"

        # Write in binary mode (must encode manually)
        with open(test_file, "wb") as f:
            f.write(content.encode("utf-8"))

        # Read in text mode
        with open(test_file, "r", encoding="utf-8") as f:
            read_content = f.read()

        assert read_content == content
        assert "âœ…" in read_content

    def test_file_with_only_emoji(self, tmp_path):
        """Test file containing only emoji characters."""
        test_file = tmp_path / "only_emoji.txt"
        content = "âœ…âŒâš ï¸ğŸ‰ğŸ“ğŸ”§"

        test_file.write_text(content, encoding="utf-8")
        read_content = test_file.read_text(encoding="utf-8")

        assert read_content == content
        assert len(read_content) == len(content)  # Use dynamic length instead of hard-coded value

    def test_newlines_with_unicode(self, tmp_path):
        """Test various newline styles with unicode content."""
        test_file = tmp_path / "newlines_test.txt"

        # Test different newline styles
        content = "Line1 âœ…\nLine2 ğŸ‰\r\nLine3 ä¸­æ–‡"

        test_file.write_text(content, encoding="utf-8")
        read_content = test_file.read_text(encoding="utf-8")

        # Python normalizes newlines on Windows
        assert "âœ…" in read_content
        assert "ğŸ‰" in read_content
        assert "ä¸­æ–‡" in read_content
