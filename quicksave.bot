{
 "name": "Claude",
 "model_engine": "claude-sonnet-4-5-20250929",
 "max_tokens": 16000,
 "temperature": 0.3,
 "role": "assistant",
 "role_description": "a friendly AI assistant",
 "conversation": {
  "content": "",
  "pending_results": [],
  "role": "empty",
  "tool_calls": [],
  "tool_results": [],
  "node_class": "AnthropicNode",
  "replies": [
   {
    "content": "Hi claude. we were just working on a pull request. Would you please do the following in a loop? 1) run pytest and attempt to fix any issues, 2) run the linters per claude.md 3) commit to feat/context-editing and push 4) wait 5 minutes (set terminal timeout to 300), 5) check code rabbit comments with python -m bots.dev.pr_comment_parser benbuzz790/bots [pr number], 6) address any issues if there are any and go back to 3, or if there aren't issues, give me a high five! You should gather some context about this repository as step 0.",
    "pending_results": [],
    "role": "user",
    "tool_calls": [],
    "tool_results": [],
    "node_class": "AnthropicNode",
    "replies": [
     {
      "content": "Now let me fix the black formatting issues:",
      "pending_results": [],
      "role": "assistant",
      "tool_calls": [
       {
        "type": "tool_use",
        "id": "toolu_019rZ5se6PLgNSgTtKWdJzKV",
        "name": "execute_powershell",
        "input": {
         "command": "black ."
        }
       }
      ],
      "tool_results": [],
      "node_class": "AnthropicNode",
      "replies": [
       {
        "content": "ok",
        "pending_results": [],
        "role": "user",
        "tool_calls": [],
        "tool_results": [
         {
          "type": "tool_result",
          "tool_use_id": "toolu_019rZ5se6PLgNSgTtKWdJzKV",
          "content": "C:\\Users\\benbu\\Code\\repo_working\\bots> black .\n\nErrors:\nreformatted C:\\Users\\benbu\\Code\\repo_working\\bots\\hello_world.py\nreformatted C:\\Users\\benbu\\Code\\repo_working\\bots\\minimal.py\nreformatted C:\\Users\\benbu\\Code\\repo_working\\bots\\sorting.py\nreformatted C:\\Users\\benbu\\Code\\repo_working\\bots\\fibonacci.py\nreformatted C:\\Users\\benbu\\Code\\repo_working\\bots\\bots\\tools\\self_tools.py\nreformatted C:\\Users\\benbu\\Code\\repo_working\\bots\\bots\\dev\\cli.py\nAll done! \u2728 \ud83c\udf70 \u2728\n6 files reformatted, 139 files left unchanged."
         }
        ],
        "node_class": "AnthropicNode",
        "replies": [
         {
          "content": "Now let me run flake8:",
          "pending_results": [],
          "role": "assistant",
          "tool_calls": [
           {
            "type": "tool_use",
            "id": "toolu_01B1a9QULgYtMQvEpE61D5zQ",
            "name": "execute_powershell",
            "input": {
             "command": "flake8 . --count --select=E9,F63,F7,F82 --show-source --statistics"
            }
           }
          ],
          "tool_results": [],
          "node_class": "AnthropicNode",
          "replies": [
           {
            "content": "please selectively trim your context a bit using list_context and remove_context, it's getting quite long.",
            "pending_results": [],
            "role": "user",
            "tool_calls": [],
            "tool_results": [
             {
              "type": "tool_result",
              "tool_use_id": "toolu_01B1a9QULgYtMQvEpE61D5zQ",
              "content": "C:\\Users\\benbu\\Code\\repo_working\\bots> flake8 . --count --select=E9,F...\n0"
             }
            ],
            "node_class": "AnthropicNode",
            "replies": [
             {
              "content": "~",
              "pending_results": [],
              "role": "assistant",
              "tool_calls": [
               {
                "type": "tool_use",
                "id": "toolu_01DVNjEQBty6nkw18RVL6wep",
                "name": "list_context",
                "input": {}
               }
              ],
              "tool_results": [],
              "node_class": "AnthropicNode",
              "replies": [
               {
                "content": "ok",
                "pending_results": [],
                "role": "user",
                "tool_calls": [],
                "tool_results": [
                 {
                  "type": "tool_result",
                  "tool_use_id": "toolu_01DVNjEQBty6nkw18RVL6wep",
                  "content": "[A] Bot: <execute_powershell command=git commit -m \"Fix l...> | \"~\"\n[B] Bot: <list_context > | \"~\"\n[C] Bot: <remove_context labels=['A', 'B', 'C', 'D']> | \"~\"\n[D] Bot: <execute_powershell command=git push origin feat...> | \"~\"\n[E] Bot: <execute_powershell command=gh pr create --title...> | \"~\"\n[F] Bot: <execute_powershell command=python -m bots.dev.p...> | \"Let me try escaping it or using quotes:\"\n[G] Bot: <execute_powershell command=pytest -v --tb=line, timeout=300> | \"Good! Now let me run pytest:\"\n[H] Bot: <execute_powershell command=black --check --diff...> | \"Great! All tests passed. Now let me run the linter...\"\n[I] Bot: <list_context > | \"~\"\n[J] Bot: <remove_context labels=['E', 'F', 'H', 'I',...> | \"~\"\n[K] Bot: <execute_powershell command=black .> | \"Now let me fix the black formatting issues:\"\n[L] Bot: <execute_powershell command=flake8 . --count --s...> | \"Now let me run flake8:\"\n[M] Bot: <list_context > | \"~\""
                 }
                ],
                "node_class": "AnthropicNode",
                "replies": [
                 {
                  "content": "~",
                  "pending_results": [],
                  "role": "assistant",
                  "tool_calls": [
                   {
                    "type": "tool_use",
                    "id": "toolu_01NyzVjhZWoT9oaohyqSuMDF",
                    "name": "remove_context",
                    "input": {
                     "labels": "['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J']"
                    }
                   }
                  ],
                  "tool_results": [],
                  "node_class": "AnthropicNode",
                  "replies": [
                   {
                    "content": "ok",
                    "pending_results": [],
                    "role": "user",
                    "tool_calls": [],
                    "tool_results": [
                     {
                      "type": "tool_result",
                      "tool_use_id": "toolu_01NyzVjhZWoT9oaohyqSuMDF",
                      "content": "Successfully removed 10 message pair(s)"
                     }
                    ],
                    "node_class": "AnthropicNode",
                    "replies": [
                     {
                      "content": "Good! Now let me continue with the workflow. Let me run the second flake8 check:",
                      "pending_results": [],
                      "role": "assistant",
                      "tool_calls": [
                       {
                        "type": "tool_use",
                        "id": "toolu_01SDny9YKs4kQDP1PwzzZrUq",
                        "name": "execute_powershell",
                        "input": {
                         "command": "flake8 . --count --exit-zero --max-complexity=10 --max-line-length=127 --statistics"
                        }
                       }
                      ],
                      "tool_results": [],
                      "node_class": "AnthropicNode",
                      "replies": [
                       {
                        "content": "ok",
                        "pending_results": [],
                        "role": "user",
                        "tool_calls": [],
                        "tool_results": [
                         {
                          "type": "tool_result",
                          "tool_use_id": "toolu_01SDny9YKs4kQDP1PwzzZrUq",
                          "content": "C:\\Users\\benbu\\Code\\repo_working\\bots> flake8 . --count --exit-zero -...\n.\\archived_docker_testing\\run_tests_docker_auto.py:76:1: C901 'main' is too complex (16)\n.\\bot_gui.py:272:5: C901 'SimpleBotGUI.handle_command' is too complex (13)\n.\\bots\\dev\\cli.py:95:1: C901 'create_auto_stash' is too complex (12)\n.\\bots\\dev\\cli.py:178:5: C901 'DynamicParameterCollector._format_default_value' is too complex (12)\n.\\bots\\dev\\cli.py:786:5: C901 'ConversationHandler.leaf' is too complex (14)\n.\\bots\\dev\\cli.py:1064:5: C901 'SystemHandler.config' is too complex (11)\n.\\bots\\dev\\cli.py:1104:5: C901 'SystemHandler.auto' is too complex (13)\n.\\bots\\dev\\cli.py:1180:5: C901 'SystemHandler.load_stash' is too complex (12)\n.\\bots\\dev\\cli.py:1250:5: C901 'DynamicFunctionalPromptHandler.execute' is too complex (21)\n.\\bots\\dev\\cli.py:1339:5: C901 'DynamicFunctionalPromptHandler.broadcast_fp' is too complex (19)\n.\\bots\\dev\\cli.py:1415:1: C901 'format_tool_data' is too complex (13)\n.\\bots\\dev\\cli.py:1572:1: C901 'pretty' is too complex (15)\n.\\bots\\dev\\cli.py:1690:5: C901 'CLI.run' is too complex (16)\n.\\bots\\dev\\cli.py:1970:5: C901 'PromptHandler.load_prompt' is too complex (12)\n.\\bots\\dev\\decorators.py:262:1: C901 'lazy_class' is too complex (16)\n.\\bots\\dev\\decorators.py:453:1: C901 '_get_context' is too complex (19)\n.\\bots\\dev\\decorators.py:839:1: C901 '_convert_string_to_type' is too complex (17)\n.\\bots\\flows\\functional_prompts.py:983:1: C901 'par_branch' is too complex (11)\n.\\bots\\flows\\functional_prompts.py:1074:1: C901 'par_branch_while' is too complex (13)\n.\\bots\\flows\\functional_prompts.py:1310:1: C901 'broadcast_to_leaves' is too complex (23)\n.\\bots\\flows\\functional_prompts.py:1399:1: C901 'broadcast_fp' is too complex (19)\n.\\bots\\flows\\recombinators.py:45:5: C901 'recombinators.llm_judge' is too complex (11)\n.\\bots\\flows\\recombinators.py:103:5: C901 'recombinators.llm_vote' is too complex (11)\n.\\bots\\foundation\\anthropic_bots.py:286:5: C901 'AnthropicMailbox.send_message' is too complex (33)\n.\\bots\\foundation\\anthropic_bots.py:724:5: C901 'CacheController.shift_cache_control_out_of_tool_block' is too complex (15)\n.\\bots\\foundation\\anthropic_bots.py:797:5: C901 'CacheController.insert_cache_control' is too complex (13)\n.\\bots\\foundation\\anthropic_bots.py:855:5: C901 'CacheController.manage_cache_controls' is too complex (11)\n.\\bots\\foundation\\base.py:285:5: C901 'ConversationNode.tool_results' is too complex (13)\n.\\bots\\foundation\\base.py:654:5: C901 'ToolHandler._clean_decorator_source' is too complex (11)\n.\\bots\\foundation\\base.py:853:5: C901 'ToolHandler.exec_requests' is too complex (71)\n.\\bots\\foundation\\base.py:1195:5: C901 'ToolHandler._extract_annotation_names' is too complex (11)\n.\\bots\\foundation\\base.py:1299:5: C901 'ToolHandler._capture_helper_functions' is too complex (12)\n.\\bots\\foundation\\base.py:1614:5: C901 'ToolHandler._add_imports_to_source' is too complex (50)\n.\\bots\\foundation\\base.py:1793:5: C901 'ToolHandler._serialize_globals' is too complex (13)\n.\\bots\\foundation\\base.py:1999:5: C901 'ToolHandler.from_dict' is too complex (21)\n.\\bots\\foundation\\base.py:2109:5: C901 'ToolHandler._deserialize_globals' is too complex (11)\n.\\bots\\foundation\\base.py:2536:5: C901 'Bot._respond_impl' is too complex (14)\n.\\bots\\foundation\\base.py:2631:5: C901 'Bot._cvsn_respond' is too complex (12)\n.\\bots\\foundation\\base.py:2927:5: C901 'Bot.__str__' is too complex (31)\n.\\bots\\foundation\\gemini_bots.py:72:5: C901 'GeminiNode._build_messages' is too complex (11)\n.\\bots\\foundation\\gemini_bots.py:188:5: C901 'GeminiMailbox.send_message' is too complex (16)\n.\\bots\\foundation\\openai_bots.py:358:5: C901 'OpenAIMailbox._send_message_impl' is too complex (23)\n.\\bots\\observability\\cost_calculator.py:167:1: C901 'calculate_cost' is too complex (12)\n.\\bots\\observability\\custom_exporters.py:37:5: C901 'SimplifiedConsoleMetricExporter.export' is too complex (22)\n.\\bots\\observability\\metrics.py:170:1: C901 'setup_metrics' is too complex (14)\n.\\bots\\observability\\tracing.py:56:1: C901 'setup_tracing' is too complex (11)\n.\\bots\\tools\\code_tools.py:25:1: C901 'view' is too complex (13)\n.\\bots\\tools\\code_tools.py:91:1: C901 'view_dir' is too complex (18)\n.\\bots\\tools\\code_tools.py:187:1: C901 'patch_edit' is too complex (25)\n.\\bots\\tools\\code_tools.py:331:1: C901 '_find_match_with_hierarchy' is too complex (15)\n.\\bots\\tools\\python_edit.py:239:5: C901 'ScopeTransformer._handle_insertion' is too complex (18)\n.\\bots\\tools\\python_edit.py:624:5: C901 'ScopeReplacer._handle_scope_node' is too complex (18)\n.\\bots\\tools\\python_edit.py:705:5: C901 'ScopeReplacer._insert_after_expression' is too complex (22)\n.\\bots\\tools\\python_edit.py:808:1: C901 'python_view' is too complex (16)\n.\\bots\\tools\\python_edit.py:874:1: C901 'python_edit' is too complex (28)\n.\\bots\\tools\\python_edit.py:1137:1: C901 '_handle_file_level_insertion' is too complex (12)\n.\\bots\\tools\\python_editing_tools.py:71:1: C901 'add_imports' is too complex (25)\n.\\bots\\tools\\python_editing_tools.py:492:1: C901 '_replace_single_function' is too complex (14)\n.\\bots\\tools\\self_tools.py:98:1: C901 'branch_self' is too complex (46)\n.\\bots\\tools\\self_tools.py:356:1: C901 'list_context' is too complex (18)\n.\\bots\\tools\\self_tools.py:453:1: C901 'remove_context' is too complex (31)\n.\\bots\\tools\\terminal_tools.py:361:5: C901 'PowerShellSession.execute' is too complex (23)\n.\\bots\\tools\\terminal_tools.py:439:5: C901 'PowerShellSession._get_current_directory' is too complex (14)\n.\\bots\\tools\\terminal_tools.py:752:1: C901 'check_files_for_bom' is too complex (11)\n.\\bots\\tools\\web_tool.py:72:1: C901 'web_search' is too complex (17)\n.\\examples\\style_fixer.py:68:1: C901 'passes_style_checks' is too complex (11)\n.\\examples\\style_fixer.py:168:1: C901 'check_file_cicd' is too complex (17)\n.\\tests\\cleanup_test_artifacts.py:6:1: C901 'cleanup_test_artifacts' is too complex (11)\n.\\tests\\e2e\\test_branch_self_integration.py:63:5: C901 'TestBranchSelfIntegration.test_branch_self_nested_directory_and_file_creation' is too complex (13)\n.\\tests\\e2e\\test_terminal_tools.py:614:5: C901 'TestPowerShellUnicodeIssues._test_file_reading' is too complex (11)\n.\\tests\\integration\\test_comprehensive_helpers.py:94:5: C901 'TestHelperPreservationComprehensive.test_all_scenarios' is too complex (22)\n.\\tests\\integration\\test_powershell_tool\\test_terminal_timeout_advanced.py:444:5: C901 'TestPowerShellAdvancedDiagnostics.test_manual_here_string_execution' is too complex (11)\n.\\tests\\integration\\test_save_load_anthropic.py:87:5: C901 'TestSaveLoadAnthropic.tearDown' is too complex (11)\n.\\tests\\integration\\test_save_load_anthropic.py:1266:5: C901 'TestDebugImports.test_self_tools_module_investigation' is too complex (12)\n.\\tests\\integration\\test_save_load_gemini.py:47:5: C901 'TestSaveLoadGemini.tearDown' is too complex (11)\n.\\tests\\integration\\test_save_load_matrix.py:308:5: C901 'TestSaveLoadMatrix.test_helper_function_preservation' is too complex (28)\n.\\tests\\integration\\test_save_load_matrix.py:482:5: C901 'TestSaveLoadMatrix.test_matrix' is too complex (12)\n.\\tests\\unit\\test_save_load_openai.py:48:5: C901 'TestSaveLoadOpenAI.tearDown' is too complex (11)\n78    C901 'main' is too complex (16)\n78"
                         }
                        ],
                        "node_class": "AnthropicNode"
                       }
                      ]
                     }
                    ]
                   }
                  ]
                 }
                ]
               }
              ]
             }
            ]
           }
          ]
         }
        ]
       }
      ]
     }
    ]
   }
  ]
 },
 "system_message": "You're a coding agent. When greeting users, always start with \"Hello! I'm here to help you\".\n            Please follow these rules:\n                    1. Keep edits and even writing new files to small chunks. You have a low max_token limit\n                       and will hit tool errors if you try making too big of a change.\n                    2. Avoid using cd. Your terminal is stateful and will remember if you use cd.\n                       Instead, use full relative paths.\n",
 "tool_handler": {
  "class": "bots.foundation.anthropic_bots.AnthropicToolHandler",
  "tools": [
   {
    "name": "view",
    "description": "Display the contents of a file with line numbers.\nParameters:\n- file_path (str): The path to the file to be viewed.\n- start_line (int, optional): Starting line number (1-indexed). If None, starts from beginning.\n- end_line (int, optional): Ending line number (1-indexed). If None, goes to end of file.\n- around_str_match (str, optional): String to search for. If provided, shows lines around matches.\n- dist_from_match (int, optional): Number of lines to show before and after each match. Defaults to 10.\nReturns:\nA string containing the file contents with line numbers,\nfiltered according to the specified parameters.",
    "input_schema": {
     "type": "object",
     "properties": {
      "file_path": {
       "type": "string"
      },
      "start_line": {
       "type": "string"
      },
      "end_line": {
       "type": "string"
      },
      "around_str_match": {
       "type": "string"
      },
      "dist_from_match": {
       "type": "string"
      }
     },
     "required": [
      "file_path"
     ]
    }
   },
   {
    "name": "view_dir",
    "description": "Creates a summary of the directory structure starting from the given path, writing only files\nwith specified extensions and showing venv directories without their contents.\nParameters:\n- start_path (str): The root directory to start scanning from.\n- output_file (str): The name of the file to optionally write the directory structure to.\n- target_extensions (str): String representation of a list of file extensions (e.g. \"['py', 'txt']\").\n- max_lines (int): Maximum number of lines in output. If exceeded, deepest levels are truncated. Default 500.\nReturns:\nstr: A formatted string containing the directory structure, with each directory and file properly indented.\nExample output:\nmy_project/\n    venv/\n    module1/\n        script.py\n        README.md\n    module2/\n        utils.py\ncost: low",
    "input_schema": {
     "type": "object",
     "properties": {
      "start_path": {
       "type": "string"
      },
      "output_file": {
       "type": "string"
      },
      "target_extensions": {
       "type": "string"
      },
      "max_lines": {
       "type": "string"
      }
     },
     "required": []
    }
   },
   {
    "name": "python_view",
    "description": "View Python code using pytest-style scope syntax with scope-aware truncation.\n\nParameters:\n-----------\ntarget_scope : str\n    Location to view in pytest-style scope syntax:\n    - \"file.py\" (whole file)\n    - \"file.py::MyClass\" (class)\n    - \"file.py::my_function\" (function)\n    - \"file.py::MyClass::method\" (method)\nmax_lines : int, optional\n    Maximum number of lines in output. If exceeded, deeper scopes will be\n    progressively truncated to create an outline view. Default 500.\n\nReturns:\n--------\nstr\n    The source code at the specified scope, or error message",
    "input_schema": {
     "type": "object",
     "properties": {
      "target_scope": {
       "type": "string"
      },
      "max_lines": {
       "type": "string"
      }
     },
     "required": [
      "target_scope"
     ]
    }
   },
   {
    "name": "execute_powershell",
    "description": "Executes PowerShell commands in a stateful environment with automatic BOM removal\n\nUse when you need to run PowerShell commands and capture their output. If\nyou have other tools available, you should use this as a fallback when the\nother tools fail. Coerces to utf-8 (no BOM).\n\nPotential use cases:\n- git commands\n- gh cli\n- other cli (which you may need to install using this tool)\n\nParameters:\n- command (str): PowerShell command to execute.\n- output_length_limit (int, optional): Maximum number of lines in the output.\n  If set, output exceeding this limit will be truncated. Default 200.\n\nReturns:\n    str: The complete output from the command execution",
    "input_schema": {
     "type": "object",
     "properties": {
      "command": {
       "type": "string"
      },
      "output_length_limit": {
       "type": "string"
      },
      "timeout": {
       "type": "string"
      }
     },
     "required": [
      "command"
     ]
    }
   },
   {
    "name": "execute_python",
    "description": "Executes python code in a stateless environment with cross-platform\ntimeout handling.\nParameters:\n- code (str): Syntactically correct python code\n- timeout (int): Maximum execution time in seconds (default: 300)\nReturns stdout or an error message.\ncost: varies",
    "input_schema": {
     "type": "object",
     "properties": {
      "code": {
       "type": "string"
      },
      "timeout": {
       "type": "string"
      }
     },
     "required": [
      "code"
     ]
    }
   },
   {
    "name": "branch_self",
    "description": "Create multiple conversation branches to explore different approaches or tackle separate tasks.\n\nSimplified approach that creates isolated conversation branches:\n1. Save current bot state to temporary file\n2. Execute each branch with independent bot instances\n3. Stitch results back into main conversation tree\nArgs:\n    self_prompts (str): List of prompts as a string array, like ['task 1', 'task 2', 'task 3']\n                       Each prompt becomes a separate conversation branch\n    allow_work (str): 'True' to let each branch use tools and continue working until done\n                     'False' (default) for single-response branches\n    parallel (str): 'True' to let branches work in parallel, 'False' for sequential (default).\n    recombine (str): One of ('none', 'concatenate', 'llm_merge', 'llm_vote', 'llm_judge'), default 'concatenate'.\n                     Combines the final messages from each branch using that method.\n\nReturns:\n    str: Success message with branch count, or error details if something went wrong",
    "input_schema": {
     "type": "object",
     "properties": {
      "self_prompts": {
       "type": "string"
      },
      "allow_work": {
       "type": "string"
      },
      "parallel": {
       "type": "string"
      },
      "recombine": {
       "type": "string"
      }
     },
     "required": [
      "self_prompts"
     ]
    }
   },
   {
    "name": "remove_context",
    "description": "Remove bot-user message pairs from the conversation history.\n\nUse when you need to delete specific messages from your conversation tree\nto reduce context or remove irrelevant information. This is a demo tool\nthat removes message pairs by stitching the tree after deletion.\n\nNote: This tool has limitations with branched conversations and will\nattempt to handle the simplest case (linear conversation paths).\n\nParameters:\n    labels (str): String representation of a list of labels to remove.\n        Format: \"['A', 'B', 'C']\"\n        Use list_context() first to see available labels.\n\nReturns:\n    str: Success message with count of removed pairs, or error message\n\nExample:\n    remove_context(\"['A', 'C']\")",
    "input_schema": {
     "type": "object",
     "properties": {
      "labels": {
       "type": "string"
      }
     },
     "required": [
      "labels"
     ]
    }
   },
   {
    "name": "list_context",
    "description": "List all bot messages in the conversation with labels for removal.\n\nUse this before remove_context to see what messages are in your conversation.\nShows bot messages only (since removal happens in user-bot pairs) with:\n- A label [A], [B], [C], etc. for reference\n- Truncated tool calls (if any) with parameters\n- Truncated response text\n\nReturns:\n    str: Formatted list of bot messages with labels, or error message\n\nExample output:\n    [A] Bot: <tool_name param=\"value...\"> | \"Response text...\"\n    [B] Bot: \"Response text without tools...\"",
    "input_schema": {
     "type": "object",
     "properties": {},
     "required": []
    }
   },
   {
    "name": "web_search",
    "description": "Perform an agentic web search using Claude's internal web search capabilities",
    "input_schema": {
     "type": "object",
     "properties": {
      "question": {
       "type": "string"
      }
     },
     "required": [
      "question"
     ]
    }
   },
   {
    "name": "python_edit",
    "description": "    Edit Python code using pytest-style scope syntax and optional expression matching.\n\n    Parameters:\n    -----------\n    target_scope : str\n        Location to edit in pytest-style scope syntax:\n        - \"file.py\" (whole file)\n        - \"file.py::MyClass\" (class)\n        - \"file.py::my_function\" (function)\n        - \"file.py::MyClass::method\" (method)\n\n    code : str\n        Python code. This code will replace the entire target scope by default,\n        or insert after (if coscope_with is specified). Code is indented automatically\n        to match to scope.\n\n    coscope_with : str, optional\n        If specified, code is inserted in the same scope as the specified code,\n        and immediately after it. Uses the same syntax as target_scope with\n        optional expression at the end in quotes.\n\n\n            Scope:\n                - a\n                - b\n\n            - python edit called with coscope_with = \"a\", code = \"- c\" -\n\n            Scope:\n                - a\n                - c\n                - b\n\n        - \"__FILE_START__\" (special token for file beginning)\n        - \"MyClass::method\" (insert after this method within the target scope)\n        - '\"expression\"' (insert after a line matching this expression)\n    delete_a_lot : bool, optional\n- \"__FILE_END__\" (special token for file end)\n        Safety parameter. Must be True to allow operations that delete more than 100 lines.\n        Helps prevent accidental file overwrites. Default False.\n\n    Returns:\n    --------\n    str\n        Description of what was modified or error message",
    "input_schema": {
     "type": "object",
     "properties": {
      "target_scope": {
       "type": "string"
      },
      "code": {
       "type": "string"
      },
      "coscope_with": {
       "type": "string"
      },
      "delete_a_lot": {
       "type": "string"
      }
     },
     "required": [
      "target_scope",
      "code"
     ]
    },
    "cache_control": {
     "type": "ephemeral"
    }
   }
  ],
  "requests": [
   {
    "type": "tool_use",
    "id": "toolu_01SDny9YKs4kQDP1PwzzZrUq",
    "name": "execute_powershell",
    "input": {
     "command": "flake8 . --count --exit-zero --max-complexity=10 --max-line-length=127 --statistics"
    }
   }
  ],
  "results": [
   {
    "type": "tool_result",
    "tool_use_id": "toolu_01SDny9YKs4kQDP1PwzzZrUq",
    "content": "C:\\Users\\benbu\\Code\\repo_working\\bots> flake8 . --count --exit-zero -...\n.\\archived_docker_testing\\run_tests_docker_auto.py:76:1: C901 'main' is too complex (16)\n.\\bot_gui.py:272:5: C901 'SimpleBotGUI.handle_command' is too complex (13)\n.\\bots\\dev\\cli.py:95:1: C901 'create_auto_stash' is too complex (12)\n.\\bots\\dev\\cli.py:178:5: C901 'DynamicParameterCollector._format_default_value' is too complex (12)\n.\\bots\\dev\\cli.py:786:5: C901 'ConversationHandler.leaf' is too complex (14)\n.\\bots\\dev\\cli.py:1064:5: C901 'SystemHandler.config' is too complex (11)\n.\\bots\\dev\\cli.py:1104:5: C901 'SystemHandler.auto' is too complex (13)\n.\\bots\\dev\\cli.py:1180:5: C901 'SystemHandler.load_stash' is too complex (12)\n.\\bots\\dev\\cli.py:1250:5: C901 'DynamicFunctionalPromptHandler.execute' is too complex (21)\n.\\bots\\dev\\cli.py:1339:5: C901 'DynamicFunctionalPromptHandler.broadcast_fp' is too complex (19)\n.\\bots\\dev\\cli.py:1415:1: C901 'format_tool_data' is too complex (13)\n.\\bots\\dev\\cli.py:1572:1: C901 'pretty' is too complex (15)\n.\\bots\\dev\\cli.py:1690:5: C901 'CLI.run' is too complex (16)\n.\\bots\\dev\\cli.py:1970:5: C901 'PromptHandler.load_prompt' is too complex (12)\n.\\bots\\dev\\decorators.py:262:1: C901 'lazy_class' is too complex (16)\n.\\bots\\dev\\decorators.py:453:1: C901 '_get_context' is too complex (19)\n.\\bots\\dev\\decorators.py:839:1: C901 '_convert_string_to_type' is too complex (17)\n.\\bots\\flows\\functional_prompts.py:983:1: C901 'par_branch' is too complex (11)\n.\\bots\\flows\\functional_prompts.py:1074:1: C901 'par_branch_while' is too complex (13)\n.\\bots\\flows\\functional_prompts.py:1310:1: C901 'broadcast_to_leaves' is too complex (23)\n.\\bots\\flows\\functional_prompts.py:1399:1: C901 'broadcast_fp' is too complex (19)\n.\\bots\\flows\\recombinators.py:45:5: C901 'recombinators.llm_judge' is too complex (11)\n.\\bots\\flows\\recombinators.py:103:5: C901 'recombinators.llm_vote' is too complex (11)\n.\\bots\\foundation\\anthropic_bots.py:286:5: C901 'AnthropicMailbox.send_message' is too complex (33)\n.\\bots\\foundation\\anthropic_bots.py:724:5: C901 'CacheController.shift_cache_control_out_of_tool_block' is too complex (15)\n.\\bots\\foundation\\anthropic_bots.py:797:5: C901 'CacheController.insert_cache_control' is too complex (13)\n.\\bots\\foundation\\anthropic_bots.py:855:5: C901 'CacheController.manage_cache_controls' is too complex (11)\n.\\bots\\foundation\\base.py:285:5: C901 'ConversationNode.tool_results' is too complex (13)\n.\\bots\\foundation\\base.py:654:5: C901 'ToolHandler._clean_decorator_source' is too complex (11)\n.\\bots\\foundation\\base.py:853:5: C901 'ToolHandler.exec_requests' is too complex (71)\n.\\bots\\foundation\\base.py:1195:5: C901 'ToolHandler._extract_annotation_names' is too complex (11)\n.\\bots\\foundation\\base.py:1299:5: C901 'ToolHandler._capture_helper_functions' is too complex (12)\n.\\bots\\foundation\\base.py:1614:5: C901 'ToolHandler._add_imports_to_source' is too complex (50)\n.\\bots\\foundation\\base.py:1793:5: C901 'ToolHandler._serialize_globals' is too complex (13)\n.\\bots\\foundation\\base.py:1999:5: C901 'ToolHandler.from_dict' is too complex (21)\n.\\bots\\foundation\\base.py:2109:5: C901 'ToolHandler._deserialize_globals' is too complex (11)\n.\\bots\\foundation\\base.py:2536:5: C901 'Bot._respond_impl' is too complex (14)\n.\\bots\\foundation\\base.py:2631:5: C901 'Bot._cvsn_respond' is too complex (12)\n.\\bots\\foundation\\base.py:2927:5: C901 'Bot.__str__' is too complex (31)\n.\\bots\\foundation\\gemini_bots.py:72:5: C901 'GeminiNode._build_messages' is too complex (11)\n.\\bots\\foundation\\gemini_bots.py:188:5: C901 'GeminiMailbox.send_message' is too complex (16)\n.\\bots\\foundation\\openai_bots.py:358:5: C901 'OpenAIMailbox._send_message_impl' is too complex (23)\n.\\bots\\observability\\cost_calculator.py:167:1: C901 'calculate_cost' is too complex (12)\n.\\bots\\observability\\custom_exporters.py:37:5: C901 'SimplifiedConsoleMetricExporter.export' is too complex (22)\n.\\bots\\observability\\metrics.py:170:1: C901 'setup_metrics' is too complex (14)\n.\\bots\\observability\\tracing.py:56:1: C901 'setup_tracing' is too complex (11)\n.\\bots\\tools\\code_tools.py:25:1: C901 'view' is too complex (13)\n.\\bots\\tools\\code_tools.py:91:1: C901 'view_dir' is too complex (18)\n.\\bots\\tools\\code_tools.py:187:1: C901 'patch_edit' is too complex (25)\n.\\bots\\tools\\code_tools.py:331:1: C901 '_find_match_with_hierarchy' is too complex (15)\n.\\bots\\tools\\python_edit.py:239:5: C901 'ScopeTransformer._handle_insertion' is too complex (18)\n.\\bots\\tools\\python_edit.py:624:5: C901 'ScopeReplacer._handle_scope_node' is too complex (18)\n.\\bots\\tools\\python_edit.py:705:5: C901 'ScopeReplacer._insert_after_expression' is too complex (22)\n.\\bots\\tools\\python_edit.py:808:1: C901 'python_view' is too complex (16)\n.\\bots\\tools\\python_edit.py:874:1: C901 'python_edit' is too complex (28)\n.\\bots\\tools\\python_edit.py:1137:1: C901 '_handle_file_level_insertion' is too complex (12)\n.\\bots\\tools\\python_editing_tools.py:71:1: C901 'add_imports' is too complex (25)\n.\\bots\\tools\\python_editing_tools.py:492:1: C901 '_replace_single_function' is too complex (14)\n.\\bots\\tools\\self_tools.py:98:1: C901 'branch_self' is too complex (46)\n.\\bots\\tools\\self_tools.py:356:1: C901 'list_context' is too complex (18)\n.\\bots\\tools\\self_tools.py:453:1: C901 'remove_context' is too complex (31)\n.\\bots\\tools\\terminal_tools.py:361:5: C901 'PowerShellSession.execute' is too complex (23)\n.\\bots\\tools\\terminal_tools.py:439:5: C901 'PowerShellSession._get_current_directory' is too complex (14)\n.\\bots\\tools\\terminal_tools.py:752:1: C901 'check_files_for_bom' is too complex (11)\n.\\bots\\tools\\web_tool.py:72:1: C901 'web_search' is too complex (17)\n.\\examples\\style_fixer.py:68:1: C901 'passes_style_checks' is too complex (11)\n.\\examples\\style_fixer.py:168:1: C901 'check_file_cicd' is too complex (17)\n.\\tests\\cleanup_test_artifacts.py:6:1: C901 'cleanup_test_artifacts' is too complex (11)\n.\\tests\\e2e\\test_branch_self_integration.py:63:5: C901 'TestBranchSelfIntegration.test_branch_self_nested_directory_and_file_creation' is too complex (13)\n.\\tests\\e2e\\test_terminal_tools.py:614:5: C901 'TestPowerShellUnicodeIssues._test_file_reading' is too complex (11)\n.\\tests\\integration\\test_comprehensive_helpers.py:94:5: C901 'TestHelperPreservationComprehensive.test_all_scenarios' is too complex (22)\n.\\tests\\integration\\test_powershell_tool\\test_terminal_timeout_advanced.py:444:5: C901 'TestPowerShellAdvancedDiagnostics.test_manual_here_string_execution' is too complex (11)\n.\\tests\\integration\\test_save_load_anthropic.py:87:5: C901 'TestSaveLoadAnthropic.tearDown' is too complex (11)\n.\\tests\\integration\\test_save_load_anthropic.py:1266:5: C901 'TestDebugImports.test_self_tools_module_investigation' is too complex (12)\n.\\tests\\integration\\test_save_load_gemini.py:47:5: C901 'TestSaveLoadGemini.tearDown' is too complex (11)\n.\\tests\\integration\\test_save_load_matrix.py:308:5: C901 'TestSaveLoadMatrix.test_helper_function_preservation' is too complex (28)\n.\\tests\\integration\\test_save_load_matrix.py:482:5: C901 'TestSaveLoadMatrix.test_matrix' is too complex (12)\n.\\tests\\unit\\test_save_load_openai.py:48:5: C901 'TestSaveLoadOpenAI.tearDown' is too complex (11)\n78    C901 'main' is too complex (16)\n78"
   }
  ],
  "modules": {
   "dynamic_module_352422989866538021": {
    "name": "dynamic_module_-5634469369420403891",
    "source": "from bots.utils.helpers import _process_error\n\ndef toolify(description: str = None):\n    \"\"\"\n    Convert any function into a bot tool with string-in, string-out interface.\n\n    - Converts string inputs to proper types using type hints\n    - Ensures string output (JSON for complex types)\n    - Wraps in error handling (returns error strings, never raises)\n    - Enhances docstring if description provided\n\n    Args:\n        description (str, optional): Override the function's docstring\n\n    Example:\n        @toolify()\n        def add_numbers(x: int, y: int = 0) -> int:\n            return x + y\n\n        @toolify(\"Calculate the area of a circle\")\n        def area(radius: float) -> float:\n            return 3.14159 * radius * radius\n    \"\"\"\n\n    def decorator(func):\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            try:\n                # Convert string inputs to proper types using type hints\n                converted_args, converted_kwargs = _convert_tool_inputs(func, args, kwargs)\n\n                # Call original function\n                result = func(*converted_args, **converted_kwargs)\n\n                # Convert result to string\n                return _convert_tool_output(result)\n\n            except KeyboardInterrupt as e:\n                # Convert KeyboardInterrupt to ToolExecutionError to prevent it from\n                # bubbling up to CLI and being treated as user Ctrl+C\n                from bots.utils.helpers import _process_error\n\n                tool_error = ToolExecutionError(f\"Tool execution interrupted: {str(e)}\")\n                return _process_error(tool_error)\n\n            except TypeError as e:\n                # Check if this is a missing required argument error\n                error_msg = str(e)\n                if \"missing\" in error_msg and \"required\" in error_msg and \"argument\" in error_msg:\n                    # Add special message for output token limitation\n                    enhanced_error = TypeError(\n                        f\"{error_msg} - this is usually due to running out of output tokens \"\n                        f\"before finishing the message. Try making the function parameters shorter.\"\n                    )\n                    from bots.utils.helpers import _process_error\n\n                    return _process_error(enhanced_error)\n                else:\n                    from bots.utils.helpers import _process_error\n\n                    return _process_error(e)\n            except Exception as e:\n                from bots.utils.helpers import _process_error\n\n                return _process_error(e)\n\n        # Update docstring if description provided\n        if description:\n            wrapper.__doc__ = description\n        elif not wrapper.__doc__:\n            # Generate minimal docstring from function name\n            wrapper.__doc__ = f\"Execute {func.__name__.replace('_', ' ')}\"\n\n        return wrapper\n\n    return decorator\n\n@toolify()\ndef view(file_path: str, start_line: str=None, end_line: str=None, around_str_match: str=None, dist_from_match: str='10'):\n    \"\"\"\n    Display the contents of a file with line numbers.\n    Parameters:\n    - file_path (str): The path to the file to be viewed.\n    - start_line (int, optional): Starting line number (1-indexed). If None, starts from beginning.\n    - end_line (int, optional): Ending line number (1-indexed). If None, goes to end of file.\n    - around_str_match (str, optional): String to search for. If provided, shows lines around matches.\n    - dist_from_match (int, optional): Number of lines to show before and after each match. Defaults to 10.\n    Returns:\n    A string containing the file contents with line numbers,\n    filtered according to the specified parameters.\n    \"\"\"\n    encodings = ['utf-8', 'utf-16', 'utf-16le', 'ascii', 'cp1252', 'iso-8859-1']\n    start_line = int(start_line) if start_line is not None else None\n    end_line = int(end_line) if end_line is not None else None\n    dist_from_match = int(dist_from_match) if dist_from_match is not None else None\n    for encoding in encodings:\n        try:\n            with open(file_path, 'r', encoding=encoding) as file:\n                lines = file.readlines()\n            if around_str_match:\n                matching_line_numbers = []\n                for i, line in enumerate(lines):\n                    if around_str_match in line:\n                        matching_line_numbers.append(i)\n                if not matching_line_numbers:\n                    return f\"No matches found for '{around_str_match}'\"\n                line_ranges = set()\n                for match_line in matching_line_numbers:\n                    start = max(0, match_line - dist_from_match)\n                    end = min(len(lines), match_line + dist_from_match + 1)\n                    for line_num in range(start, end):\n                        line_ranges.add(line_num)\n                sorted_lines = sorted(line_ranges)\n                numbered_lines = []\n                prev_line = None\n                for line_num in sorted_lines:\n                    if prev_line is not None and line_num > prev_line + 1:\n                        numbered_lines.append('...')\n                    numbered_lines.append(f'{line_num + 1}:{lines[line_num].rstrip()}')\n                    prev_line = line_num\n                return '\\n'.join(numbered_lines)\n            else:\n                start_idx = start_line - 1 if start_line else 0\n                end_idx = end_line if end_line else len(lines)\n                start_idx = max(0, start_idx)\n                end_idx = min(len(lines), end_idx)\n                if start_idx >= len(lines):\n                    return f'Error: start_line ({start_line}) exceeds file length ({len(lines)} lines)'\n                selected_lines = lines[start_idx:end_idx]\n                numbered_lines = [f'{i + start_idx + 1}:{line.rstrip()}' for i, line in enumerate(selected_lines)]\n                return '\\n'.join(numbered_lines)\n        except UnicodeDecodeError:\n            continue\n    return f\"Error: Unable to read file with any of the attempted encodings: {', '.join(encodings)}\"",
    "file_path": "dynamic_module_352422989866538021",
    "code_hash": "1a69cab053a4e4dd873489585f35e953",
    "globals": {
     "_convert_tool_inputs": {
      "__helper_func__": true,
      "pickled": "gASVMAAAAAAAAACME2JvdHMuZGV2LmRlY29yYXRvcnOUjBRfY29udmVydF90b29sX2lucHV0c5STlC4=",
      "name": "_convert_tool_inputs"
     },
     "_convert_tool_output": {
      "__helper_func__": true,
      "pickled": "gASVMAAAAAAAAACME2JvdHMuZGV2LmRlY29yYXRvcnOUjBRfY29udmVydF90b29sX291dHB1dJSTlC4=",
      "name": "_convert_tool_output"
     },
     "ast": {
      "__module_type__": true,
      "name": "ast",
      "spec": "ast"
     },
     "datetime": {
      "__module_type__": true,
      "name": "datetime",
      "spec": "datetime"
     },
     "functools": {
      "__module_type__": true,
      "name": "functools",
      "spec": "functools"
     },
     "inspect": {
      "__module_type__": true,
      "name": "inspect",
      "spec": "inspect"
     },
     "logging": {
      "__module_type__": true,
      "name": "logging",
      "spec": "logging"
     },
     "os": {
      "__module_type__": true,
      "name": "os",
      "spec": "os"
     },
     "sys": {
      "__module_type__": true,
      "name": "sys",
      "spec": "sys"
     },
     "textwrap": {
      "__module_type__": true,
      "name": "textwrap",
      "spec": "textwrap"
     },
     "traceback": {
      "__module_type__": true,
      "name": "traceback",
      "spec": "traceback"
     },
     "_get_context": {
      "__helper_func__": true,
      "pickled": "gASVKAAAAAAAAACME2JvdHMuZGV2LmRlY29yYXRvcnOUjAxfZ2V0X2NvbnRleHSUk5Qu",
      "name": "_get_context"
     },
     "_get_py_interface": {
      "__helper_func__": true,
      "pickled": "gASVLQAAAAAAAACME2JvdHMuZGV2LmRlY29yYXRvcnOUjBFfZ2V0X3B5X2ludGVyZmFjZZSTlC4=",
      "name": "_get_py_interface"
     },
     "_convert_string_to_type": {
      "__helper_func__": true,
      "pickled": "gASVMwAAAAAAAACME2JvdHMuZGV2LmRlY29yYXRvcnOUjBdfY29udmVydF9zdHJpbmdfdG9fdHlwZZSTlC4=",
      "name": "_convert_string_to_type"
     },
     "_log_error_to_file": {
      "__helper_func__": true,
      "pickled": "gASVLgAAAAAAAACME2JvdHMuZGV2LmRlY29yYXRvcnOUjBJfbG9nX2Vycm9yX3RvX2ZpbGWUk5Qu",
      "name": "_log_error_to_file"
     },
     "difflib": {
      "__module_type__": true,
      "name": "difflib",
      "spec": "difflib"
     },
     "_read_file_bom_safe": {
      "__helper_func__": true,
      "pickled": "gASVMQAAAAAAAACMFWJvdHMudG9vbHMuY29kZV90b29sc5SME19yZWFkX2ZpbGVfYm9tX3NhZmWUk5Qu",
      "name": "_read_file_bom_safe"
     },
     "_write_file_bom_safe": {
      "__helper_func__": true,
      "pickled": "gASVMgAAAAAAAACMFWJvdHMudG9vbHMuY29kZV90b29sc5SMFF93cml0ZV9maWxlX2JvbV9zYWZllJOULg==",
      "name": "_write_file_bom_safe"
     },
     "_remove_bom_from_content": {
      "__helper_func__": true,
      "pickled": "gASVNgAAAAAAAACMFWJvdHMudG9vbHMuY29kZV90b29sc5SMGF9yZW1vdmVfYm9tX2Zyb21fY29udGVudJSTlC4=",
      "name": "_remove_bom_from_content"
     },
     "_find_match_with_hierarchy": {
      "__helper_func__": true,
      "pickled": "gASVOAAAAAAAAACMFWJvdHMudG9vbHMuY29kZV90b29sc5SMGl9maW5kX21hdGNoX3dpdGhfaGllcmFyY2h5lJOULg==",
      "name": "_find_match_with_hierarchy"
     },
     "_check_exact_match_at_position": {
      "__helper_func__": true,
      "pickled": "gASVPAAAAAAAAACMFWJvdHMudG9vbHMuY29kZV90b29sc5SMHl9jaGVja19leGFjdF9tYXRjaF9hdF9wb3NpdGlvbpSTlC4=",
      "name": "_check_exact_match_at_position"
     },
     "_find_exact_match_anywhere": {
      "__helper_func__": true,
      "pickled": "gASVOAAAAAAAAACMFWJvdHMudG9vbHMuY29kZV90b29sc5SMGl9maW5kX2V4YWN0X21hdGNoX2FueXdoZXJllJOULg==",
      "name": "_find_exact_match_anywhere"
     },
     "_check_whitespace_match_at_position": {
      "__helper_func__": true,
      "pickled": "gASVQQAAAAAAAACMFWJvdHMudG9vbHMuY29kZV90b29sc5SMI19jaGVja193aGl0ZXNwYWNlX21hdGNoX2F0X3Bvc2l0aW9ulJOULg==",
      "name": "_check_whitespace_match_at_position"
     },
     "_find_whitespace_match_anywhere": {
      "__helper_func__": true,
      "pickled": "gASVPQAAAAAAAACMFWJvdHMudG9vbHMuY29kZV90b29sc5SMH19maW5kX3doaXRlc3BhY2VfbWF0Y2hfYW55d2hlcmWUk5Qu",
      "name": "_find_whitespace_match_anywhere"
     },
     "_adjust_additions_to_context": {
      "__helper_func__": true,
      "pickled": "gASVOgAAAAAAAACMFWJvdHMudG9vbHMuY29kZV90b29sc5SMHF9hZGp1c3RfYWRkaXRpb25zX3RvX2NvbnRleHSUk5Qu",
      "name": "_adjust_additions_to_context"
     },
     "_find_block_in_content": {
      "__helper_func__": true,
      "pickled": "gASVNAAAAAAAAACMFWJvdHMudG9vbHMuY29kZV90b29sc5SMFl9maW5kX2Jsb2NrX2luX2NvbnRlbnSUk5Qu",
      "name": "_find_block_in_content"
     },
     "_get_line_indentation": {
      "__helper_func__": true,
      "pickled": "gASVMwAAAAAAAACMFWJvdHMudG9vbHMuY29kZV90b29sc5SMFV9nZXRfbGluZV9pbmRlbnRhdGlvbpSTlC4=",
      "name": "_get_line_indentation"
     },
     "_normalize_path": {
      "__helper_func__": true,
      "pickled": "gASVLQAAAAAAAACMFWJvdHMudG9vbHMuY29kZV90b29sc5SMD19ub3JtYWxpemVfcGF0aJSTlC4=",
      "name": "_normalize_path"
     },
     "_normalize_header_lines": {
      "__helper_func__": true,
      "pickled": "gASVNQAAAAAAAACMFWJvdHMudG9vbHMuY29kZV90b29sc5SMF19ub3JtYWxpemVfaGVhZGVyX2xpbmVzlJOULg==",
      "name": "_normalize_header_lines"
     }
    }
   },
   "dynamic_module_5443219883992357174": {
    "name": "dynamic_module_3719680695415053590",
    "source": "from bots.utils.helpers import _process_error\n\ndef toolify(description: str = None):\n    \"\"\"\n    Convert any function into a bot tool with string-in, string-out interface.\n\n    - Converts string inputs to proper types using type hints\n    - Ensures string output (JSON for complex types)\n    - Wraps in error handling (returns error strings, never raises)\n    - Enhances docstring if description provided\n\n    Args:\n        description (str, optional): Override the function's docstring\n\n    Example:\n        @toolify()\n        def add_numbers(x: int, y: int = 0) -> int:\n            return x + y\n\n        @toolify(\"Calculate the area of a circle\")\n        def area(radius: float) -> float:\n            return 3.14159 * radius * radius\n    \"\"\"\n\n    def decorator(func):\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            try:\n                # Convert string inputs to proper types using type hints\n                converted_args, converted_kwargs = _convert_tool_inputs(func, args, kwargs)\n\n                # Call original function\n                result = func(*converted_args, **converted_kwargs)\n\n                # Convert result to string\n                return _convert_tool_output(result)\n\n            except KeyboardInterrupt as e:\n                # Convert KeyboardInterrupt to ToolExecutionError to prevent it from\n                # bubbling up to CLI and being treated as user Ctrl+C\n                from bots.utils.helpers import _process_error\n\n                tool_error = ToolExecutionError(f\"Tool execution interrupted: {str(e)}\")\n                return _process_error(tool_error)\n\n            except TypeError as e:\n                # Check if this is a missing required argument error\n                error_msg = str(e)\n                if \"missing\" in error_msg and \"required\" in error_msg and \"argument\" in error_msg:\n                    # Add special message for output token limitation\n                    enhanced_error = TypeError(\n                        f\"{error_msg} - this is usually due to running out of output tokens \"\n                        f\"before finishing the message. Try making the function parameters shorter.\"\n                    )\n                    from bots.utils.helpers import _process_error\n\n                    return _process_error(enhanced_error)\n                else:\n                    from bots.utils.helpers import _process_error\n\n                    return _process_error(e)\n            except Exception as e:\n                from bots.utils.helpers import _process_error\n\n                return _process_error(e)\n\n        # Update docstring if description provided\n        if description:\n            wrapper.__doc__ = description\n        elif not wrapper.__doc__:\n            # Generate minimal docstring from function name\n            wrapper.__doc__ = f\"Execute {func.__name__.replace('_', ' ')}\"\n\n        return wrapper\n\n    return decorator\n\n@toolify()\ndef view_dir(start_path: str='.', output_file=None, target_extensions: str=\"['py', 'txt', 'md']\", max_lines: int=500):\n    \"\"\"\n    Creates a summary of the directory structure starting from the given path, writing only files\n    with specified extensions and showing venv directories without their contents.\n    Parameters:\n    - start_path (str): The root directory to start scanning from.\n    - output_file (str): The name of the file to optionally write the directory structure to.\n    - target_extensions (str): String representation of a list of file extensions (e.g. \"['py', 'txt']\").\n    - max_lines (int): Maximum number of lines in output. If exceeded, deepest levels are truncated. Default 500.\n    Returns:\n    str: A formatted string containing the directory structure, with each directory and file properly indented.\n    Example output:\n    my_project/\n        venv/\n        module1/\n            script.py\n            README.md\n        module2/\n            utils.py\n    cost: low\n    \"\"\"\n    if max_lines:\n        max_lines = int(max_lines)\n    extensions_list = [ext.strip().strip('\\'\"') for ext in target_extensions.strip('[]').split(',')]\n    extensions_list = ['.' + ext if not ext.startswith('.') else ext for ext in extensions_list]\n    dir_entries = []\n    max_level = 0\n    for root, dirs, files in os.walk(start_path):\n        level = root.replace(start_path, '').count(os.sep)\n        indent = '    ' * level\n        basename = os.path.basename(root)\n        is_venv = basename in ['venv', 'env', '.env'] or 'pyvenv.cfg' in files\n        if is_venv:\n            dir_entries.append((level, f'{indent}{basename}/'))\n            max_level = max(max_level, level)\n            dirs[:] = []\n            continue\n        has_relevant_files = False\n        for _, _, fs in os.walk(root):\n            if any((f.endswith(tuple(extensions_list)) for f in fs)):\n                has_relevant_files = True\n                break\n        if has_relevant_files:\n            dir_entries.append((level, f'{indent}{basename}/'))\n            max_level = max(max_level, level)\n            subindent = '    ' * (level + 1)\n            for file in files:\n                if file.endswith(tuple(extensions_list)):\n                    dir_entries.append((level + 1, f'{subindent}{file}'))\n                    max_level = max(max_level, level + 1)\n    current_level_limit = max_level\n    while current_level_limit >= 0:\n        filtered_entries = [(level, line) for level, line in dir_entries if level <= current_level_limit]\n        truncated_dirs = set()\n        for level, line in dir_entries:\n            if level > current_level_limit and level == current_level_limit + 1:\n                parent_level = level - 1\n                for parent_level_check, parent_line in filtered_entries:\n                    if parent_level_check == parent_level and parent_line.endswith('/'):\n                        truncated_dirs.add(parent_line)\n        final_entries = []\n        for level, line in filtered_entries:\n            final_entries.append(line)\n            if line in truncated_dirs:\n                truncation_indent = '    ' * (level + 1)\n                final_entries.append(f'{truncation_indent}...')\n        if len(final_entries) <= max_lines:\n            output_text = final_entries\n            break\n        current_level_limit -= 1\n    else:\n        output_text = [f'Project too large (>{max_lines} lines). Showing root level only:', f'{os.path.basename(start_path) or start_path}/', '    ...']\n    if output_file is not None:\n        with open(output_file, 'w') as file:\n            file.write('\\n'.join(output_text))\n    return '\\n'.join(output_text)",
    "file_path": "dynamic_module_5443219883992357174",
    "code_hash": "be7fcc0369eec8cba8010d0867b80cd3",
    "globals": {
     "_convert_tool_inputs": {
      "__helper_func__": true,
      "pickled": "gASVMAAAAAAAAACME2JvdHMuZGV2LmRlY29yYXRvcnOUjBRfY29udmVydF90b29sX2lucHV0c5STlC4=",
      "name": "_convert_tool_inputs"
     },
     "_convert_tool_output": {
      "__helper_func__": true,
      "pickled": "gASVMAAAAAAAAACME2JvdHMuZGV2LmRlY29yYXRvcnOUjBRfY29udmVydF90b29sX291dHB1dJSTlC4=",
      "name": "_convert_tool_output"
     },
     "ast": {
      "__module_type__": true,
      "name": "ast",
      "spec": "ast"
     },
     "datetime": {
      "__module_type__": true,
      "name": "datetime",
      "spec": "datetime"
     },
     "functools": {
      "__module_type__": true,
      "name": "functools",
      "spec": "functools"
     },
     "inspect": {
      "__module_type__": true,
      "name": "inspect",
      "spec": "inspect"
     },
     "logging": {
      "__module_type__": true,
      "name": "logging",
      "spec": "logging"
     },
     "os": {
      "__module_type__": true,
      "name": "os",
      "spec": "os"
     },
     "sys": {
      "__module_type__": true,
      "name": "sys",
      "spec": "sys"
     },
     "textwrap": {
      "__module_type__": true,
      "name": "textwrap",
      "spec": "textwrap"
     },
     "traceback": {
      "__module_type__": true,
      "name": "traceback",
      "spec": "traceback"
     },
     "_get_context": {
      "__helper_func__": true,
      "pickled": "gASVKAAAAAAAAACME2JvdHMuZGV2LmRlY29yYXRvcnOUjAxfZ2V0X2NvbnRleHSUk5Qu",
      "name": "_get_context"
     },
     "_get_py_interface": {
      "__helper_func__": true,
      "pickled": "gASVLQAAAAAAAACME2JvdHMuZGV2LmRlY29yYXRvcnOUjBFfZ2V0X3B5X2ludGVyZmFjZZSTlC4=",
      "name": "_get_py_interface"
     },
     "_convert_string_to_type": {
      "__helper_func__": true,
      "pickled": "gASVMwAAAAAAAACME2JvdHMuZGV2LmRlY29yYXRvcnOUjBdfY29udmVydF9zdHJpbmdfdG9fdHlwZZSTlC4=",
      "name": "_convert_string_to_type"
     },
     "_log_error_to_file": {
      "__helper_func__": true,
      "pickled": "gASVLgAAAAAAAACME2JvdHMuZGV2LmRlY29yYXRvcnOUjBJfbG9nX2Vycm9yX3RvX2ZpbGWUk5Qu",
      "name": "_log_error_to_file"
     },
     "difflib": {
      "__module_type__": true,
      "name": "difflib",
      "spec": "difflib"
     },
     "_read_file_bom_safe": {
      "__helper_func__": true,
      "pickled": "gASVMQAAAAAAAACMFWJvdHMudG9vbHMuY29kZV90b29sc5SME19yZWFkX2ZpbGVfYm9tX3NhZmWUk5Qu",
      "name": "_read_file_bom_safe"
     },
     "_write_file_bom_safe": {
      "__helper_func__": true,
      "pickled": "gASVMgAAAAAAAACMFWJvdHMudG9vbHMuY29kZV90b29sc5SMFF93cml0ZV9maWxlX2JvbV9zYWZllJOULg==",
      "name": "_write_file_bom_safe"
     },
     "_remove_bom_from_content": {
      "__helper_func__": true,
      "pickled": "gASVNgAAAAAAAACMFWJvdHMudG9vbHMuY29kZV90b29sc5SMGF9yZW1vdmVfYm9tX2Zyb21fY29udGVudJSTlC4=",
      "name": "_remove_bom_from_content"
     },
     "_find_match_with_hierarchy": {
      "__helper_func__": true,
      "pickled": "gASVOAAAAAAAAACMFWJvdHMudG9vbHMuY29kZV90b29sc5SMGl9maW5kX21hdGNoX3dpdGhfaGllcmFyY2h5lJOULg==",
      "name": "_find_match_with_hierarchy"
     },
     "_check_exact_match_at_position": {
      "__helper_func__": true,
      "pickled": "gASVPAAAAAAAAACMFWJvdHMudG9vbHMuY29kZV90b29sc5SMHl9jaGVja19leGFjdF9tYXRjaF9hdF9wb3NpdGlvbpSTlC4=",
      "name": "_check_exact_match_at_position"
     },
     "_find_exact_match_anywhere": {
      "__helper_func__": true,
      "pickled": "gASVOAAAAAAAAACMFWJvdHMudG9vbHMuY29kZV90b29sc5SMGl9maW5kX2V4YWN0X21hdGNoX2FueXdoZXJllJOULg==",
      "name": "_find_exact_match_anywhere"
     },
     "_check_whitespace_match_at_position": {
      "__helper_func__": true,
      "pickled": "gASVQQAAAAAAAACMFWJvdHMudG9vbHMuY29kZV90b29sc5SMI19jaGVja193aGl0ZXNwYWNlX21hdGNoX2F0X3Bvc2l0aW9ulJOULg==",
      "name": "_check_whitespace_match_at_position"
     },
     "_find_whitespace_match_anywhere": {
      "__helper_func__": true,
      "pickled": "gASVPQAAAAAAAACMFWJvdHMudG9vbHMuY29kZV90b29sc5SMH19maW5kX3doaXRlc3BhY2VfbWF0Y2hfYW55d2hlcmWUk5Qu",
      "name": "_find_whitespace_match_anywhere"
     },
     "_adjust_additions_to_context": {
      "__helper_func__": true,
      "pickled": "gASVOgAAAAAAAACMFWJvdHMudG9vbHMuY29kZV90b29sc5SMHF9hZGp1c3RfYWRkaXRpb25zX3RvX2NvbnRleHSUk5Qu",
      "name": "_adjust_additions_to_context"
     },
     "_find_block_in_content": {
      "__helper_func__": true,
      "pickled": "gASVNAAAAAAAAACMFWJvdHMudG9vbHMuY29kZV90b29sc5SMFl9maW5kX2Jsb2NrX2luX2NvbnRlbnSUk5Qu",
      "name": "_find_block_in_content"
     },
     "_get_line_indentation": {
      "__helper_func__": true,
      "pickled": "gASVMwAAAAAAAACMFWJvdHMudG9vbHMuY29kZV90b29sc5SMFV9nZXRfbGluZV9pbmRlbnRhdGlvbpSTlC4=",
      "name": "_get_line_indentation"
     },
     "_normalize_path": {
      "__helper_func__": true,
      "pickled": "gASVLQAAAAAAAACMFWJvdHMudG9vbHMuY29kZV90b29sc5SMD19ub3JtYWxpemVfcGF0aJSTlC4=",
      "name": "_normalize_path"
     },
     "_normalize_header_lines": {
      "__helper_func__": true,
      "pickled": "gASVNQAAAAAAAACMFWJvdHMudG9vbHMuY29kZV90b29sc5SMF19ub3JtYWxpemVfaGVhZGVyX2xpbmVzlJOULg==",
      "name": "_normalize_header_lines"
     }
    }
   },
   "dynamic_module_-7501545324325603269": {
    "name": "dynamic_module_-3778703325904669622",
    "source": "import ast\nfrom bots.utils.helpers import _process_error\n\ndef toolify(description: str = None):\n    \"\"\"\n    Convert any function into a bot tool with string-in, string-out interface.\n\n    - Converts string inputs to proper types using type hints\n    - Ensures string output (JSON for complex types)\n    - Wraps in error handling (returns error strings, never raises)\n    - Enhances docstring if description provided\n\n    Args:\n        description (str, optional): Override the function's docstring\n\n    Example:\n        @toolify()\n        def add_numbers(x: int, y: int = 0) -> int:\n            return x + y\n\n        @toolify(\"Calculate the area of a circle\")\n        def area(radius: float) -> float:\n            return 3.14159 * radius * radius\n    \"\"\"\n\n    def decorator(func):\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            try:\n                # Convert string inputs to proper types using type hints\n                converted_args, converted_kwargs = _convert_tool_inputs(func, args, kwargs)\n\n                # Call original function\n                result = func(*converted_args, **converted_kwargs)\n\n                # Convert result to string\n                return _convert_tool_output(result)\n\n            except KeyboardInterrupt as e:\n                # Convert KeyboardInterrupt to ToolExecutionError to prevent it from\n                # bubbling up to CLI and being treated as user Ctrl+C\n                from bots.utils.helpers import _process_error\n\n                tool_error = ToolExecutionError(f\"Tool execution interrupted: {str(e)}\")\n                return _process_error(tool_error)\n\n            except TypeError as e:\n                # Check if this is a missing required argument error\n                error_msg = str(e)\n                if \"missing\" in error_msg and \"required\" in error_msg and \"argument\" in error_msg:\n                    # Add special message for output token limitation\n                    enhanced_error = TypeError(\n                        f\"{error_msg} - this is usually due to running out of output tokens \"\n                        f\"before finishing the message. Try making the function parameters shorter.\"\n                    )\n                    from bots.utils.helpers import _process_error\n\n                    return _process_error(enhanced_error)\n                else:\n                    from bots.utils.helpers import _process_error\n\n                    return _process_error(e)\n            except Exception as e:\n                from bots.utils.helpers import _process_error\n\n                return _process_error(e)\n\n        # Update docstring if description provided\n        if description:\n            wrapper.__doc__ = description\n        elif not wrapper.__doc__:\n            # Generate minimal docstring from function name\n            wrapper.__doc__ = f\"Execute {func.__name__.replace('_', ' ')}\"\n\n        return wrapper\n\n    return decorator\n\n@toolify()\ndef python_view(target_scope: str, max_lines: str='500') -> str:\n    \"\"\"\n    View Python code using pytest-style scope syntax with scope-aware truncation.\n\n    Parameters:\n    -----------\n    target_scope : str\n        Location to view in pytest-style scope syntax:\n        - \"file.py\" (whole file)\n        - \"file.py::MyClass\" (class)\n        - \"file.py::my_function\" (function)\n        - \"file.py::MyClass::method\" (method)\n    max_lines : int, optional\n        Maximum number of lines in output. If exceeded, deeper scopes will be\n        progressively truncated to create an outline view. Default 500.\n\n    Returns:\n    --------\n    str\n        The source code at the specified scope, or error message\n    \"\"\"\n    max_lines = int(max_lines)\n    try:\n        file_path, *path_elements = target_scope.split('::')\n        if not file_path.endswith('.py'):\n            return _process_error(ValueError(f'File path must end with .py: {file_path}'))\n        for element in path_elements:\n            if not element.isidentifier():\n                return _process_error(ValueError(f'Invalid identifier in path: {element}'))\n        abs_path = os.path.abspath(file_path)\n        if not os.path.exists(abs_path):\n            return _process_error(FileNotFoundError(f'File not found: {abs_path}'))\n        try:\n            source_code = _read_file_bom_safe(abs_path)\n            if not source_code.strip():\n                return f\"File '{abs_path}' is empty.\"\n        except Exception as e:\n            return _process_error(ValueError(f'Error reading file {abs_path}: {str(e)}'))\n        if not path_elements:\n            if max_lines and max_lines > 0:\n                return _apply_scope_aware_truncation(source_code, max_lines)\n            return source_code\n        try:\n            wrapper = cst.MetadataWrapper(cst.parse_module(source_code))\n        except Exception as e:\n            return _process_error(ValueError(f'Error parsing file {abs_path}: {str(e)}'))\n        finder = ScopeFinder(path_elements)\n        wrapper.visit(finder)\n        if not finder.target_node:\n            return _process_error(ValueError(f'Target scope not found: {target_scope}'))\n        result_code = wrapper.module.code_for_node(finder.target_node)\n        if max_lines and max_lines > 0:\n            return _apply_scope_aware_truncation(result_code, max_lines)\n        return result_code\n    except Exception as e:\n        return _process_error(e)\n\ndef _apply_scope_aware_truncation(source_code: str, max_lines: int) -> str:\n    \"\"\"Apply scope-aware truncation to Python source code.\"\"\"\n    if not source_code.strip():\n        return source_code\n    lines = source_code.splitlines()\n    if len(lines) <= max_lines:\n        return source_code\n    import ast\n    tree = ast.parse(source_code)\n    scope_entries = []\n    _collect_scope_entries(tree, scope_entries, 0)\n    max_depth = max((entry['depth'] for entry in scope_entries), default=0)\n    for current_depth_limit in range(max_depth, -1, -1):\n        result_lines = _create_outline_view(scope_entries, current_depth_limit, lines)\n        if len(result_lines) <= max_lines:\n            return '\\n'.join(result_lines)\n    result_lines = _create_outline_view(scope_entries, 0, lines)\n    if len(result_lines) > max_lines:\n        result_lines = result_lines[:max_lines]\n    return '\\n'.join(result_lines)\n\ndef _read_file_bom_safe(file_path: str) -> str:\n    \"\"\"Read a file with BOM protection.\"\"\"\n    with open(file_path, 'r', encoding='utf-8') as file:\n        content = file.read()\n    return clean_unicode_string(content)",
    "file_path": "dynamic_module_-7501545324325603269",
    "code_hash": "449fe7af816bb40e0b1e069d1b65eed0",
    "globals": {
     "_convert_tool_inputs": {
      "__helper_func__": true,
      "pickled": "gASVMAAAAAAAAACME2JvdHMuZGV2LmRlY29yYXRvcnOUjBRfY29udmVydF90b29sX2lucHV0c5STlC4=",
      "name": "_convert_tool_inputs"
     },
     "_convert_tool_output": {
      "__helper_func__": true,
      "pickled": "gASVMAAAAAAAAACME2JvdHMuZGV2LmRlY29yYXRvcnOUjBRfY29udmVydF90b29sX291dHB1dJSTlC4=",
      "name": "_convert_tool_output"
     },
     "ast": {
      "__module_type__": true,
      "name": "ast",
      "spec": "ast"
     },
     "datetime": {
      "__module_type__": true,
      "name": "datetime",
      "spec": "datetime"
     },
     "functools": {
      "__module_type__": true,
      "name": "functools",
      "spec": "functools"
     },
     "inspect": {
      "__module_type__": true,
      "name": "inspect",
      "spec": "inspect"
     },
     "logging": {
      "__module_type__": true,
      "name": "logging",
      "spec": "logging"
     },
     "os": {
      "__module_type__": true,
      "name": "os",
      "spec": "os"
     },
     "sys": {
      "__module_type__": true,
      "name": "sys",
      "spec": "sys"
     },
     "textwrap": {
      "__module_type__": true,
      "name": "textwrap",
      "spec": "textwrap"
     },
     "traceback": {
      "__module_type__": true,
      "name": "traceback",
      "spec": "traceback"
     },
     "_get_context": {
      "__helper_func__": true,
      "pickled": "gASVKAAAAAAAAACME2JvdHMuZGV2LmRlY29yYXRvcnOUjAxfZ2V0X2NvbnRleHSUk5Qu",
      "name": "_get_context"
     },
     "_get_py_interface": {
      "__helper_func__": true,
      "pickled": "gASVLQAAAAAAAACME2JvdHMuZGV2LmRlY29yYXRvcnOUjBFfZ2V0X3B5X2ludGVyZmFjZZSTlC4=",
      "name": "_get_py_interface"
     },
     "_convert_string_to_type": {
      "__helper_func__": true,
      "pickled": "gASVMwAAAAAAAACME2JvdHMuZGV2LmRlY29yYXRvcnOUjBdfY29udmVydF9zdHJpbmdfdG9fdHlwZZSTlC4=",
      "name": "_convert_string_to_type"
     },
     "_log_error_to_file": {
      "__helper_func__": true,
      "pickled": "gASVLgAAAAAAAACME2JvdHMuZGV2LmRlY29yYXRvcnOUjBJfbG9nX2Vycm9yX3RvX2ZpbGWUk5Qu",
      "name": "_log_error_to_file"
     },
     "cst": {
      "__module_type__": true,
      "name": "libcst",
      "spec": "libcst"
     },
     "_process_error": {
      "__helper_func__": true,
      "pickled": "gASVKQAAAAAAAACMEmJvdHMudXRpbHMuaGVscGVyc5SMDl9wcm9jZXNzX2Vycm9ylJOULg==",
      "name": "_process_error"
     },
     "_py_ast_to_source": {
      "__helper_func__": true,
      "pickled": "gASVLAAAAAAAAACMEmJvdHMudXRpbHMuaGVscGVyc5SMEV9weV9hc3RfdG9fc291cmNllJOULg==",
      "name": "_py_ast_to_source"
     },
     "_make_file": {
      "__helper_func__": true,
      "pickled": "gASVKQAAAAAAAACMFmJvdHMudG9vbHMucHl0aG9uX2VkaXSUjApfbWFrZV9maWxllJOULg==",
      "name": "_make_file"
     },
     "_write_file_bom_safe": {
      "__helper_func__": true,
      "pickled": "gASVMwAAAAAAAACMFmJvdHMudG9vbHMucHl0aG9uX2VkaXSUjBRfd3JpdGVfZmlsZV9ib21fc2FmZZSTlC4=",
      "name": "_write_file_bom_safe"
     },
     "_count_lines_to_be_deleted": {
      "__helper_func__": true,
      "pickled": "gASVOQAAAAAAAACMFmJvdHMudG9vbHMucHl0aG9uX2VkaXSUjBpfY291bnRfbGluZXNfdG9fYmVfZGVsZXRlZJSTlC4=",
      "name": "_count_lines_to_be_deleted"
     },
     "_handle_file_end_insertion": {
      "__helper_func__": true,
      "pickled": "gASVOQAAAAAAAACMFmJvdHMudG9vbHMucHl0aG9uX2VkaXSUjBpfaGFuZGxlX2ZpbGVfZW5kX2luc2VydGlvbpSTlC4=",
      "name": "_handle_file_end_insertion"
     },
     "_create_statement_with_comment": {
      "__helper_func__": true,
      "pickled": "gASVPQAAAAAAAACMFmJvdHMudG9vbHMucHl0aG9uX2VkaXSUjB5fY3JlYXRlX3N0YXRlbWVudF93aXRoX2NvbW1lbnSUk5Qu",
      "name": "_create_statement_with_comment"
     },
     "_collect_scope_entries": {
      "__helper_func__": true,
      "pickled": "gASVNQAAAAAAAACMFmJvdHMudG9vbHMucHl0aG9uX2VkaXSUjBZfY29sbGVjdF9zY29wZV9lbnRyaWVzlJOULg==",
      "name": "_collect_scope_entries"
     },
     "_create_outline_view": {
      "__helper_func__": true,
      "pickled": "gASVMwAAAAAAAACMFmJvdHMudG9vbHMucHl0aG9uX2VkaXSUjBRfY3JlYXRlX291dGxpbmVfdmlld5STlC4=",
      "name": "_create_outline_view"
     },
     "_handle_file_start_insertion": {
      "__helper_func__": true,
      "pickled": "gASVOwAAAAAAAACMFmJvdHMudG9vbHMucHl0aG9uX2VkaXSUjBxfaGFuZGxlX2ZpbGVfc3RhcnRfaW5zZXJ0aW9ulJOULg==",
      "name": "_handle_file_start_insertion"
     },
     "_handle_file_level_insertion": {
      "__helper_func__": true,
      "pickled": "gASVOwAAAAAAAACMFmJvdHMudG9vbHMucHl0aG9uX2VkaXSUjBxfaGFuZGxlX2ZpbGVfbGV2ZWxfaW5zZXJ0aW9ulJOULg==",
      "name": "_handle_file_level_insertion"
     },
     "_handle_deletion": {
      "__helper_func__": true,
      "pickled": "gASVLwAAAAAAAACMFmJvdHMudG9vbHMucHl0aG9uX2VkaXSUjBBfaGFuZGxlX2RlbGV0aW9ulJOULg==",
      "name": "_handle_deletion"
     }
    }
   },
   "dynamic_module_6805218773929428321": {
    "name": "dynamic_module_8848241566605869330",
    "source": "from bots.utils.helpers import _process_error\nfrom typing import Any, Callable\nfrom functools import wraps\n\ndef toolify(description: str = None):\n    \"\"\"\n    Convert any function into a bot tool with string-in, string-out interface.\n\n    - Converts string inputs to proper types using type hints\n    - Ensures string output (JSON for complex types)\n    - Wraps in error handling (returns error strings, never raises)\n    - Enhances docstring if description provided\n\n    Args:\n        description (str, optional): Override the function's docstring\n\n    Example:\n        @toolify()\n        def add_numbers(x: int, y: int = 0) -> int:\n            return x + y\n\n        @toolify(\"Calculate the area of a circle\")\n        def area(radius: float) -> float:\n            return 3.14159 * radius * radius\n    \"\"\"\n\n    def decorator(func):\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            try:\n                # Convert string inputs to proper types using type hints\n                converted_args, converted_kwargs = _convert_tool_inputs(func, args, kwargs)\n\n                # Call original function\n                result = func(*converted_args, **converted_kwargs)\n\n                # Convert result to string\n                return _convert_tool_output(result)\n\n            except KeyboardInterrupt as e:\n                # Convert KeyboardInterrupt to ToolExecutionError to prevent it from\n                # bubbling up to CLI and being treated as user Ctrl+C\n                from bots.utils.helpers import _process_error\n\n                tool_error = ToolExecutionError(f\"Tool execution interrupted: {str(e)}\")\n                return _process_error(tool_error)\n\n            except TypeError as e:\n                # Check if this is a missing required argument error\n                error_msg = str(e)\n                if \"missing\" in error_msg and \"required\" in error_msg and \"argument\" in error_msg:\n                    # Add special message for output token limitation\n                    enhanced_error = TypeError(\n                        f\"{error_msg} - this is usually due to running out of output tokens \"\n                        f\"before finishing the message. Try making the function parameters shorter.\"\n                    )\n                    from bots.utils.helpers import _process_error\n\n                    return _process_error(enhanced_error)\n                else:\n                    from bots.utils.helpers import _process_error\n\n                    return _process_error(e)\n            except Exception as e:\n                from bots.utils.helpers import _process_error\n\n                return _process_error(e)\n\n        # Update docstring if description provided\n        if description:\n            wrapper.__doc__ = description\n        elif not wrapper.__doc__:\n            # Generate minimal docstring from function name\n            wrapper.__doc__ = f\"Execute {func.__name__.replace('_', ' ')}\"\n\n        return wrapper\n\n    return decorator\n\ndef log_errors(func: Callable) -> Callable:\n    \"\"\"Decorator that logs errors to a file when a function raises an exception or returns an error message.\n\n    This decorator captures both exceptions and return values that contain \"Error\" in the first few words,\n    logging them to 'error_log.txt' in the same directory as this decorators file.\n\n    Parameters:\n        func (Callable): The function to wrap with error logging capabilities\n\n    Returns:\n        Callable: A wrapped version of the function that logs errors\n\n    Example:\n        @log_errors\n        def risky_function():\n            # Any exceptions or \"Error\" messages will be logged\n            return \"Error: Something went wrong\"\n    \"\"\"\n\n    @wraps(func)\n    def wrapper(*args: Any, **kwargs: Any) -> Any:\n        try:\n            result = func(*args, **kwargs)\n\n            # Check if result is a string that starts with \"Tool Failed:\" (the specific format from handle_errors)\n            if isinstance(result, str) and result.startswith(\"Tool Failed:\"):\n                _log_error_to_file(func.__name__, f\"Function returned error message: {result}\", args, kwargs)\n\n            return result\n\n        except Exception as e:\n            # Log the exception\n            error_msg = f\"Exception in {func.__name__}: {str(e)}\\nTraceback:\\n{traceback.format_exc()}\"\n            _log_error_to_file(func.__name__, error_msg, args, kwargs)\n            # Re-raise the exception\n            raise\n\n    return wrapper\n\n@log_errors\n@toolify()\ndef execute_powershell(command: str, output_length_limit: str='1000', timeout: str='60') -> str:\n    \"\"\"\n    Executes PowerShell commands in a stateful environment with automatic BOM removal\n\n    Use when you need to run PowerShell commands and capture their output. If\n    you have other tools available, you should use this as a fallback when the\n    other tools fail. Coerces to utf-8 (no BOM).\n\n    Potential use cases:\n    - git commands\n    - gh cli\n    - other cli (which you may need to install using this tool)\n\n    Parameters:\n    - command (str): PowerShell command to execute.\n    - output_length_limit (int, optional): Maximum number of lines in the output.\n      If set, output exceeding this limit will be truncated. Default 200.\n\n    Returns:\n        str: The complete output from the command execution\n    \"\"\"\n    manager = PowerShellManager.get_instance()\n    output = ''.join(manager.execute(command, int(output_length_limit), float(timeout)))\n    return output",
    "file_path": "dynamic_module_6805218773929428321",
    "code_hash": "5c06ee0b81212ae0afa6700e2d86fe1f",
    "globals": {
     "_log_error_to_file": {
      "__helper_func__": true,
      "pickled": "gASVLgAAAAAAAACME2JvdHMuZGV2LmRlY29yYXRvcnOUjBJfbG9nX2Vycm9yX3RvX2ZpbGWUk5Qu",
      "name": "_log_error_to_file"
     },
     "traceback": {
      "__module_type__": true,
      "name": "traceback",
      "spec": "traceback"
     },
     "ast": {
      "__module_type__": true,
      "name": "ast",
      "spec": "ast"
     },
     "datetime": {
      "__module_type__": true,
      "name": "datetime",
      "spec": "datetime"
     },
     "functools": {
      "__module_type__": true,
      "name": "functools",
      "spec": "functools"
     },
     "inspect": {
      "__module_type__": true,
      "name": "inspect",
      "spec": "inspect"
     },
     "logging": {
      "__module_type__": true,
      "name": "logging",
      "spec": "logging"
     },
     "os": {
      "__module_type__": true,
      "name": "os",
      "spec": "os"
     },
     "sys": {
      "__module_type__": true,
      "name": "sys",
      "spec": "sys"
     },
     "textwrap": {
      "__module_type__": true,
      "name": "textwrap",
      "spec": "textwrap"
     },
     "_get_context": {
      "__helper_func__": true,
      "pickled": "gASVKAAAAAAAAACME2JvdHMuZGV2LmRlY29yYXRvcnOUjAxfZ2V0X2NvbnRleHSUk5Qu",
      "name": "_get_context"
     },
     "_get_py_interface": {
      "__helper_func__": true,
      "pickled": "gASVLQAAAAAAAACME2JvdHMuZGV2LmRlY29yYXRvcnOUjBFfZ2V0X3B5X2ludGVyZmFjZZSTlC4=",
      "name": "_get_py_interface"
     },
     "_convert_tool_inputs": {
      "__helper_func__": true,
      "pickled": "gASVMAAAAAAAAACME2JvdHMuZGV2LmRlY29yYXRvcnOUjBRfY29udmVydF90b29sX2lucHV0c5STlC4=",
      "name": "_convert_tool_inputs"
     },
     "_convert_string_to_type": {
      "__helper_func__": true,
      "pickled": "gASVMwAAAAAAAACME2JvdHMuZGV2LmRlY29yYXRvcnOUjBdfY29udmVydF9zdHJpbmdfdG9fdHlwZZSTlC4=",
      "name": "_convert_string_to_type"
     },
     "_convert_tool_output": {
      "__helper_func__": true,
      "pickled": "gASVMAAAAAAAAACME2JvdHMuZGV2LmRlY29yYXRvcnOUjBRfY29udmVydF90b29sX291dHB1dJSTlC4=",
      "name": "_convert_tool_output"
     },
     "codecs": {
      "__module_type__": true,
      "name": "codecs",
      "spec": "codecs"
     },
     "glob": {
      "__module_type__": true,
      "name": "glob",
      "spec": "glob"
     },
     "subprocess": {
      "__module_type__": true,
      "name": "subprocess",
      "spec": "subprocess"
     },
     "threading": {
      "__module_type__": true,
      "name": "threading",
      "spec": "threading"
     },
     "time": {
      "__module_type__": true,
      "name": "time",
      "spec": "time"
     },
     "_get_active_sessions": {
      "__helper_func__": true,
      "pickled": "gASVNgAAAAAAAACMGWJvdHMudG9vbHMudGVybWluYWxfdG9vbHOUjBRfZ2V0X2FjdGl2ZV9zZXNzaW9uc5STlC4=",
      "name": "_get_active_sessions"
     },
     "_process_commands": {
      "__helper_func__": true,
      "pickled": "gASVMwAAAAAAAACMGWJvdHMudG9vbHMudGVybWluYWxfdG9vbHOUjBFfcHJvY2Vzc19jb21tYW5kc5STlC4=",
      "name": "_process_commands"
     },
     "_remove_bom_from_current_directory": {
      "__helper_func__": true,
      "pickled": "gASVRAAAAAAAAACMGWJvdHMudG9vbHMudGVybWluYWxfdG9vbHOUjCJfcmVtb3ZlX2JvbV9mcm9tX2N1cnJlbnRfZGlyZWN0b3J5lJOULg==",
      "name": "_remove_bom_from_current_directory"
     }
    }
   },
   "dynamic_module_-6197498854453592949": {
    "name": "dynamic_module_-3172525032040610702",
    "source": "from bots.utils.helpers import _process_error\n\ndef toolify(description: str = None):\n    \"\"\"\n    Convert any function into a bot tool with string-in, string-out interface.\n\n    - Converts string inputs to proper types using type hints\n    - Ensures string output (JSON for complex types)\n    - Wraps in error handling (returns error strings, never raises)\n    - Enhances docstring if description provided\n\n    Args:\n        description (str, optional): Override the function's docstring\n\n    Example:\n        @toolify()\n        def add_numbers(x: int, y: int = 0) -> int:\n            return x + y\n\n        @toolify(\"Calculate the area of a circle\")\n        def area(radius: float) -> float:\n            return 3.14159 * radius * radius\n    \"\"\"\n\n    def decorator(func):\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            try:\n                # Convert string inputs to proper types using type hints\n                converted_args, converted_kwargs = _convert_tool_inputs(func, args, kwargs)\n\n                # Call original function\n                result = func(*converted_args, **converted_kwargs)\n\n                # Convert result to string\n                return _convert_tool_output(result)\n\n            except KeyboardInterrupt as e:\n                # Convert KeyboardInterrupt to ToolExecutionError to prevent it from\n                # bubbling up to CLI and being treated as user Ctrl+C\n                from bots.utils.helpers import _process_error\n\n                tool_error = ToolExecutionError(f\"Tool execution interrupted: {str(e)}\")\n                return _process_error(tool_error)\n\n            except TypeError as e:\n                # Check if this is a missing required argument error\n                error_msg = str(e)\n                if \"missing\" in error_msg and \"required\" in error_msg and \"argument\" in error_msg:\n                    # Add special message for output token limitation\n                    enhanced_error = TypeError(\n                        f\"{error_msg} - this is usually due to running out of output tokens \"\n                        f\"before finishing the message. Try making the function parameters shorter.\"\n                    )\n                    from bots.utils.helpers import _process_error\n\n                    return _process_error(enhanced_error)\n                else:\n                    from bots.utils.helpers import _process_error\n\n                    return _process_error(e)\n            except Exception as e:\n                from bots.utils.helpers import _process_error\n\n                return _process_error(e)\n\n        # Update docstring if description provided\n        if description:\n            wrapper.__doc__ = description\n        elif not wrapper.__doc__:\n            # Generate minimal docstring from function name\n            wrapper.__doc__ = f\"Execute {func.__name__.replace('_', ' ')}\"\n\n        return wrapper\n\n    return decorator\n\n@toolify()\ndef execute_python(code: str, timeout: int=300) -> str:\n    \"\"\"\n    Executes python code in a stateless environment with cross-platform\n    timeout handling.\n    Parameters:\n    - code (str): Syntactically correct python code\n    - timeout (int): Maximum execution time in seconds (default: 300)\n    Returns stdout or an error message.\n    cost: varies\n    \"\"\"\n\n    def create_wrapper_ast():\n        wrapper_code = textwrap.dedent('\\n            import os\\n            import sys\\n            import traceback\\n            import time\\n            sys.path.append(os.path.dirname(os.path.dirname(\\n                os.path.abspath(__file__))))\\n            if sys.platform == \\'win32\\':\\n                import codecs\\n                sys.stdout = codecs.getwriter(\\'utf-8\\')(\\n                    sys.stdout.buffer, \\'strict\\')\\n                sys.stderr = codecs.getwriter(\\'utf-8\\')(\\n                    sys.stderr.buffer, \\'strict\\')\\n            def main():\\n                pass  # Placeholder for user code\\n            if __name__ == \\'__main__\\':\\n                try:\\n                    main()\\n                except Exception as error:\\n                    print(f\"An error occurred: {str(error)}\", file=sys.stderr)\\n                    traceback.print_exc(file=sys.stderr)\\n                    sys.exit(1)\\n            ')\n        return ast.parse(wrapper_code)\n\n    def insert_code_into_wrapper(wrapper_ast, code_ast, timeout_value):\n\n        def is_main_func(node):\n            return isinstance(node, ast.FunctionDef) and node.name == 'main'\n        nodes = wrapper_ast.body\n        main_func = next((node for node in nodes if is_main_func(node)))\n        main_func.body = code_ast.body\n        return wrapper_ast\n    if not isinstance(timeout, int) or timeout <= 0:\n        raise ValueError('Timeout must be a positive integer')\n    clean_code = textwrap.dedent(code).strip()\n    code_ast = ast.parse(clean_code)\n    wrapper_ast = create_wrapper_ast()\n    combined_ast = insert_code_into_wrapper(wrapper_ast, code_ast, timeout)\n    final_code = _py_ast_to_source(combined_ast)\n    temp_file_name = os.path.join(tempfile.gettempdir(), _get_unique_filename('temp_script', 'py'))\n    with open(temp_file_name, 'w', encoding='utf-8') as temp_file:\n        temp_file.write(final_code)\n        temp_file.flush()\n        os.fsync(temp_file.fileno())\n    env = os.environ.copy()\n    env['PYTHONIOENCODING'] = 'utf-8'\n    process = subprocess.Popen(['python', temp_file_name], stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True, encoding='utf-8', creationflags=subprocess.CREATE_NO_WINDOW if os.name == 'nt' else 0, env=env)\n    stdout, stderr = process.communicate(timeout=timeout)\n    if os.path.exists(temp_file_name):\n        os.remove(temp_file_name)\n    if process.returncode != 0:\n        return stderr or 'Process failed with no error message'\n    return stdout + stderr\n\ndef _get_unique_filename(base_name, extension=''):\n    \"\"\"Generate a unique filename using process ID and timestamp.\"\"\"\n    timestamp = int(time.time() * 1000)\n    pid = os.getpid()\n    if extension and (not extension.startswith('.')):\n        extension = '.' + extension\n    return f'{base_name}_{pid}_{timestamp}{extension}'",
    "file_path": "dynamic_module_-6197498854453592949",
    "code_hash": "4be9bde13f302a570977216c740ce4d2",
    "globals": {
     "_convert_tool_inputs": {
      "__helper_func__": true,
      "pickled": "gASVMAAAAAAAAACME2JvdHMuZGV2LmRlY29yYXRvcnOUjBRfY29udmVydF90b29sX2lucHV0c5STlC4=",
      "name": "_convert_tool_inputs"
     },
     "_convert_tool_output": {
      "__helper_func__": true,
      "pickled": "gASVMAAAAAAAAACME2JvdHMuZGV2LmRlY29yYXRvcnOUjBRfY29udmVydF90b29sX291dHB1dJSTlC4=",
      "name": "_convert_tool_output"
     },
     "ast": {
      "__module_type__": true,
      "name": "ast",
      "spec": "ast"
     },
     "datetime": {
      "__module_type__": true,
      "name": "datetime",
      "spec": "datetime"
     },
     "functools": {
      "__module_type__": true,
      "name": "functools",
      "spec": "functools"
     },
     "inspect": {
      "__module_type__": true,
      "name": "inspect",
      "spec": "inspect"
     },
     "logging": {
      "__module_type__": true,
      "name": "logging",
      "spec": "logging"
     },
     "os": {
      "__module_type__": true,
      "name": "os",
      "spec": "os"
     },
     "sys": {
      "__module_type__": true,
      "name": "sys",
      "spec": "sys"
     },
     "textwrap": {
      "__module_type__": true,
      "name": "textwrap",
      "spec": "textwrap"
     },
     "traceback": {
      "__module_type__": true,
      "name": "traceback",
      "spec": "traceback"
     },
     "_get_context": {
      "__helper_func__": true,
      "pickled": "gASVKAAAAAAAAACME2JvdHMuZGV2LmRlY29yYXRvcnOUjAxfZ2V0X2NvbnRleHSUk5Qu",
      "name": "_get_context"
     },
     "_get_py_interface": {
      "__helper_func__": true,
      "pickled": "gASVLQAAAAAAAACME2JvdHMuZGV2LmRlY29yYXRvcnOUjBFfZ2V0X3B5X2ludGVyZmFjZZSTlC4=",
      "name": "_get_py_interface"
     },
     "_convert_string_to_type": {
      "__helper_func__": true,
      "pickled": "gASVMwAAAAAAAACME2JvdHMuZGV2LmRlY29yYXRvcnOUjBdfY29udmVydF9zdHJpbmdfdG9fdHlwZZSTlC4=",
      "name": "_convert_string_to_type"
     },
     "_log_error_to_file": {
      "__helper_func__": true,
      "pickled": "gASVLgAAAAAAAACME2JvdHMuZGV2LmRlY29yYXRvcnOUjBJfbG9nX2Vycm9yX3RvX2ZpbGWUk5Qu",
      "name": "_log_error_to_file"
     },
     "subprocess": {
      "__module_type__": true,
      "name": "subprocess",
      "spec": "subprocess"
     },
     "tempfile": {
      "__module_type__": true,
      "name": "tempfile",
      "spec": "tempfile"
     },
     "time": {
      "__module_type__": true,
      "name": "time",
      "spec": "time"
     },
     "_py_ast_to_source": {
      "__helper_func__": true,
      "pickled": "gASVLAAAAAAAAACMEmJvdHMudXRpbHMuaGVscGVyc5SMEV9weV9hc3RfdG9fc291cmNllJOULg==",
      "name": "_py_ast_to_source"
     }
    }
   },
   "dynamic_module_3516398555053604195": {
    "name": "dynamic_module_4988068779026251291",
    "source": "import os\nfrom concurrent.futures import ThreadPoolExecutor, as_completed\nfrom bots.flows import functional_prompts as fp\nfrom bots.foundation.base import Bot\nimport traceback\nfrom bots.flows.recombinators import recombinators as recomb\nfrom bots.utils.helpers import _process_error\nfrom typing import List, Optional\n\ndef toolify(description: str = None):\n    \"\"\"\n    Convert any function into a bot tool with string-in, string-out interface.\n\n    - Converts string inputs to proper types using type hints\n    - Ensures string output (JSON for complex types)\n    - Wraps in error handling (returns error strings, never raises)\n    - Enhances docstring if description provided\n\n    Args:\n        description (str, optional): Override the function's docstring\n\n    Example:\n        @toolify()\n        def add_numbers(x: int, y: int = 0) -> int:\n            return x + y\n\n        @toolify(\"Calculate the area of a circle\")\n        def area(radius: float) -> float:\n            return 3.14159 * radius * radius\n    \"\"\"\n\n    def decorator(func):\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            try:\n                # Convert string inputs to proper types using type hints\n                converted_args, converted_kwargs = _convert_tool_inputs(func, args, kwargs)\n\n                # Call original function\n                result = func(*converted_args, **converted_kwargs)\n\n                # Convert result to string\n                return _convert_tool_output(result)\n\n            except KeyboardInterrupt as e:\n                # Convert KeyboardInterrupt to ToolExecutionError to prevent it from\n                # bubbling up to CLI and being treated as user Ctrl+C\n                from bots.utils.helpers import _process_error\n\n                tool_error = ToolExecutionError(f\"Tool execution interrupted: {str(e)}\")\n                return _process_error(tool_error)\n\n            except TypeError as e:\n                # Check if this is a missing required argument error\n                error_msg = str(e)\n                if \"missing\" in error_msg and \"required\" in error_msg and \"argument\" in error_msg:\n                    # Add special message for output token limitation\n                    enhanced_error = TypeError(\n                        f\"{error_msg} - this is usually due to running out of output tokens \"\n                        f\"before finishing the message. Try making the function parameters shorter.\"\n                    )\n                    from bots.utils.helpers import _process_error\n\n                    return _process_error(enhanced_error)\n                else:\n                    from bots.utils.helpers import _process_error\n\n                    return _process_error(e)\n            except Exception as e:\n                from bots.utils.helpers import _process_error\n\n                return _process_error(e)\n\n        # Update docstring if description provided\n        if description:\n            wrapper.__doc__ = description\n        elif not wrapper.__doc__:\n            # Generate minimal docstring from function name\n            wrapper.__doc__ = f\"Execute {func.__name__.replace('_', ' ')}\"\n\n        return wrapper\n\n    return decorator\n\n@toolify()\ndef branch_self(self_prompts: str, allow_work: str='False', parallel: str='False', recombine: str='concatenate') -> str:\n    \"\"\"Create multiple conversation branches to explore different approaches or tackle separate tasks.\n\n    Simplified approach that creates isolated conversation branches:\n    1. Save current bot state to temporary file\n    2. Execute each branch with independent bot instances\n    3. Stitch results back into main conversation tree\n    Args:\n        self_prompts (str): List of prompts as a string array, like ['task 1', 'task 2', 'task 3']\n                           Each prompt becomes a separate conversation branch\n        allow_work (str): 'True' to let each branch use tools and continue working until done\n                         'False' (default) for single-response branches\n        parallel (str): 'True' to let branches work in parallel, 'False' for sequential (default).\n        recombine (str): One of ('none', 'concatenate', 'llm_merge', 'llm_vote', 'llm_judge'), default 'concatenate'.\n                         Combines the final messages from each branch using that method.\n\n    Returns:\n        str: Success message with branch count, or error details if something went wrong\n    \"\"\"\n    import os\n    from concurrent.futures import ThreadPoolExecutor, as_completed\n    from bots.flows import functional_prompts as fp\n    from bots.foundation.base import Bot\n    bot = _get_calling_bot()\n    if not bot:\n        return 'Error: Could not find calling bot'\n    allow_work = allow_work.lower() == 'true'\n    parallel = parallel.lower() == 'true'\n    recombine = recombine.lower()\n    valid_recombine_options = ['none', 'concatenate', 'llm_judge', 'llm_vote', 'llm_merge']\n    if recombine not in valid_recombine_options:\n        return f'Error: Invalid recombine option. Valid: {valid_recombine_options}'\n    try:\n        message_list = _process_string_array(self_prompts)\n        if not message_list:\n            return 'Error: No valid messages provided'\n    except Exception as e:\n        return f'Error parsing prompts: {str(e)}'\n    prefixed_prompts = [f'(self-prompt): {prompt}' for prompt in message_list]\n    try:\n        original_node = bot.conversation\n        original_autosave = bot.autosave\n        bot.autosave = False\n        branch_tag = f'_branch_self_anchor_{uuid.uuid4().hex[:8]}'\n        setattr(original_node, branch_tag, True)\n        if original_node.tool_calls:\n            dummy_results = []\n            for tool_call in original_node.tool_calls:\n                if tool_call.get('name') == 'branch_self':\n                    dummy_result = {'tool_use_id': tool_call['id'], 'content': 'Branching in progress...'}\n                    dummy_results.append(dummy_result)\n            if dummy_results:\n                original_results = getattr(original_node, 'tool_results', [])\n                original_node._add_tool_results(dummy_results)\n                temp_id = str(uuid.uuid4())[:8]\n                temp_file = f'branch_self_{temp_id}.bot'\n                bot.save(temp_file)\n                original_node.tool_results = original_results\n            else:\n                temp_id = str(uuid.uuid4())[:8]\n                temp_file = f'branch_self_{temp_id}.bot'\n                bot.save(temp_file)\n        else:\n            temp_id = str(uuid.uuid4())[:8]\n            temp_file = f'branch_self_{temp_id}.bot'\n            bot.save(temp_file)\n\n        def execute_branch(prompt, parent_bot_node):\n            \"\"\"Execute a single branch with the given prompt.\"\"\"\n            try:\n                branch_bot = Bot.load(temp_file)\n                branch_bot.autosave = False\n\n                def find_tagged_node(node):\n                    \"\"\"Recursively search for the node with the branch tag.\"\"\"\n                    for attr in dir(node):\n                        if attr.startswith('_branch_self_anchor_'):\n                            return node\n                    current = node\n                    while current.parent:\n                        current = current.parent\n                        for attr in dir(current):\n                            if attr.startswith('_branch_self_anchor_'):\n                                return current\n                    root = node\n                    while root.parent:\n                        root = root.parent\n\n                    def search_tree(n):\n                        for attr in dir(n):\n                            if attr.startswith('_branch_self_anchor_'):\n                                return n\n                        for reply in n.replies:\n                            result = search_tree(reply)\n                            if result:\n                                return result\n                        return None\n                    return search_tree(root)\n                tagged_node = find_tagged_node(branch_bot.conversation)\n                if tagged_node:\n                    branch_bot.conversation = tagged_node\n                    for attr in dir(tagged_node):\n                        if attr.startswith('_branch_self_anchor_'):\n                            delattr(tagged_node, attr)\n                            break\n                branching_node = branch_bot.conversation\n                if hasattr(branch_bot, 'tool_handler') and branch_bot.tool_handler:\n                    branch_bot.tool_handler.clear()\n                if allow_work:\n                    response = branch_bot.respond(prompt)\n                    while not fp.conditions.tool_not_used(branch_bot):\n                        response = branch_bot.respond('ok')\n                else:\n                    response = branch_bot.respond(prompt)\n                parent_bot_node.replies.extend(branching_node.replies)\n                for node in branching_node.replies:\n                    node.parent = parent_bot_node\n                return (response, branch_bot.conversation)\n            except Exception:\n                import traceback\n                traceback.print_exc()\n                return (None, None)\n        responses = []\n        branch_nodes = []\n        if parallel:\n            with ThreadPoolExecutor() as executor:\n                futures = [executor.submit(execute_branch, prompt, original_node) for prompt in prefixed_prompts]\n                for future in as_completed(futures):\n                    response, node = future.result()\n                    responses.append(response)\n                    branch_nodes.append(node)\n        else:\n            for prompt in prefixed_prompts:\n                response, node = execute_branch(prompt, original_node)\n                responses.append(response)\n                branch_nodes.append(node)\n        if hasattr(original_node, branch_tag):\n            delattr(original_node, branch_tag)\n        bot.autosave = original_autosave\n        try:\n            os.remove(temp_file)\n        except OSError:\n            pass\n        success_count = sum((1 for r in responses if r is not None))\n        combined = 'No recombinator selected'\n        if recombine != 'none' and responses:\n            valid_responses = [r for r in responses if r is not None]\n            if valid_responses:\n                from bots.flows.recombinators import recombinators as recomb\n                if recombine == 'concatenate':\n                    combined, _ = recomb.concatenate(valid_responses, [])\n                elif recombine == 'llm_judge':\n                    combined, _ = recomb.llm_judge(valid_responses, [], judge_bot=bot)\n                elif recombine == 'llm_vote':\n                    combined, _ = recomb.llm_vote(valid_responses, [], vote_bot=bot)\n                elif recombine == 'llm_merge':\n                    combined, _ = recomb.llm_merge(valid_responses, [], merge_bot=bot)\n                else:\n                    combined = 'Unknown recombination method'\n        exec_type = 'parallel' if parallel else 'sequential'\n        work_type = 'iterative' if allow_work else 'single-response'\n        result_content = f'Successfully completed {success_count}/{len(message_list)} {exec_type} {work_type} branches. Recombination result:\\n\\n{combined}'\n        return result_content\n    except Exception as e:\n        import traceback\n        traceback.print_exc()\n        return f'Error in branch_self: {str(e)}'\n\ndef _get_calling_bot() -> Optional[Bot]:\n    \"\"\"Helper function to get a reference to the calling bot.\n    Returns:\n        Optional[Bot]: Reference to the calling bot or None if not found\n    \"\"\"\n    frame = inspect.currentframe()\n    while frame:\n        if frame.f_code.co_name == '_cvsn_respond' and 'self' in frame.f_locals:\n            potential_bot = frame.f_locals['self']\n            if isinstance(potential_bot, Bot):\n                return potential_bot\n        frame = frame.f_back\n    return None\n\ndef _process_string_array(input_str: str) -> List[str]:\n    \"\"\"Parse a string representation of an array into a list of strings.\n    Only works with properly formatted Python list literals.\n    Args:\n        input_str (str): String representation of a Python list literal\n    Returns:\n        List[str]: List of parsed strings\n    Raises:\n        ValueError: If the input is not a valid Python list literal\n    \"\"\"\n    result = ast.literal_eval(input_str)\n    if not isinstance(result, list) or not all((isinstance(x, str) for x in result)):\n        raise ValueError('Input must evaluate to a list of strings')\n    return result",
    "file_path": "dynamic_module_3516398555053604195",
    "code_hash": "95fc62dedb1037e9f60b5e652489bf82",
    "globals": {
     "_convert_tool_inputs": {
      "__helper_func__": true,
      "pickled": "gASVMAAAAAAAAACME2JvdHMuZGV2LmRlY29yYXRvcnOUjBRfY29udmVydF90b29sX2lucHV0c5STlC4=",
      "name": "_convert_tool_inputs"
     },
     "_convert_tool_output": {
      "__helper_func__": true,
      "pickled": "gASVMAAAAAAAAACME2JvdHMuZGV2LmRlY29yYXRvcnOUjBRfY29udmVydF90b29sX291dHB1dJSTlC4=",
      "name": "_convert_tool_output"
     },
     "ast": {
      "__module_type__": true,
      "name": "ast",
      "spec": "ast"
     },
     "datetime": {
      "__module_type__": true,
      "name": "datetime",
      "spec": "datetime"
     },
     "functools": {
      "__module_type__": true,
      "name": "functools",
      "spec": "functools"
     },
     "inspect": {
      "__module_type__": true,
      "name": "inspect",
      "spec": "inspect"
     },
     "logging": {
      "__module_type__": true,
      "name": "logging",
      "spec": "logging"
     },
     "os": {
      "__module_type__": true,
      "name": "os",
      "spec": "os"
     },
     "sys": {
      "__module_type__": true,
      "name": "sys",
      "spec": "sys"
     },
     "textwrap": {
      "__module_type__": true,
      "name": "textwrap",
      "spec": "textwrap"
     },
     "traceback": {
      "__module_type__": true,
      "name": "traceback",
      "spec": "traceback"
     },
     "_get_context": {
      "__helper_func__": true,
      "pickled": "gASVKAAAAAAAAACME2JvdHMuZGV2LmRlY29yYXRvcnOUjAxfZ2V0X2NvbnRleHSUk5Qu",
      "name": "_get_context"
     },
     "_get_py_interface": {
      "__helper_func__": true,
      "pickled": "gASVLQAAAAAAAACME2JvdHMuZGV2LmRlY29yYXRvcnOUjBFfZ2V0X3B5X2ludGVyZmFjZZSTlC4=",
      "name": "_get_py_interface"
     },
     "_convert_string_to_type": {
      "__helper_func__": true,
      "pickled": "gASVMwAAAAAAAACME2JvdHMuZGV2LmRlY29yYXRvcnOUjBdfY29udmVydF9zdHJpbmdfdG9fdHlwZZSTlC4=",
      "name": "_convert_string_to_type"
     },
     "_log_error_to_file": {
      "__helper_func__": true,
      "pickled": "gASVLgAAAAAAAACME2JvdHMuZGV2LmRlY29yYXRvcnOUjBJfbG9nX2Vycm9yX3RvX2ZpbGWUk5Qu",
      "name": "_log_error_to_file"
     },
     "json": {
      "__module_type__": true,
      "name": "json",
      "spec": "json"
     },
     "uuid": {
      "__module_type__": true,
      "name": "uuid",
      "spec": "uuid"
     },
     "_modify_own_settings": {
      "__helper_func__": true,
      "pickled": "gASVMgAAAAAAAACMFWJvdHMudG9vbHMuc2VsZl90b29sc5SMFF9tb2RpZnlfb3duX3NldHRpbmdzlJOULg==",
      "name": "_modify_own_settings"
     },
     "_verbose_callback": {
      "__helper_func__": true,
      "pickled": "gASVLwAAAAAAAACMFWJvdHMudG9vbHMuc2VsZl90b29sc5SMEV92ZXJib3NlX2NhbGxiYWNrlJOULg==",
      "name": "_verbose_callback"
     },
     "_remove_dummy_from_tree": {
      "__helper_func__": true,
      "pickled": "gASVNQAAAAAAAACMFWJvdHMudG9vbHMuc2VsZl90b29sc5SMF19yZW1vdmVfZHVtbXlfZnJvbV90cmVllJOULg==",
      "name": "_remove_dummy_from_tree"
     }
    }
   },
   "dynamic_module_8519542499546822820": {
    "name": "dynamic_module_-844887830895821550",
    "source": "from bots.utils.helpers import _process_error\nfrom typing import List, Optional\n\ndef toolify(description: str = None):\n    \"\"\"\n    Convert any function into a bot tool with string-in, string-out interface.\n\n    - Converts string inputs to proper types using type hints\n    - Ensures string output (JSON for complex types)\n    - Wraps in error handling (returns error strings, never raises)\n    - Enhances docstring if description provided\n\n    Args:\n        description (str, optional): Override the function's docstring\n\n    Example:\n        @toolify()\n        def add_numbers(x: int, y: int = 0) -> int:\n            return x + y\n\n        @toolify(\"Calculate the area of a circle\")\n        def area(radius: float) -> float:\n            return 3.14159 * radius * radius\n    \"\"\"\n\n    def decorator(func):\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            try:\n                # Convert string inputs to proper types using type hints\n                converted_args, converted_kwargs = _convert_tool_inputs(func, args, kwargs)\n\n                # Call original function\n                result = func(*converted_args, **converted_kwargs)\n\n                # Convert result to string\n                return _convert_tool_output(result)\n\n            except KeyboardInterrupt as e:\n                # Convert KeyboardInterrupt to ToolExecutionError to prevent it from\n                # bubbling up to CLI and being treated as user Ctrl+C\n                from bots.utils.helpers import _process_error\n\n                tool_error = ToolExecutionError(f\"Tool execution interrupted: {str(e)}\")\n                return _process_error(tool_error)\n\n            except TypeError as e:\n                # Check if this is a missing required argument error\n                error_msg = str(e)\n                if \"missing\" in error_msg and \"required\" in error_msg and \"argument\" in error_msg:\n                    # Add special message for output token limitation\n                    enhanced_error = TypeError(\n                        f\"{error_msg} - this is usually due to running out of output tokens \"\n                        f\"before finishing the message. Try making the function parameters shorter.\"\n                    )\n                    from bots.utils.helpers import _process_error\n\n                    return _process_error(enhanced_error)\n                else:\n                    from bots.utils.helpers import _process_error\n\n                    return _process_error(e)\n            except Exception as e:\n                from bots.utils.helpers import _process_error\n\n                return _process_error(e)\n\n        # Update docstring if description provided\n        if description:\n            wrapper.__doc__ = description\n        elif not wrapper.__doc__:\n            # Generate minimal docstring from function name\n            wrapper.__doc__ = f\"Execute {func.__name__.replace('_', ' ')}\"\n\n        return wrapper\n\n    return decorator\n\n@toolify()\ndef remove_context(labels: str) -> str:\n    \"\"\"Remove bot-user message pairs from the conversation history.\n\n    Use when you need to delete specific messages from your conversation tree\n    to reduce context or remove irrelevant information. This is a demo tool\n    that removes message pairs by stitching the tree after deletion.\n\n    Note: This tool has limitations with branched conversations and will\n    attempt to handle the simplest case (linear conversation paths).\n\n    Parameters:\n        labels (str): String representation of a list of labels to remove.\n            Format: \"['A', 'B', 'C']\"\n            Use list_context() first to see available labels.\n\n    Returns:\n        str: Success message with count of removed pairs, or error message\n\n    Example:\n        remove_context(\"['A', 'C']\")\n    \"\"\"\n    bot = _get_calling_bot()\n    if not bot:\n        return 'Error: Could not find calling bot'\n    try:\n        label_list = _process_string_array(labels)\n        if not label_list:\n            return 'Error: No valid labels provided'\n    except Exception as e:\n        return f'Error parsing labels: {str(e)}'\n    root = bot.conversation._find_root()\n    bot_nodes = []\n\n    def collect_bot_nodes(node):\n        \"\"\"Recursively collect all bot (assistant) nodes in order.\"\"\"\n        if hasattr(node, 'role') and node.role == 'assistant':\n            bot_nodes.append(node)\n        for reply in node.replies:\n            collect_bot_nodes(reply)\n    collect_bot_nodes(root)\n    if not bot_nodes:\n        return 'Error: No bot messages found in conversation'\n\n    def generate_label(index):\n        \"\"\"Generate Excel-style column labels: A, B, ..., Z, AA, AB, ...\"\"\"\n        label = ''\n        index += 1\n        while index > 0:\n            index -= 1\n            label = chr(65 + index % 26) + label\n            index //= 26\n        return label\n    label_to_node = {}\n    for i, node in enumerate(bot_nodes):\n        label = generate_label(i)\n        label_to_node[label] = node\n    nodes_to_remove = []\n    missing_labels = []\n    for label in label_list:\n        if label in label_to_node:\n            nodes_to_remove.append(label_to_node[label])\n        else:\n            missing_labels.append(label)\n    if missing_labels and (not nodes_to_remove):\n        return f'Error: None of the provided labels were found: {missing_labels}'\n    removed_count = 0\n    errors = []\n    for bot_node in nodes_to_remove:\n        try:\n            if not bot_node.parent:\n                errors.append(f'Cannot remove root node')\n                continue\n            parent = bot_node.parent\n            if len(bot_node.replies) == 0:\n                errors.append(f'Bot node has no child user node to remove')\n                continue\n            if len(bot_node.replies) > 1:\n                errors.append(f'Bot node has multiple children - cannot determine which to remove')\n                continue\n            user_node = bot_node.replies[0]\n            if not (hasattr(user_node, 'role') and user_node.role == 'user'):\n                errors.append(f\"Bot node's child is not a user node\")\n                continue\n            if bot_node in parent.replies:\n                parent.replies.remove(bot_node)\n            for child in user_node.replies:\n                child.parent = parent\n                parent.replies.append(child)\n            current = bot.conversation\n            while current:\n                if current == bot_node or current == user_node:\n                    bot.conversation = parent\n                    break\n                current = current.parent\n            removed_count += 1\n        except Exception as e:\n            errors.append(f'Failed to remove node pair: {str(e)}')\n            continue\n    result_parts = []\n    if removed_count > 0:\n        result_parts.append(f'Successfully removed {removed_count} message pair(s)')\n    if missing_labels:\n        result_parts.append(f'Missing labels: {missing_labels}')\n    if errors:\n        result_parts.append(f\"Errors: {'; '.join(errors)}\")\n    if not result_parts:\n        return 'No messages were removed'\n    return ' | '.join(result_parts)\n\ndef _get_calling_bot() -> Optional[Bot]:\n    \"\"\"Helper function to get a reference to the calling bot.\n    Returns:\n        Optional[Bot]: Reference to the calling bot or None if not found\n    \"\"\"\n    frame = inspect.currentframe()\n    while frame:\n        if frame.f_code.co_name == '_cvsn_respond' and 'self' in frame.f_locals:\n            potential_bot = frame.f_locals['self']\n            if isinstance(potential_bot, Bot):\n                return potential_bot\n        frame = frame.f_back\n    return None\n\ndef _process_string_array(input_str: str) -> List[str]:\n    \"\"\"Parse a string representation of an array into a list of strings.\n    Only works with properly formatted Python list literals.\n    Args:\n        input_str (str): String representation of a Python list literal\n    Returns:\n        List[str]: List of parsed strings\n    Raises:\n        ValueError: If the input is not a valid Python list literal\n    \"\"\"\n    result = ast.literal_eval(input_str)\n    if not isinstance(result, list) or not all((isinstance(x, str) for x in result)):\n        raise ValueError('Input must evaluate to a list of strings')\n    return result",
    "file_path": "dynamic_module_8519542499546822820",
    "code_hash": "f60120c16beefd04fdf0655d87464788",
    "globals": {
     "_convert_tool_inputs": {
      "__helper_func__": true,
      "pickled": "gASVMAAAAAAAAACME2JvdHMuZGV2LmRlY29yYXRvcnOUjBRfY29udmVydF90b29sX2lucHV0c5STlC4=",
      "name": "_convert_tool_inputs"
     },
     "_convert_tool_output": {
      "__helper_func__": true,
      "pickled": "gASVMAAAAAAAAACME2JvdHMuZGV2LmRlY29yYXRvcnOUjBRfY29udmVydF90b29sX291dHB1dJSTlC4=",
      "name": "_convert_tool_output"
     },
     "ast": {
      "__module_type__": true,
      "name": "ast",
      "spec": "ast"
     },
     "datetime": {
      "__module_type__": true,
      "name": "datetime",
      "spec": "datetime"
     },
     "functools": {
      "__module_type__": true,
      "name": "functools",
      "spec": "functools"
     },
     "inspect": {
      "__module_type__": true,
      "name": "inspect",
      "spec": "inspect"
     },
     "logging": {
      "__module_type__": true,
      "name": "logging",
      "spec": "logging"
     },
     "os": {
      "__module_type__": true,
      "name": "os",
      "spec": "os"
     },
     "sys": {
      "__module_type__": true,
      "name": "sys",
      "spec": "sys"
     },
     "textwrap": {
      "__module_type__": true,
      "name": "textwrap",
      "spec": "textwrap"
     },
     "traceback": {
      "__module_type__": true,
      "name": "traceback",
      "spec": "traceback"
     },
     "_get_context": {
      "__helper_func__": true,
      "pickled": "gASVKAAAAAAAAACME2JvdHMuZGV2LmRlY29yYXRvcnOUjAxfZ2V0X2NvbnRleHSUk5Qu",
      "name": "_get_context"
     },
     "_get_py_interface": {
      "__helper_func__": true,
      "pickled": "gASVLQAAAAAAAACME2JvdHMuZGV2LmRlY29yYXRvcnOUjBFfZ2V0X3B5X2ludGVyZmFjZZSTlC4=",
      "name": "_get_py_interface"
     },
     "_convert_string_to_type": {
      "__helper_func__": true,
      "pickled": "gASVMwAAAAAAAACME2JvdHMuZGV2LmRlY29yYXRvcnOUjBdfY29udmVydF9zdHJpbmdfdG9fdHlwZZSTlC4=",
      "name": "_convert_string_to_type"
     },
     "_log_error_to_file": {
      "__helper_func__": true,
      "pickled": "gASVLgAAAAAAAACME2JvdHMuZGV2LmRlY29yYXRvcnOUjBJfbG9nX2Vycm9yX3RvX2ZpbGWUk5Qu",
      "name": "_log_error_to_file"
     },
     "json": {
      "__module_type__": true,
      "name": "json",
      "spec": "json"
     },
     "uuid": {
      "__module_type__": true,
      "name": "uuid",
      "spec": "uuid"
     },
     "_modify_own_settings": {
      "__helper_func__": true,
      "pickled": "gASVMgAAAAAAAACMFWJvdHMudG9vbHMuc2VsZl90b29sc5SMFF9tb2RpZnlfb3duX3NldHRpbmdzlJOULg==",
      "name": "_modify_own_settings"
     },
     "_verbose_callback": {
      "__helper_func__": true,
      "pickled": "gASVLwAAAAAAAACMFWJvdHMudG9vbHMuc2VsZl90b29sc5SMEV92ZXJib3NlX2NhbGxiYWNrlJOULg==",
      "name": "_verbose_callback"
     },
     "_remove_dummy_from_tree": {
      "__helper_func__": true,
      "pickled": "gASVNQAAAAAAAACMFWJvdHMudG9vbHMuc2VsZl90b29sc5SMF19yZW1vdmVfZHVtbXlfZnJvbV90cmVllJOULg==",
      "name": "_remove_dummy_from_tree"
     }
    }
   },
   "dynamic_module_1561770137829577916": {
    "name": "dynamic_module_-1109479255203827417",
    "source": "from bots.utils.helpers import _process_error\nfrom typing import Optional\n\ndef toolify(description: str = None):\n    \"\"\"\n    Convert any function into a bot tool with string-in, string-out interface.\n\n    - Converts string inputs to proper types using type hints\n    - Ensures string output (JSON for complex types)\n    - Wraps in error handling (returns error strings, never raises)\n    - Enhances docstring if description provided\n\n    Args:\n        description (str, optional): Override the function's docstring\n\n    Example:\n        @toolify()\n        def add_numbers(x: int, y: int = 0) -> int:\n            return x + y\n\n        @toolify(\"Calculate the area of a circle\")\n        def area(radius: float) -> float:\n            return 3.14159 * radius * radius\n    \"\"\"\n\n    def decorator(func):\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            try:\n                # Convert string inputs to proper types using type hints\n                converted_args, converted_kwargs = _convert_tool_inputs(func, args, kwargs)\n\n                # Call original function\n                result = func(*converted_args, **converted_kwargs)\n\n                # Convert result to string\n                return _convert_tool_output(result)\n\n            except KeyboardInterrupt as e:\n                # Convert KeyboardInterrupt to ToolExecutionError to prevent it from\n                # bubbling up to CLI and being treated as user Ctrl+C\n                from bots.utils.helpers import _process_error\n\n                tool_error = ToolExecutionError(f\"Tool execution interrupted: {str(e)}\")\n                return _process_error(tool_error)\n\n            except TypeError as e:\n                # Check if this is a missing required argument error\n                error_msg = str(e)\n                if \"missing\" in error_msg and \"required\" in error_msg and \"argument\" in error_msg:\n                    # Add special message for output token limitation\n                    enhanced_error = TypeError(\n                        f\"{error_msg} - this is usually due to running out of output tokens \"\n                        f\"before finishing the message. Try making the function parameters shorter.\"\n                    )\n                    from bots.utils.helpers import _process_error\n\n                    return _process_error(enhanced_error)\n                else:\n                    from bots.utils.helpers import _process_error\n\n                    return _process_error(e)\n            except Exception as e:\n                from bots.utils.helpers import _process_error\n\n                return _process_error(e)\n\n        # Update docstring if description provided\n        if description:\n            wrapper.__doc__ = description\n        elif not wrapper.__doc__:\n            # Generate minimal docstring from function name\n            wrapper.__doc__ = f\"Execute {func.__name__.replace('_', ' ')}\"\n\n        return wrapper\n\n    return decorator\n\n@toolify()\ndef list_context() -> str:\n    \"\"\"List all bot messages in the conversation with labels for removal.\n\n    Use this before remove_context to see what messages are in your conversation.\n    Shows bot messages only (since removal happens in user-bot pairs) with:\n    - A label [A], [B], [C], etc. for reference\n    - Truncated tool calls (if any) with parameters\n    - Truncated response text\n\n    Returns:\n        str: Formatted list of bot messages with labels, or error message\n\n    Example output:\n        [A] Bot: <tool_name param=\"value...\"> | \"Response text...\"\n        [B] Bot: \"Response text without tools...\"\n    \"\"\"\n    bot = _get_calling_bot()\n    if not bot:\n        return 'Error: Could not find calling bot'\n    root = bot.conversation._find_root()\n    bot_nodes = []\n\n    def collect_bot_nodes(node):\n        \"\"\"Recursively collect all bot (assistant) nodes in order.\"\"\"\n        if hasattr(node, 'role') and node.role == 'assistant':\n            bot_nodes.append(node)\n        for reply in node.replies:\n            collect_bot_nodes(reply)\n    collect_bot_nodes(root)\n    if not bot_nodes:\n        return 'No bot messages found in conversation'\n\n    def generate_label(index):\n        \"\"\"Generate Excel-style column labels: A, B, ..., Z, AA, AB, ...\"\"\"\n        label = ''\n        index += 1\n        while index > 0:\n            index -= 1\n            label = chr(65 + index % 26) + label\n            index //= 26\n        return label\n    lines = []\n    for i, node in enumerate(bot_nodes):\n        label = generate_label(i)\n        parts = []\n        if hasattr(node, 'tool_calls') and node.tool_calls:\n            tool_strs = []\n            for tool_call in node.tool_calls:\n                tool_name = tool_call.get('name', 'unknown')\n                tool_input = tool_call.get('input', {})\n                if isinstance(tool_input, dict):\n                    param_parts = []\n                    for key, value in tool_input.items():\n                        value_str = str(value)\n                        if len(value_str) > 20:\n                            value_str = value_str[:20] + '...'\n                        param_parts.append(f'{key}={value_str}')\n                    params_str = ', '.join(param_parts)\n                else:\n                    params_str = str(tool_input)\n                    if len(params_str) > 20:\n                        params_str = params_str[:20] + '...'\n                tool_strs.append(f'<{tool_name} {params_str}>')\n            parts.append(' '.join(tool_strs))\n        if hasattr(node, 'content') and node.content:\n            content = node.content.replace('\\n', ' ')\n            if len(content) > 50:\n                content = content[:50] + '...'\n            parts.append(f'\"{content}\"')\n        if parts:\n            message_str = ' | '.join(parts)\n        else:\n            message_str = '<empty message>'\n        lines.append(f'[{label}] Bot: {message_str}')\n    return '\\n'.join(lines)\n\ndef _get_calling_bot() -> Optional[Bot]:\n    \"\"\"Helper function to get a reference to the calling bot.\n    Returns:\n        Optional[Bot]: Reference to the calling bot or None if not found\n    \"\"\"\n    frame = inspect.currentframe()\n    while frame:\n        if frame.f_code.co_name == '_cvsn_respond' and 'self' in frame.f_locals:\n            potential_bot = frame.f_locals['self']\n            if isinstance(potential_bot, Bot):\n                return potential_bot\n        frame = frame.f_back\n    return None",
    "file_path": "dynamic_module_1561770137829577916",
    "code_hash": "663c4426732f0b1694df97decf39d8e4",
    "globals": {
     "_convert_tool_inputs": {
      "__helper_func__": true,
      "pickled": "gASVMAAAAAAAAACME2JvdHMuZGV2LmRlY29yYXRvcnOUjBRfY29udmVydF90b29sX2lucHV0c5STlC4=",
      "name": "_convert_tool_inputs"
     },
     "_convert_tool_output": {
      "__helper_func__": true,
      "pickled": "gASVMAAAAAAAAACME2JvdHMuZGV2LmRlY29yYXRvcnOUjBRfY29udmVydF90b29sX291dHB1dJSTlC4=",
      "name": "_convert_tool_output"
     },
     "ast": {
      "__module_type__": true,
      "name": "ast",
      "spec": "ast"
     },
     "datetime": {
      "__module_type__": true,
      "name": "datetime",
      "spec": "datetime"
     },
     "functools": {
      "__module_type__": true,
      "name": "functools",
      "spec": "functools"
     },
     "inspect": {
      "__module_type__": true,
      "name": "inspect",
      "spec": "inspect"
     },
     "logging": {
      "__module_type__": true,
      "name": "logging",
      "spec": "logging"
     },
     "os": {
      "__module_type__": true,
      "name": "os",
      "spec": "os"
     },
     "sys": {
      "__module_type__": true,
      "name": "sys",
      "spec": "sys"
     },
     "textwrap": {
      "__module_type__": true,
      "name": "textwrap",
      "spec": "textwrap"
     },
     "traceback": {
      "__module_type__": true,
      "name": "traceback",
      "spec": "traceback"
     },
     "_get_context": {
      "__helper_func__": true,
      "pickled": "gASVKAAAAAAAAACME2JvdHMuZGV2LmRlY29yYXRvcnOUjAxfZ2V0X2NvbnRleHSUk5Qu",
      "name": "_get_context"
     },
     "_get_py_interface": {
      "__helper_func__": true,
      "pickled": "gASVLQAAAAAAAACME2JvdHMuZGV2LmRlY29yYXRvcnOUjBFfZ2V0X3B5X2ludGVyZmFjZZSTlC4=",
      "name": "_get_py_interface"
     },
     "_convert_string_to_type": {
      "__helper_func__": true,
      "pickled": "gASVMwAAAAAAAACME2JvdHMuZGV2LmRlY29yYXRvcnOUjBdfY29udmVydF9zdHJpbmdfdG9fdHlwZZSTlC4=",
      "name": "_convert_string_to_type"
     },
     "_log_error_to_file": {
      "__helper_func__": true,
      "pickled": "gASVLgAAAAAAAACME2JvdHMuZGV2LmRlY29yYXRvcnOUjBJfbG9nX2Vycm9yX3RvX2ZpbGWUk5Qu",
      "name": "_log_error_to_file"
     },
     "json": {
      "__module_type__": true,
      "name": "json",
      "spec": "json"
     },
     "uuid": {
      "__module_type__": true,
      "name": "uuid",
      "spec": "uuid"
     },
     "_modify_own_settings": {
      "__helper_func__": true,
      "pickled": "gASVMgAAAAAAAACMFWJvdHMudG9vbHMuc2VsZl90b29sc5SMFF9tb2RpZnlfb3duX3NldHRpbmdzlJOULg==",
      "name": "_modify_own_settings"
     },
     "_process_string_array": {
      "__helper_func__": true,
      "pickled": "gASVMwAAAAAAAACMFWJvdHMudG9vbHMuc2VsZl90b29sc5SMFV9wcm9jZXNzX3N0cmluZ19hcnJheZSTlC4=",
      "name": "_process_string_array"
     },
     "_verbose_callback": {
      "__helper_func__": true,
      "pickled": "gASVLwAAAAAAAACMFWJvdHMudG9vbHMuc2VsZl90b29sc5SMEV92ZXJib3NlX2NhbGxiYWNrlJOULg==",
      "name": "_verbose_callback"
     },
     "_remove_dummy_from_tree": {
      "__helper_func__": true,
      "pickled": "gASVNQAAAAAAAACMFWJvdHMudG9vbHMuc2VsZl90b29sc5SMF19yZW1vdmVfZHVtbXlfZnJvbV90cmVllJOULg==",
      "name": "_remove_dummy_from_tree"
     }
    }
   },
   "dynamic_module_2308802714246007567": {
    "name": "dynamic_module_1530100030158944457",
    "source": "from bots.utils.helpers import _process_error\n\ndef toolify(description: str = None):\n    \"\"\"\n    Convert any function into a bot tool with string-in, string-out interface.\n\n    - Converts string inputs to proper types using type hints\n    - Ensures string output (JSON for complex types)\n    - Wraps in error handling (returns error strings, never raises)\n    - Enhances docstring if description provided\n\n    Args:\n        description (str, optional): Override the function's docstring\n\n    Example:\n        @toolify()\n        def add_numbers(x: int, y: int = 0) -> int:\n            return x + y\n\n        @toolify(\"Calculate the area of a circle\")\n        def area(radius: float) -> float:\n            return 3.14159 * radius * radius\n    \"\"\"\n\n    def decorator(func):\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            try:\n                # Convert string inputs to proper types using type hints\n                converted_args, converted_kwargs = _convert_tool_inputs(func, args, kwargs)\n\n                # Call original function\n                result = func(*converted_args, **converted_kwargs)\n\n                # Convert result to string\n                return _convert_tool_output(result)\n\n            except KeyboardInterrupt as e:\n                # Convert KeyboardInterrupt to ToolExecutionError to prevent it from\n                # bubbling up to CLI and being treated as user Ctrl+C\n                from bots.utils.helpers import _process_error\n\n                tool_error = ToolExecutionError(f\"Tool execution interrupted: {str(e)}\")\n                return _process_error(tool_error)\n\n            except TypeError as e:\n                # Check if this is a missing required argument error\n                error_msg = str(e)\n                if \"missing\" in error_msg and \"required\" in error_msg and \"argument\" in error_msg:\n                    # Add special message for output token limitation\n                    enhanced_error = TypeError(\n                        f\"{error_msg} - this is usually due to running out of output tokens \"\n                        f\"before finishing the message. Try making the function parameters shorter.\"\n                    )\n                    from bots.utils.helpers import _process_error\n\n                    return _process_error(enhanced_error)\n                else:\n                    from bots.utils.helpers import _process_error\n\n                    return _process_error(e)\n            except Exception as e:\n                from bots.utils.helpers import _process_error\n\n                return _process_error(e)\n\n        # Update docstring if description provided\n        if description:\n            wrapper.__doc__ = description\n        elif not wrapper.__doc__:\n            # Generate minimal docstring from function name\n            wrapper.__doc__ = f\"Execute {func.__name__.replace('_', ' ')}\"\n\n        return wrapper\n\n    return decorator\n\n@toolify(\"Perform an agentic web search using Claude's internal web search capabilities\")\ndef web_search(question: str) -> str:\n    \"\"\"Perform an intelligent web search and return organized results.\n\n    This tool uses Claude's built-in web search functionality to perform searches\n    and returns organized, pertinent information extracted from the results.\n\n    Args:\n        question (str): The search goal framed as a question.\n        Good examples:\n            \"Who is Ben Rinauto?\"\n            \"What is the connection between Paris, France and Buffalo, NY?\"\n        Bad examples:\n            \"Ben R wrestling\"\n            \"paris buffalo\"\n\n    Returns:\n        str: Organized search results with key information extracted\n    \"\"\"\n    try:\n        _validate_question_format(question)\n        api_key = os.getenv('ANTHROPIC_API_KEY')\n        if not api_key:\n            return 'Error: ANTHROPIC_API_KEY environment variable not set'\n        client = anthropic.Anthropic(api_key=api_key)\n        tools = [{'type': 'web_search_20250305', 'name': 'web_search', 'max_uses': 10}]\n        search_prompt = f'I need you to search the web answers to this question: \"{question}\"\\n\\n        Please use the web search tool to find current, relevant information to precisely and\\n        accurately answer this question.'\n        response = client.messages.create(model='claude-opus-4-1', max_tokens=16384, temperature=0.3, tools=tools, messages=[{'role': 'user', 'content': search_prompt}])\n\n        def extract_clean_content(response):\n            \"\"\"Extract only the essential content from web search response.\"\"\"\n            result = []\n            result.append('=== WEB SEARCH RESULTS ===\\n')\n            result.append(f'Search: \"{question}\"\\n')\n            if hasattr(response, 'content') and response.content:\n                text_responses = []\n                search_results = []\n                for block in response.content:\n                    if hasattr(block, 'type') and block.type == 'text' and hasattr(block, 'text') and block.text:\n                        text_responses.append(block.text)\n                    elif hasattr(block, 'type') and block.type == 'web_search_tool_result':\n                        if hasattr(block, 'content') and block.content:\n                            for item in block.content:\n                                if isinstance(item, dict) and item.get('type') == 'web_search_result':\n                                    search_results.append({'title': item.get('title', 'No title'), 'url': item.get('url', 'No URL'), 'age': item.get('page_age', 'Unknown age')})\n                if text_responses:\n                    result.append(\"=== CLAUDE'S ANALYSIS ===\\n\")\n                    for i, text in enumerate(text_responses, 1):\n                        result.append(f'{i}. {text}\\n')\n                    result.append('')\n                if search_results:\n                    result.append('=== SOURCES FOUND ===\\n')\n                    for i, item in enumerate(search_results, 1):\n                        result.append(f\"{i}. {item['title']}\")\n                        result.append(f\"   {item['url']}\")\n                        if item['age'] and item['age'] != 'Unknown age':\n                            result.append(f\"   ({item['age']})\")\n                        result.append('')\n                result.append(f\"Search performed: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M UTC')}\")\n            return '\\n'.join(result)\n        clean_content = extract_clean_content(response)\n        return clean_content\n    except Exception as e:\n        return f'Web search failed: {str(e)}'\n\ndef _validate_question_format(query: str) -> bool:\n    \"\"\"Use a simple Haiku bot to validate if input is formatted as a question.\n\n    Args:\n        query (str): The input query to validate\n\n    Returns:\n        bool: True if formatted as a question, False otherwise\n\n    Raises:\n        ValueError: If query is not formatted as a question\n    \"\"\"\n    try:\n        api_key = os.getenv('ANTHROPIC_API_KEY')\n        if not api_key:\n            return True\n        client = anthropic.Anthropic(api_key=api_key)\n        validation_prompt = f'Is this text formatted as a question? Answer only Y or N.\\n\\nText: \"{query}\"\\n\\nAnswer:'\n        response = client.messages.create(model='claude-3-haiku-20240307', max_tokens=10, temperature=0.0, messages=[{'role': 'user', 'content': validation_prompt}])\n        answer = response.content[0].text.strip().upper()\n        if answer.startswith('N'):\n            raise ValueError(\"Input queries must be formatted as questions. Good examples: 'Who is...?', 'What is...?', 'How does...?' Bad examples: 'Ben R wrestling', 'paris buffalo'The more information, and the more specific, the better. You are asking an AI to answer a question, not performing a traditional web keyword search.\")\n        return True\n    except ValueError:\n        raise\n    except Exception:\n        return True",
    "file_path": "dynamic_module_2308802714246007567",
    "code_hash": "da6cd7163e652f16f8b0ad248f04a418",
    "globals": {
     "_convert_tool_inputs": {
      "__helper_func__": true,
      "pickled": "gASVMAAAAAAAAACME2JvdHMuZGV2LmRlY29yYXRvcnOUjBRfY29udmVydF90b29sX2lucHV0c5STlC4=",
      "name": "_convert_tool_inputs"
     },
     "_convert_tool_output": {
      "__helper_func__": true,
      "pickled": "gASVMAAAAAAAAACME2JvdHMuZGV2LmRlY29yYXRvcnOUjBRfY29udmVydF90b29sX291dHB1dJSTlC4=",
      "name": "_convert_tool_output"
     },
     "ast": {
      "__module_type__": true,
      "name": "ast",
      "spec": "ast"
     },
     "datetime": {
      "__module_type__": true,
      "name": "datetime",
      "spec": "datetime"
     },
     "functools": {
      "__module_type__": true,
      "name": "functools",
      "spec": "functools"
     },
     "inspect": {
      "__module_type__": true,
      "name": "inspect",
      "spec": "inspect"
     },
     "logging": {
      "__module_type__": true,
      "name": "logging",
      "spec": "logging"
     },
     "os": {
      "__module_type__": true,
      "name": "os",
      "spec": "os"
     },
     "sys": {
      "__module_type__": true,
      "name": "sys",
      "spec": "sys"
     },
     "textwrap": {
      "__module_type__": true,
      "name": "textwrap",
      "spec": "textwrap"
     },
     "traceback": {
      "__module_type__": true,
      "name": "traceback",
      "spec": "traceback"
     },
     "_get_context": {
      "__helper_func__": true,
      "pickled": "gASVKAAAAAAAAACME2JvdHMuZGV2LmRlY29yYXRvcnOUjAxfZ2V0X2NvbnRleHSUk5Qu",
      "name": "_get_context"
     },
     "_get_py_interface": {
      "__helper_func__": true,
      "pickled": "gASVLQAAAAAAAACME2JvdHMuZGV2LmRlY29yYXRvcnOUjBFfZ2V0X3B5X2ludGVyZmFjZZSTlC4=",
      "name": "_get_py_interface"
     },
     "_convert_string_to_type": {
      "__helper_func__": true,
      "pickled": "gASVMwAAAAAAAACME2JvdHMuZGV2LmRlY29yYXRvcnOUjBdfY29udmVydF9zdHJpbmdfdG9fdHlwZZSTlC4=",
      "name": "_convert_string_to_type"
     },
     "_log_error_to_file": {
      "__helper_func__": true,
      "pickled": "gASVLgAAAAAAAACME2JvdHMuZGV2LmRlY29yYXRvcnOUjBJfbG9nX2Vycm9yX3RvX2ZpbGWUk5Qu",
      "name": "_log_error_to_file"
     },
     "anthropic": {
      "__module_type__": true,
      "name": "anthropic",
      "spec": "anthropic"
     }
    }
   },
   "dynamic_module_3019238725971262868": {
    "name": "dynamic_module_-65348588349682347",
    "source": "import textwrap\nfrom bots.utils.helpers import _process_error\nfrom typing import List\n\ndef toolify(description: str = None):\n    \"\"\"\n    Convert any function into a bot tool with string-in, string-out interface.\n\n    - Converts string inputs to proper types using type hints\n    - Ensures string output (JSON for complex types)\n    - Wraps in error handling (returns error strings, never raises)\n    - Enhances docstring if description provided\n\n    Args:\n        description (str, optional): Override the function's docstring\n\n    Example:\n        @toolify()\n        def add_numbers(x: int, y: int = 0) -> int:\n            return x + y\n\n        @toolify(\"Calculate the area of a circle\")\n        def area(radius: float) -> float:\n            return 3.14159 * radius * radius\n    \"\"\"\n\n    def decorator(func):\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            try:\n                # Convert string inputs to proper types using type hints\n                converted_args, converted_kwargs = _convert_tool_inputs(func, args, kwargs)\n\n                # Call original function\n                result = func(*converted_args, **converted_kwargs)\n\n                # Convert result to string\n                return _convert_tool_output(result)\n\n            except KeyboardInterrupt as e:\n                # Convert KeyboardInterrupt to ToolExecutionError to prevent it from\n                # bubbling up to CLI and being treated as user Ctrl+C\n                from bots.utils.helpers import _process_error\n\n                tool_error = ToolExecutionError(f\"Tool execution interrupted: {str(e)}\")\n                return _process_error(tool_error)\n\n            except TypeError as e:\n                # Check if this is a missing required argument error\n                error_msg = str(e)\n                if \"missing\" in error_msg and \"required\" in error_msg and \"argument\" in error_msg:\n                    # Add special message for output token limitation\n                    enhanced_error = TypeError(\n                        f\"{error_msg} - this is usually due to running out of output tokens \"\n                        f\"before finishing the message. Try making the function parameters shorter.\"\n                    )\n                    from bots.utils.helpers import _process_error\n\n                    return _process_error(enhanced_error)\n                else:\n                    from bots.utils.helpers import _process_error\n\n                    return _process_error(e)\n            except Exception as e:\n                from bots.utils.helpers import _process_error\n\n                return _process_error(e)\n\n        # Update docstring if description provided\n        if description:\n            wrapper.__doc__ = description\n        elif not wrapper.__doc__:\n            # Generate minimal docstring from function name\n            wrapper.__doc__ = f\"Execute {func.__name__.replace('_', ' ')}\"\n\n        return wrapper\n\n    return decorator\n\n@toolify()\ndef python_edit(target_scope: str, code: str, *, coscope_with: str=None, delete_a_lot: bool=False) -> str:\n    \"\"\"\n        Edit Python code using pytest-style scope syntax and optional expression matching.\n\n        Parameters:\n        -----------\n        target_scope : str\n            Location to edit in pytest-style scope syntax:\n            - \"file.py\" (whole file)\n            - \"file.py::MyClass\" (class)\n            - \"file.py::my_function\" (function)\n            - \"file.py::MyClass::method\" (method)\n\n        code : str\n            Python code. This code will replace the entire target scope by default,\n            or insert after (if coscope_with is specified). Code is indented automatically\n            to match to scope.\n\n        coscope_with : str, optional\n            If specified, code is inserted in the same scope as the specified code,\n            and immediately after it. Uses the same syntax as target_scope with\n            optional expression at the end in quotes.\n\n\n                Scope:\n                    - a\n                    - b\n\n                - python edit called with coscope_with = \"a\", code = \"- c\" -\n\n                Scope:\n                    - a\n                    - c\n                    - b\n\n            - \"__FILE_START__\" (special token for file beginning)\n            - \"MyClass::method\" (insert after this method within the target scope)\n            - '\"expression\"' (insert after a line matching this expression)\n        delete_a_lot : bool, optional\n    - \"__FILE_END__\" (special token for file end)\n            Safety parameter. Must be True to allow operations that delete more than 100 lines.\n            Helps prevent accidental file overwrites. Default False.\n\n        Returns:\n        --------\n        str\n            Description of what was modified or error message\n    \"\"\"\n    try:\n        file_path, *path_elements = target_scope.split('::')\n        if not file_path.endswith('.py'):\n            return _process_error(ValueError(f'File path must end with .py: {file_path}'))\n        for element in path_elements:\n            if not element.isidentifier():\n                return _process_error(ValueError(f'Invalid identifier in path: {element}'))\n        abs_path = _make_file(file_path)\n        try:\n            original_content = _read_file_bom_safe(abs_path)\n            was_originally_empty = not original_content.strip()\n        except Exception as e:\n            return _process_error(ValueError(f'Error reading file {abs_path}: {str(e)}'))\n        try:\n            if original_content.strip():\n                tree = cst.parse_module(original_content)\n            else:\n                tree = cst.parse_module('')\n        except Exception as e:\n            return _process_error(ValueError(f'Error parsing file {abs_path}: {str(e)}'))\n        try:\n            import textwrap\n            cleaned_code = textwrap.dedent(code).strip()\n            if not cleaned_code:\n                if coscope_with:\n                    return _process_error(ValueError('Cannot use empty code with insert_after - nothing to insert'))\n                return _handle_deletion(abs_path, target_scope, path_elements, original_content, tree, delete_a_lot)\n            elif was_originally_empty and (not path_elements):\n                _write_file_bom_safe(abs_path, cleaned_code)\n                return f\"Code added to '{abs_path}'.\"\n            new_module = None\n            if cleaned_code:\n                try:\n                    new_module = cst.parse_module(cleaned_code)\n                except Exception as e:\n                    if cleaned_code.strip().startswith('#'):\n                        comment_stmt = _create_statement_with_comment(cleaned_code.strip())\n                        new_module = cst.Module(body=[comment_stmt])\n                    else:\n                        return _process_error(ValueError(f'Error parsing new code: {str(e)}'))\n        except Exception as e:\n            return _process_error(ValueError(f'Error processing new code: {str(e)}'))\n        if coscope_with == '__FILE_START__':\n            return _handle_file_start_insertion(abs_path, tree, new_module)\n        elif coscope_with == '__FILE_END__':\n            return _handle_file_end_insertion(abs_path, tree, new_module)\n        elif not path_elements:\n            if coscope_with:\n                return _handle_file_level_insertion(abs_path, tree, new_module, coscope_with)\n            else:\n                lines_to_delete = _count_lines_to_be_deleted(original_content, cleaned_code)\n                if lines_to_delete > 100 and (not delete_a_lot):\n                    return _process_error(ValueError(f'Safety check: this operation would delete {lines_to_delete} lines. ' + \"If intentional, set delete_a_lot=True. Consider using 'insert_after' parameter to add code without deleting existing content.\"))\n                _write_file_bom_safe(abs_path, cleaned_code)\n                return f\"Code replaced at file level in '{abs_path}'.\"\n        else:\n            replacer = ScopeReplacer(path_elements, new_module, coscope_with, tree)\n            modified_tree = tree.visit(replacer)\n            if not replacer.modified:\n                if coscope_with:\n                    return _process_error(ValueError(f'Insert point not found: {coscope_with}'))\n                else:\n                    return _process_error(ValueError(f'Target scope not found: {target_scope}'))\n            _write_file_bom_safe(abs_path, modified_tree.code)\n            if coscope_with:\n                return f\"Code inserted after '{coscope_with}' in '{abs_path}'.\"\n            else:\n                return f\"Code replaced at '{target_scope}'.\"\n    except Exception as e:\n        return _process_error(e)\n\ndef _handle_file_end_insertion(abs_path: str, tree: cst.Module, new_module: cst.Module) -> str:\n    \"\"\"Handle insertion at the end of a file.\"\"\"\n    if len(new_module.body) == 0 and new_module.code.strip():\n        comment_stmt = _create_statement_with_comment(new_module.code.strip())\n        new_body = list(tree.body) + [comment_stmt]\n    else:\n        new_body = list(tree.body) + list(new_module.body)\n    modified_tree = tree.with_changes(body=new_body)\n    final_code = modified_tree.code\n    if final_code and (not final_code.endswith('\\n')):\n        final_code += '\\n'\n    _write_file_bom_safe(abs_path, final_code)\n    return f\"Code inserted at end of '{abs_path}'.\"\n\ndef _make_file(file_path: str) -> str:\n    \"\"\"\n    Create a file and its parent directories if they don't exist.\n\n    Parameters:\n    -----------\n    file_path : str\n        Path to the file to create\n\n    Returns:\n    --------\n    str\n        Absolute path to the created/existing file\n\n    Raises:\n    -------\n    ValueError\n        If there's an error creating the file or directories\n    \"\"\"\n    if not file_path:\n        raise ValueError('File path cannot be empty')\n    abs_path = os.path.abspath(file_path)\n    dir_path = os.path.dirname(abs_path)\n    if dir_path:\n        try:\n            os.makedirs(dir_path, exist_ok=True)\n        except Exception as e:\n            raise ValueError(f'Error creating directories {dir_path}: {str(e)}')\n    if not os.path.exists(abs_path):\n        try:\n            with open(abs_path, 'w', encoding='utf-8') as f:\n                f.write('')\n        except Exception as e:\n            raise ValueError(f'Error creating file {abs_path}: {str(e)}')\n    return abs_path\n\ndef _read_file_bom_safe(file_path: str) -> str:\n    \"\"\"Read a file with BOM protection.\"\"\"\n    with open(file_path, 'r', encoding='utf-8') as file:\n        content = file.read()\n    return clean_unicode_string(content)\n\ndef _write_file_bom_safe(file_path: str, content: str) -> None:\n    \"\"\"Write a file with BOM protection.\"\"\"\n    ends_with_newline = content.endswith('\\n')\n    clean_content = clean_unicode_string(content)\n    if ends_with_newline and (not clean_content.endswith('\\n')):\n        clean_content += '\\n'\n    with open(file_path, 'w', encoding='utf-8') as file:\n        file.write(clean_content)\n\ndef _handle_file_start_insertion(abs_path: str, tree: cst.Module, new_module: cst.Module) -> str:\n    \"\"\"Handle insertion at the beginning of a file.\"\"\"\n    new_body = list(new_module.body) + list(tree.body)\n    modified_tree = tree.with_changes(body=new_body)\n    _write_file_bom_safe(abs_path, modified_tree.code)\n    return f\"Code inserted at start of '{abs_path}'.\"\n\ndef _handle_deletion(abs_path: str, target_scope: str, path_elements: list, original_content: str, tree: cst.Module, delete_a_lot: bool=False) -> str:\n    \"\"\"Handle deletion of a target section when empty code is provided.\"\"\"\n    try:\n        lines_to_delete = _count_lines_to_be_deleted(original_content, '')\n        if lines_to_delete > 100 and (not delete_a_lot):\n            return _process_error(ValueError(f'Safety check: this operation would delete {lines_to_delete} lines. ' + \"If intentional, set delete_a_lot=True. Consider using 'insert_after' parameter to add code without deleting existing content.\"))\n        if not path_elements:\n            _write_file_bom_safe(abs_path, '')\n            return f\"File '{abs_path}' cleared (deleted all content).\"\n        else:\n            deleter = ScopeDeleter(path_elements)\n            modified_tree = tree.visit(deleter)\n            if not deleter.modified:\n                return _process_error(ValueError(f'Target scope not found for deletion: {target_scope}'))\n            _write_file_bom_safe(abs_path, modified_tree.code)\n            return f\"Deleted scope '{target_scope}' from '{abs_path}'.\"\n    except Exception as e:\n        return _process_error(e)\n\ndef _create_statement_with_comment(comment_text: str, indent_level: int=0) -> cst.SimpleStatementLine:\n    \"\"\"\n    Create a statement that contains just a comment.\n    Since LibCST requires statements to have actual code, we create a pass statement\n    with a trailing comment.\n    \"\"\"\n    lines = comment_text.strip().split('\\n')\n    if len(lines) > 1:\n        comment_text = lines[0]\n    comment_text = comment_text.strip()\n    if comment_text.startswith('#'):\n        comment_text = comment_text[1:].strip()\n    comment = cst.Comment(f'# {comment_text}')\n    return cst.SimpleStatementLine(body=[cst.Pass()], trailing_whitespace=cst.TrailingWhitespace(whitespace=cst.SimpleWhitespace('  '), comment=comment))\n\ndef _handle_file_level_insertion(abs_path: str, tree: cst.Module, new_module: cst.Module, insert_after: str) -> str:\n    \"\"\"Handle insertion at file level after a specific pattern.\"\"\"\n    pattern = insert_after.strip()\n    if pattern.startswith('\"') and pattern.endswith('\"') or (pattern.startswith(\"'\") and pattern.endswith(\"'\")):\n        pattern = pattern[1:-1]\n\n    class FileOnlyInserter(cst.CSTTransformer):\n\n        def __init__(self, pattern: str, new_nodes: List[cst.CSTNode]):\n            self.pattern = pattern.strip()\n            self.new_nodes = new_nodes\n            self.modified = False\n\n        def leave_Module(self, original_node: cst.Module, updated_node: cst.Module) -> cst.Module:\n            new_body = []\n            for stmt in updated_node.body:\n                new_body.append(stmt)\n                match_found = False\n                if isinstance(stmt, (cst.FunctionDef, cst.ClassDef)) and stmt.name.value == self.pattern:\n                    match_found = True\n                else:\n                    try:\n                        stmt_code = updated_node.code_for_node(stmt).strip()\n                        if self.pattern in stmt_code:\n                            match_found = True\n                    except Exception:\n                        pass\n                if match_found:\n                    new_body.extend(self.new_nodes)\n                    self.modified = True\n            if self.modified:\n                return updated_node.with_changes(body=new_body)\n            return updated_node\n    inserter = FileOnlyInserter(pattern, new_module.body)\n    modified_tree = tree.visit(inserter)\n    if not inserter.modified:\n        return _process_error(ValueError(f'Insert point not found at file level: {insert_after}'))\n    _write_file_bom_safe(abs_path, modified_tree.code)\n    return f\"Code inserted after '{insert_after}' in '{abs_path}'.\"\n\ndef _count_lines_to_be_deleted(original_content: str, new_content: str) -> int:\n    \"\"\"\n    Count how many lines would be deleted by comparing original vs new content.\n\n    Parameters:\n    -----------\n    original_content : str\n        The original file content\n    new_content : str\n        The new content that would replace it\n\n    Returns:\n    --------\n    int\n        Number of lines that would be deleted\n    \"\"\"\n    original_lines = len(original_content.splitlines()) if original_content.strip() else 0\n    new_lines = len(new_content.splitlines()) if new_content.strip() else 0\n    return max(0, original_lines - new_lines)",
    "file_path": "dynamic_module_3019238725971262868",
    "code_hash": "6cd01668e833921479d5801523d8d80b",
    "globals": {
     "_convert_tool_inputs": {
      "__helper_func__": true,
      "pickled": "gASVMAAAAAAAAACME2JvdHMuZGV2LmRlY29yYXRvcnOUjBRfY29udmVydF90b29sX2lucHV0c5STlC4=",
      "name": "_convert_tool_inputs"
     },
     "_convert_tool_output": {
      "__helper_func__": true,
      "pickled": "gASVMAAAAAAAAACME2JvdHMuZGV2LmRlY29yYXRvcnOUjBRfY29udmVydF90b29sX291dHB1dJSTlC4=",
      "name": "_convert_tool_output"
     },
     "ast": {
      "__module_type__": true,
      "name": "ast",
      "spec": "ast"
     },
     "datetime": {
      "__module_type__": true,
      "name": "datetime",
      "spec": "datetime"
     },
     "functools": {
      "__module_type__": true,
      "name": "functools",
      "spec": "functools"
     },
     "inspect": {
      "__module_type__": true,
      "name": "inspect",
      "spec": "inspect"
     },
     "logging": {
      "__module_type__": true,
      "name": "logging",
      "spec": "logging"
     },
     "os": {
      "__module_type__": true,
      "name": "os",
      "spec": "os"
     },
     "sys": {
      "__module_type__": true,
      "name": "sys",
      "spec": "sys"
     },
     "textwrap": {
      "__module_type__": true,
      "name": "textwrap",
      "spec": "textwrap"
     },
     "traceback": {
      "__module_type__": true,
      "name": "traceback",
      "spec": "traceback"
     },
     "_get_context": {
      "__helper_func__": true,
      "pickled": "gASVKAAAAAAAAACME2JvdHMuZGV2LmRlY29yYXRvcnOUjAxfZ2V0X2NvbnRleHSUk5Qu",
      "name": "_get_context"
     },
     "_get_py_interface": {
      "__helper_func__": true,
      "pickled": "gASVLQAAAAAAAACME2JvdHMuZGV2LmRlY29yYXRvcnOUjBFfZ2V0X3B5X2ludGVyZmFjZZSTlC4=",
      "name": "_get_py_interface"
     },
     "_convert_string_to_type": {
      "__helper_func__": true,
      "pickled": "gASVMwAAAAAAAACME2JvdHMuZGV2LmRlY29yYXRvcnOUjBdfY29udmVydF9zdHJpbmdfdG9fdHlwZZSTlC4=",
      "name": "_convert_string_to_type"
     },
     "_log_error_to_file": {
      "__helper_func__": true,
      "pickled": "gASVLgAAAAAAAACME2JvdHMuZGV2LmRlY29yYXRvcnOUjBJfbG9nX2Vycm9yX3RvX2ZpbGWUk5Qu",
      "name": "_log_error_to_file"
     },
     "cst": {
      "__module_type__": true,
      "name": "libcst",
      "spec": "libcst"
     },
     "_process_error": {
      "__helper_func__": true,
      "pickled": "gASVKQAAAAAAAACMEmJvdHMudXRpbHMuaGVscGVyc5SMDl9wcm9jZXNzX2Vycm9ylJOULg==",
      "name": "_process_error"
     },
     "_py_ast_to_source": {
      "__helper_func__": true,
      "pickled": "gASVLAAAAAAAAACMEmJvdHMudXRpbHMuaGVscGVyc5SMEV9weV9hc3RfdG9fc291cmNllJOULg==",
      "name": "_py_ast_to_source"
     },
     "_apply_scope_aware_truncation": {
      "__helper_func__": true,
      "pickled": "gASVPAAAAAAAAACMFmJvdHMudG9vbHMucHl0aG9uX2VkaXSUjB1fYXBwbHlfc2NvcGVfYXdhcmVfdHJ1bmNhdGlvbpSTlC4=",
      "name": "_apply_scope_aware_truncation"
     },
     "_collect_scope_entries": {
      "__helper_func__": true,
      "pickled": "gASVNQAAAAAAAACMFmJvdHMudG9vbHMucHl0aG9uX2VkaXSUjBZfY29sbGVjdF9zY29wZV9lbnRyaWVzlJOULg==",
      "name": "_collect_scope_entries"
     },
     "_create_outline_view": {
      "__helper_func__": true,
      "pickled": "gASVMwAAAAAAAACMFmJvdHMudG9vbHMucHl0aG9uX2VkaXSUjBRfY3JlYXRlX291dGxpbmVfdmlld5STlC4=",
      "name": "_create_outline_view"
     }
    }
   }
  },
  "function_paths": {
   "view": "dynamic_module_352422989866538021",
   "view_dir": "dynamic_module_5443219883992357174",
   "python_view": "dynamic_module_-7501545324325603269",
   "execute_powershell": "dynamic_module_6805218773929428321",
   "execute_python": "dynamic_module_-6197498854453592949",
   "branch_self": "dynamic_module_3516398555053604195",
   "remove_context": "dynamic_module_8519542499546822820",
   "list_context": "dynamic_module_1561770137829577916",
   "web_search": "dynamic_module_2308802714246007567",
   "python_edit": "dynamic_module_3019238725971262868"
  }
 },
 "autosave": true,
 "filename": null,
 "callbacks": "<__main__.RealTimeDisplayCallbacks object at 0x00000268B3F89C70>",
 "bot_class": "AnthropicBot",
 "enable_tracing": true
}