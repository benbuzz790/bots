{
 "name": "Claude",
 "model_engine": "claude-3-5-sonnet-20241022",
 "max_tokens": 4096,
 "temperature": 0.3,
 "role": "assistant",
 "role_description": "a friendly AI assistant",
 "conversation": {
  "content": "",
  "pending_results": [],
  "role": "empty",
  "tool_calls": [],
  "tool_results": [],
  "node_class": "AnthropicNode",
  "replies": [
   {
    "content": "Hi Claude! Would you please view_dir and read bot_context.txt, base.py, functional_prompts.py, and README.md?",
    "pending_results": [],
    "role": "user",
    "tool_calls": [],
    "tool_results": [],
    "node_class": "AnthropicNode",
    "replies": [
     {
      "content": "I'll help you view the directory structure and read those specific files. Let me do this step by step.\n\nFirst, let's view the directory structure:",
      "pending_results": [],
      "role": "assistant",
      "tool_calls": [
       {
        "type": "tool_use",
        "id": "toolu_01EWnb4gJR7VsgWWexzz3kAz",
        "name": "view_dir",
        "input": {}
       }
      ],
      "tool_results": [],
      "node_class": "AnthropicNode",
      "replies": [
       {
        "content": "ok",
        "pending_results": [],
        "role": "user",
        "tool_calls": [],
        "tool_results": [
         {
          "type": "tool_result",
          "tool_use_id": "toolu_01EWnb4gJR7VsgWWexzz3kAz",
          "content": "\n        ./\n            bot_context.txt\n            CONTRIBUTING.md\n            conway.py\n            LICENSE.txt\n            oai_api_example.txt\n            README.md\n            requirements.txt\n            setup.py\n            .pytest_cache/\n                README.md\n            benbuzz790/\n                private_tests/\n                    test_file.py\n                    test_repo/\n                        mechanics.py\n                        test_mechanics.py\n                    test_repo backup/\n                        mechanics.py\n                        test_mechanics.py\n                    test_repo_broken/\n                        mechanics.py\n                    test_repo_copy/\n                        ISSUE.md\n                        mechanics.py\n                        scratch.py\n                test_repo_copy/\n                    scratch.py\n            botlib/\n                build_debug_bot.py\n                build_py_file_bot.py\n                __init__.py\n            bots/\n                __init__.py\n                dev/\n                    auto_terminal.py\n                    decorators.py\n                    start.py\n                    __init__.py\n                flows/\n                    functional_prompts.py\n                    __init__.py\n                    project_tree/\n                        project_tree.py\n                        project_tree_prompts.py\n                        project_tree_tools.py\n                        spec_builder.py\n                foundation/\n                    anthropic_bots.py\n                    base.py\n                    openai_bots.py\n                    tool_handling.md\n                    __init__.py\n                tools/\n                    code_tools.py\n                    meta_tools.py\n                    python_editing_tools.py\n                    python_execution_tool.py\n                    self_tools.py\n                    terminal_tools.py\n                    __init__.py\n                utils/\n                    compile_bot_errors.py\n                    helpers.py\n            bots.egg-info/\n                dependency_links.txt\n                requires.txt\n                SOURCES.txt\n                top_level.txt\n            examples/\n                bot_example.py\n                functional_prompt_example.py\n                lazy_example.py\n            experiments/\n                llm_stego_concept.md\n                multi_channel_bot.py\n            issue103/\n                add_main_test.py\n                py_tool_behavior.py\n                README.md\n                scenario_test.py\n                test_add_class.py\n                test_add_function.py\n                test_add_main.py\n                test_add_method.py\n                test_base.py\n                test_complex_cases.py\n                test_docstring.py\n                test_imports.py\n                test_multiple.py\n                test_preservation_scenario.py\n                test_remove_import.py\n                test_replace_class.py\n                test_replace_function.py\n                test_replace_import.py\n                test_shared.py\n            tests/\n                test_add_tools.py\n                test_add_tools_openai.py\n                test_auto_terminal.py\n                test_basic.py\n                test_bots.py\n                test_code_tools.py\n                test_diff2.py\n                test_gptbot.py\n                test_helpers.py\n                test_par_branch.py\n                test_par_dispatch.py\n                test_python_tools.py\n                test_save_load_anthropic.py\n                test_save_load_openai.py\n                test_terminal_tools.py\n                test_tool_handler.py\n                __init__.py"
         }
        ],
        "node_class": "AnthropicNode",
        "replies": [
         {
          "content": "Now I'll read each of the requested files. Let me view them one by one:",
          "pending_results": [],
          "role": "assistant",
          "tool_calls": [
           {
            "type": "tool_use",
            "id": "toolu_01YPt5gq3DsWT7UFoJh2uqmg",
            "name": "view",
            "input": {
             "file_path": "bot_context.txt"
            }
           }
          ],
          "tool_results": [],
          "node_class": "AnthropicNode",
          "replies": [
           {
            "content": "ok",
            "pending_results": [],
            "role": "user",
            "tool_calls": [],
            "tool_results": [
             {
              "type": "tool_result",
              "tool_use_id": "toolu_01YPt5gq3DsWT7UFoJh2uqmg",
              "content": "\n        1:Bot Framework Design Context\n        2:\n        3:Repository Structure and Organization:\n        4:bots/\n        5:  foundation/     # Core classes and functionality\n        6:    base.py         # Bot, ToolHandler, ConversationNode base classes - fundamental abstractions\n        7:    *_bots.py       # Specific LLM implementations (Anthropic, OpenAI, etc.)\n        8:  flows/          # Higher-level interaction patterns\n        9:    functional_prompts.py  # Core operations (chain, branch, etc.) - building blocks for complex behaviors\n        10:    flows.py        # Structured task flows - practical implementations of common patterns\n        11:  events/         # Event and scheduling system for long-running operations\n        12:  tools/          # Built-in tool implementations (file operations, GitHub integration, etc.)\n        13:  dev/            # Development utilities and support tools\n        14:\n        15:The repository structure reflects the layered architecture of the framework:\n        16:- Foundation layer provides the core abstractions and implementations\n        17:- Flows layer builds higher-level patterns on top of the foundation\n        18:- Tools layer provides practical capabilities\n        19:- Events layer enables long-running and scheduled operations\n        20:- Dev layer supports development and maintenance\n        21:\n        22:Core Design Goals and Philosophy:\n        23:\n        24:1. Interface Simplicity with Power\n        25:   - Primary interface (bot.respond()) is intentionally minimal\n        26:   - Advanced features are accessible but not required\n        27:   - Progressive complexity: start simple, add power as needed\n        28:   - Example: A basic chat bot needs only 2-3 lines of code, but can be extended with tools, flows, and events\n        29:\n        30:2. Complete Bot Portability\n        31:   - Bots are self-contained, reproducible units\n        32:   - All context, tools, and state can be saved and shared\n        33:   - Enables creation of specialized, shareable bot \"environments\"\n        34:   - Example: Create a \"code review bot\" with repo context, save it, share it\n        35:\n        36:3. Efficient Context Management\n        37:   - Tree-based conversation structure enables sophisticated context handling\n        38:   - DRY principle applied to bot contexts and conversations\n        39:   - Save and reuse common starting points\n        40:   - Branch and explore different conversation paths\n        41:\n        42:4. Testing Philosophy and Practical Evolution\n        43:   - No mocking: All tests run against real APIs\n        44:   - Tests must handle real-world conditions and timing\n        45:   - Failures provide valuable information about API behavior\n        46:   - This approach ensures the framework remains practical and reliable\n        47:\n        48:5. Practical Evolution\n        49:   - Design choices driven by real usage patterns\n        50:   - Complexity added only where it serves clear purpose\n        51:   - Architecture evolved to solve actual problems\n        52:   - Focus on reliability and reproducibility\n        53:\n        54:Detailed Component Analysis:\n        55:\n        56:1. Base Classes (base.py)\n        57:\n        58:   Bot Class:\n        59:   - Primary Interface:\n        60:     ```python\n        61:     bot = AnthropicBot()\n        62:     bot.add_tool(my_function)    # Add single tool\n        63:     bot.add_tools(my_module)     # Add all functions from module\n        64:     response = bot.respond(\"prompt\")\n        65:     bot.save(\"my_bot.bot\")\n        66:     bot.chat()                   # Interactive mode\n        67:     ```\n        68:   - Design Philosophy:\n        69:     - Simple main interface hides complexity\n        70:     - All advanced features accessible when needed\n        71:     - Consistent behavior across different LLM implementations\n        72:   - Advanced Features:\n        73:     - Access to full conversation tree\n        74:     - Tool management\n        75:     - State persistence\n        76:     - Event handling\n        77:\n        78:    ToolHandler Class:\n        79:    - Purpose: Manage module-level function/module tools with full context preservation\n        80:    - Capabilities:\n        81:      - Add individual module-level functions\n        82:      - Add entire modules\n        83:      - Preserve function source code\n        84:      - Handle dependencies\n        85:      - Manage execution context\n        86:    - Design Constraints:\n        87:      - Only handles module-level functions (not nested or class-level functions)\n        88:      - This is intentional to ensure proper context preservation and maintainable scope\n        89:   - Implementation Details:\n        90:     ```python\n        91:     # Adding a simple tool\n        92:     bot.add_tool(func: Callable)\n        93:\n        94:     # Adding a module with dependencies\n        95:     import my_module\n        96:     bot.add_tools(my_module)\n        97:\n        98:     # Tools are preserved in saved bots\n        99:     bot.save(\"my_bot\")\n        100:     new_bot = Bot.load(\"my_bot.bot\")\n        101:     # Tools still work!\n        102:     ```\n        103:\n        104:   ConversationNode Class:\n        105:   - Tree-Based Storage:\n        106:     ```\n        107:     Root\n        108:     \u251c\u2500\u2500 User message\n        109:     \u2502   \u251c\u2500\u2500 Bot response 1\n        110:     \u2502   \u2502   \u2514\u2500\u2500 User message 2\n        111:     \u2502   \u2514\u2500\u2500 Bot response 2\n        112:     \u2502       \u2514\u2500\u2500 User message 3\n        113:     ```\n        114:   - Key Features:\n        115:     - Only path to root sent to LLM\n        116:     - Efficient context management\n        117:     - Branch and merge conversations\n        118:     - Save and restore states\n        119:   - Practical Applications:\n        120:     - Create \"primed\" bots with specific context\n        121:     - Maintain multiple conversation threads\n        122:     - Explore different approaches to problems\n        123:     - Efficiently manage context window\n        124:     - parallelize\n        125:\n        126:2. Functional Patterns (functional_prompts.py)\n        127:\n        128:   Basic Operations:\n        129:   ```python\n        130:   # Chain: Sequential prompts\n        131:   responses, nodes = fp.chain(bot, [\n        132:       \"First prompt\",\n        133:       \"Second prompt\",\n        134:       \"Third prompt\"\n        135:   ])\n        136:\n        137:   # Branch: Parallel exploration\n        138:   responses, nodes = fp.branch(bot, [\n        139:       \"Approach A\",\n        140:       \"Approach B\",\n        141:       \"Approach C\"\n        142:   ])\n        143:\n        144:   # Tree of Thought\n        145:   response, node = fp.tree_of_thought(\n        146:       bot,\n        147:       [\"Think about X\", \"Consider Y\", \"Analyze Z\"],\n        148:       recombinator_function\n        149:   )\n        150:   ```\n        151:\n        152:   Composition Examples:\n        153:   ```python\n        154:   # Complex pattern combining chain and branch\n        155:   def analyze_with_perspectives(bot, topic):\n        156:       # First get perspectives\n        157:       perspectives, nodes = fp.branch(bot, [\n        158:           f\"Analyze {topic} from technical perspective\",\n        159:           f\"Analyze {topic} from business perspective\",\n        160:           f\"Analyze {topic} from user perspective\"\n        161:       ])\n        162:\n        163:       # Then chain analysis steps\n        164:       return fp.chain(bot, [\n        165:           f\"Synthesize these perspectives: {perspectives}\",\n        166:           \"Identify key insights\",\n        167:           \"Make recommendations\"\n        168:       ])\n        169:\n        170:   # Using prompt_while for iterative refinement\n        171:   def refine_until_complete(bot, initial_prompt):\n        172:       return fp.prompt_while(\n        173:           bot,\n        174:           \"Run a test, then make an edit, and repeat until there are no bugs\",\n        175:           continue_prompt = 'ok',\n        176:           stop_condition = fp.conditions.tool_not_used()\n        177:       )\n        178:   ```\n        179:\n        180:3. Flow System (flows.py)\n        181:\n        182:   Purpose:\n        183:   - Structure complex bot interactions\n        184:   - Create reusable task patterns\n        185:   - Handle common workflows\n        186:\n        187:   Example Implementation:\n        188:   ```python\n        189:   def code_review_flow(bot: Bot, **kwargs):\n        190:       bot.add_tool(view_file)\n        191:       bot.add_tool(create_pr_comment)\n        192:\n        193:       review_steps = [\n        194:           \"Examine the changed files\",\n        195:           \"Analyze code structure\",\n        196:           \"Check for potential issues\",\n        197:           \"Generate review comments\"\n        198:       ]\n        199:\n        200:       return fp.chain_while(\n        201:           bot,\n        202:           review_steps,\n        203:           fp.conditions.tool_used,\n        204:           \"Continue your analysis\"\n        205:       )\n        206:   ```\n        207:\n        208:4. Event System (events/)\n        209:\n        210:   Capabilities:\n        211:   - Schedule bot operations\n        212:   - Handle event-triggered behaviors\n        213:   - Manage long-running tasks\n        214:   - Coordinate multiple bots\n        215:\n        216:   Example Usage:\n        217:   ```python\n        218:   event_system = BotEventSystem()\n        219:\n        220:   # Schedule periodic task\n        221:   event_system.schedule_bot(\n        222:       'daily_report',\n        223:       bot,\n        224:       generate_report_flow,\n        225:       cron='0 9 * * *'\n        226:   )\n        227:\n        228:   # Event-triggered task\n        229:   event_system.subscribe_bot(\n        230:       'new_issue',\n        231:       bot,\n        232:       handle_issue_flow\n        233:   )\n        234:   ```\n        235:5. Tools System\n        236:\n        237:   Tool Requirements:\n        238:   - Must have clear, descriptive docstrings that explain:\n        239:     - What the tool does\n        240:     - When to use it (\"Use when you need to...\")\n        241:     - All parameters and their types\n        242:     - Return value and format\n        243:   - Should handle errors gracefully and return error messages as strings\n        244:   - Should have consistent return formats (often JSON strings for complex data)\n        245:   - Internal helper functions should be prefixed with underscore\n        246:\n        247:   Design Philosophy:\n        248:   - Error handling should be comprehensive\n        249:   - Return values should be predictable and documented\n        250:   - Setup and configuration should be handled internally\n        251:   - Make the tools convenient and easy to use.\n        252:   - Adapt the tools to be robust to the LLM's mistakes.\n        253:\n        254:   Implementation Patterns:\n        255:   ```python\n        256:   # Simple tool with proper docstring\n        257:   def calculate_area(radius: float) -> float:\n        258:       \"\"\"Calculate circle area.\n        259:\n        260:       Use when you need to compute the area of a circle.\n        261:\n        262:       Parameters:\n        263:       - radius (float): The radius of the circle\n        264:\n        265:       Returns:\n        266:       float: The area of the circle\n        267:       \"\"\"\n        268:       try:\n        269:           return 3.14159 * radius * radius\n        270:       except Exception as e:\n        271:           return f'Error: {str(e)}'\n        272:\n        273:   # Complex tool with setup and helper functions\n        274:   def _setup_credentials():\n        275:       \"\"\"Internal helper for credential management\"\"\"\n        276:       token = os.environ.get('API_TOKEN')\n        277:       if not token:\n        278:           raise ValueError('API_TOKEN environment variable not set')\n        279:       return token\n        280:\n        281:   def complex_operation(input_data: dict) -> str:\n        282:       \"\"\"Perform complex operation.\n        283:\n        284:       Use when you need to process structured data.\n        285:\n        286:       Parameters:\n        287:       - input_data (dict): The input data structure\n        288:\n        289:       Returns:\n        290:       str: JSON string containing operation results or error message\n        291:       \"\"\"\n        292:       try:\n        293:           token = _setup_credentials()\n        294:           # Implementation\n        295:           return json.dumps(result)\n        296:       except Exception as e:\n        297:           return f'Error: {str(e)}'\n        298:\n        299:   # Module-based tools with dependencies\n        300:   # my_tools_module.py\n        301:   import required_package  # Explicit dependencies\n        302:\n        303:   def module_function():\n        304:       \"\"\"Function from a module.\n        305:\n        306:       Use when you need module-specific functionality.\n        307:\n        308:       Returns:\n        309:       str: Operation result or error message\n        310:       \"\"\"\n        311:       try:\n        312:           result = required_package.operation()\n        313:           return json.dumps(result)\n        314:       except Exception as e:\n        315:           return f'Error: {str(e)}'\n        316:   ```\n        317:   bot.respond(\"Review key files and architecture\")\n        318:   bot.save(\"repo_context.bot\")\n        319:\n        320:   # Use case 1: Code Review\n        321:   bot = Bot.load(\"repo_context.bot\", autosave=False)\n        322:   review_responses = bot.respond(\"Review new PR\")\n        323:   # Use case 2: Documentation\n        324:   bot = Bot.load(\"repo_context.bot\", autosave=False)\n        325:   doc_responses = bot.respond(\"Generate documentation\")\n        326:   ```\n        327:\n        328:Advanced Usage Patterns:\n        329:\n        330:2. Complex Flow Composition\n        331:   ```python\n        332:   def iterative_refinement_flow(bot, initial_prompt):\n        333:       responses = []\n        334:       while True:\n        335:           # Generate solution\n        336:           solution, node = fp.chain(bot, [\n        337:               initial_prompt,\n        338:               \"Implement solution\",\n        339:               \"Self-review implementation\"\n        340:           ])\n        341:\n        342:           # Branch to analyze from different perspectives\n        343:           analyses, nodes = fp.branch(bot, [\n        344:               \"Review for correctness\",\n        345:               \"Review for efficiency\",\n        346:               \"Review for clarity\"\n        347:           ])\n        348:\n        349:           # Decide if complete\n        350:           decision = bot.respond(\n        351:               f\"Analyses: {analyses}\\nShould we continue refining?\"\n        352:           )\n        353:\n        354:           if \"COMPLETE\" in decision:\n        355:               break\n        356:\n        357:           responses.append(solution)\n        358:           initial_prompt = f\"Refine based on: {analyses}\"\n        359:\n        360:       return responses\n        361:   ```\n        362:\n        363:3. Event-Driven Architecture\n        364:   ```python\n        365:   class ProjectBot:\n        366:       def __init__(self):\n        367:           self.bot = AnthropicBot()\n        368:           self.event_system = BotEventSystem()\n        369:\n        370:           # Set up event handlers\n        371:           self.event_system.subscribe_bot(\n        372:               'new_issue',\n        373:               self.bot,\n        374:               self.handle_issue\n        375:           )\n        376:           self.event_system.subscribe_bot(\n        377:               'new_pr',\n        378:               self.bot,\n        379:               self.handle_pr\n        380:           )\n        381:\n        382:           # Set up scheduled tasks\n        383:           self.event_system.schedule_bot(\n        384:               'daily_triage',\n        385:               self.bot,\n        386:               self.daily_triage,\n        387:               cron='0 9 * * *'\n        388:           )\n        389:   ```\n        390:\n        391:The framework's design emphasizes practical utility while maintaining flexibility for advanced use cases. Each component is designed to work independently but becomes more powerful when combined with others. The tree-based conversation structure and portable tool system enable sophisticated bot behaviors while keeping the basic interface simple and approachable.\n        392:\n        393:The framework continues to evolve based on practical needs and usage patterns, with new features and capabilities added as they prove useful in real-world applications."
             }
            ],
            "node_class": "AnthropicNode",
            "replies": [
             {
              "content": "Now I'll view base.py:",
              "pending_results": [],
              "role": "assistant",
              "tool_calls": [
               {
                "type": "tool_use",
                "id": "toolu_01FdgoUmQtUxHV6i8qrYv3yD",
                "name": "view",
                "input": {
                 "file_path": "bots/foundation/base.py"
                }
               }
              ],
              "tool_results": [],
              "node_class": "AnthropicNode",
              "replies": [
               {
                "content": "ok",
                "pending_results": [],
                "role": "user",
                "tool_calls": [],
                "tool_results": [
                 {
                  "type": "tool_result",
                  "tool_use_id": "toolu_01FdgoUmQtUxHV6i8qrYv3yD",
                  "content": "\n        1:\"\"\"Base classes and utilities for bot functionality.\"\"\"\n        2:import os, sys, json, ast, inspect, hashlib, importlib, textwrap, copy\n        3:from abc import ABC, abstractmethod\n        4:from enum import Enum\n        5:from typing import Optional, Type, Dict, Any, List, Callable, Tuple\n        6:from types import ModuleType\n        7:from dataclasses import dataclass\n        8:from bots.utils.helpers import formatted_datetime, _clean\n        9:\n        10:def load(filepath: str) -> 'Bot':\n        11:    \"\"\"Loads a bot\"\"\"\n        12:    return Bot.load(filepath)\n        13:\n        14:class Engines(str, Enum):\n        15:    \"\"\"Enum class representing different AI model engines.\"\"\"\n        16:    GPT4 = 'gpt-4'\n        17:    GPT4_0613 = 'gpt-4-0613'\n        18:    GPT4_32K = 'gpt-4-32k'\n        19:    GPT4_32K_0613 = 'gpt-4-32k-0613'\n        20:    GPT4TURBO = 'gpt-4-turbo-preview'\n        21:    GPT4TURBO_0125 = 'gpt-4-0125-preview'\n        22:    GPT4TURBO_VISION = 'gpt-4-vision-preview'\n        23:    GPT35TURBO = 'gpt-3.5-turbo'\n        24:    GPT35TURBO_16K = 'gpt-3.5-turbo-16k'\n        25:    GPT35TURBO_0125 = 'gpt-3.5-turbo-0125'\n        26:    GPT35TURBO_INSTRUCT = 'gpt-3.5-turbo-instruct'\n        27:    CLAUDE3_HAIKU = 'claude-3-haiku-20240307'\n        28:    CLAUDE3_SONNET = 'claude-3-sonnet-20240229'\n        29:    CLAUDE3_OPUS = 'claude-3-opus-20240229'\n        30:    CLAUDE35_SONNET_20240620 = 'claude-3-5-sonnet-20240620'\n        31:    CLAUDE35_SONNET_20241022 = 'claude-3-5-sonnet-20241022'\n        32:    CLAUDE37_SONNET_20250219 = 'claude-3-7-sonnet-20250219'\n        33:\n        34:    @staticmethod\n        35:    def get(name):\n        36:        \"\"\"Retrieve an Engines enum member by its value.\"\"\"\n        37:        for engine in Engines:\n        38:            if engine.value == name:\n        39:                return engine\n        40:        return None\n        41:\n        42:    @staticmethod\n        43:    def get_bot_class(model_engine: 'Engines') -> Type['Bot']:\n        44:        \"\"\"Returns the bot class based on the model engine.\"\"\"\n        45:        from bots.foundation.openai_bots import ChatGPT_Bot\n        46:        from bots.foundation.anthropic_bots import AnthropicBot\n        47:        if model_engine.value.startswith('gpt'):\n        48:            return ChatGPT_Bot\n        49:        elif model_engine.value.startswith('claude'):\n        50:            return AnthropicBot\n        51:        else:\n        52:            raise ValueError(f'Unsupported model engine: {model_engine}')\n        53:\n        54:    @staticmethod\n        55:    def get_conversation_node_class(class_name: str) -> Type['ConversationNode']:\n        56:        \"\"\"Returns the conversation node class based on the class name.\"\"\"\n        57:        from bots.foundation.openai_bots import OpenAINode\n        58:        from bots.foundation.anthropic_bots import AnthropicNode\n        59:        NODE_CLASS_MAP = {'OpenAINode': OpenAINode, 'AnthropicNode': AnthropicNode}\n        60:        node_class = NODE_CLASS_MAP.get(class_name)\n        61:        if node_class is None:\n        62:            raise ValueError(f'Unsupported conversation node type: {class_name}')\n        63:        return node_class\n        64:\n        65:class ConversationNode:\n        66:    \"\"\"Base class for conversation nodes that store message history and tool interactions.\"\"\"\n        67:\n        68:    def __init__(self, content: str, role: str, tool_calls: List[Dict]=None, tool_results: List[Dict]=None, pending_results: List[Dict]=None, **kwargs):\n        69:        self.role = role\n        70:        self.content = content\n        71:        self.parent: ConversationNode = None\n        72:        self.replies: list[ConversationNode] = []\n        73:        self.tool_calls = tool_calls or []\n        74:        self.tool_results = tool_results or []\n        75:        self.pending_results = pending_results or []\n        76:        for key, value in kwargs.items():\n        77:            setattr(self, key, value)\n        78:\n        79:    @staticmethod\n        80:    def _create_empty(cls=None) -> 'ConversationNode':\n        81:        if cls:\n        82:            return cls(role='empty', content='')\n        83:        return ConversationNode(role='empty', content='')\n        84:\n        85:    def _is_empty(self) -> bool:\n        86:        return self.role == 'empty' and self.content == ''\n        87:\n        88:    def _add_reply(self, **kwargs) -> 'ConversationNode':\n        89:        reply = type(self)(**kwargs)\n        90:        reply.parent = self\n        91:        self.replies.append(reply)\n        92:        if self.pending_results:\n        93:            reply.tool_results = self.pending_results.copy()\n        94:            self.pending_results = []\n        95:        reply._sync_tool_context()\n        96:        return reply\n        97:\n        98:    def _sync_tool_context(self) -> None:\n        99:        \"\"\"Synchronize tool context between all siblings by taking the union of their tool results.\"\"\"\n        100:        if self.parent and self.parent.replies:\n        101:            all_tool_results = []\n        102:            for sibling in self.parent.replies:\n        103:                for result in sibling.tool_results:\n        104:                    if result not in all_tool_results:\n        105:                        all_tool_results.append(result)\n        106:            for sibling in self.parent.replies:\n        107:                sibling.tool_results = all_tool_results.copy()\n        108:\n        109:    def _add_tool_calls(self, calls):\n        110:        self.tool_calls.extend(calls)\n        111:\n        112:    def _add_tool_results(self, results):\n        113:        self.tool_results.extend(results)\n        114:        self._sync_tool_context()\n        115:\n        116:    def _find_root(self) -> 'ConversationNode':\n        117:        \"\"\"Navigate to the root of the conversation tree.\"\"\"\n        118:        current = self\n        119:        while current.parent is not None:\n        120:            current = current.parent\n        121:        return current\n        122:\n        123:    def _root_dict(self) -> Dict:\n        124:        \"\"\"Convert the conversation tree starting from the root to a dictionary.\"\"\"\n        125:        root = self._find_root()\n        126:        return root._to_dict_recursive()\n        127:\n        128:    def _to_dict_recursive(self) -> Dict:\n        129:        \"\"\"Recursively convert this node and its replies to a dictionary.\"\"\"\n        130:        result = self._to_dict_self()\n        131:        if self.replies:\n        132:            result['replies'] = [reply._to_dict_recursive() for reply in self.replies]\n        133:        return result\n        134:\n        135:    def _to_dict_self(self) -> Dict:\n        136:        \"\"\"\n        137:        Convert this node to a dictionary, omitting replies, parent, callables.\n        138:        \"\"\"\n        139:        result = {}\n        140:        for k in dir(self):\n        141:            if not k.startswith('_') and k not in {'parent', 'replies'} and (not callable(getattr(self, k))):\n        142:                value = getattr(self, k)\n        143:                if isinstance(value, (str, int, float, bool, list, dict, type(None))):\n        144:                    result[k] = value\n        145:                else:\n        146:                    result[k] = str(value)\n        147:        result['node_class'] = self.__class__.__name__\n        148:        return result\n        149:\n        150:    def _build_messages(self) -> List[Dict[str, str]]:\n        151:        node = self\n        152:        if node._is_empty():\n        153:            return []\n        154:        conversation_list_dict = []\n        155:        while node:\n        156:            if not node._is_empty():\n        157:                entry = {'role': node.role, 'content': node.content}\n        158:                if node.tool_calls is not None:\n        159:                    entry['tool_calls'] = node.tool_calls\n        160:                if node.tool_results is not None:\n        161:                    entry['tool_results'] = node.tool_results\n        162:                conversation_list_dict = [entry] + conversation_list_dict\n        163:            node = node.parent\n        164:        return conversation_list_dict\n        165:\n        166:    @classmethod\n        167:    def _from_dict(cls, data: Dict[str, Any]) -> 'ConversationNode':\n        168:        reply_data = data.pop('replies', [])\n        169:        node_class = Engines.get_conversation_node_class(data.pop('node_class', cls.__name__))\n        170:        node = node_class(**data)\n        171:        for reply in reply_data:\n        172:            reply_node = cls._from_dict(reply)\n        173:            reply_node.parent = node\n        174:            node.replies.append(reply_node)\n        175:        return node\n        176:\n        177:    def _node_count(self) -> int:\n        178:        \"\"\"\n        179:        Recursively count the total number of nodes in the conversation,\n        180:        starting from the root.\n        181:        \"\"\"\n        182:        root = self._find_root()\n        183:\n        184:        def count_recursive(current_node):\n        185:            count = 1\n        186:            for reply in current_node.replies:\n        187:                count += count_recursive(reply)\n        188:            return count\n        189:        return count_recursive(root)\n        190:\n        191:\n        192:@dataclass\n        193:class ModuleContext:\n        194:    \"\"\"Stores context for a module including its source and execution environment\"\"\"\n        195:    name: str\n        196:    source: str\n        197:    file_path: str\n        198:    namespace: ModuleType\n        199:    code_hash: str\n        200:\n        201:class ToolHandlerError(Exception):\n        202:    \"\"\"Base exception class for ToolHandler errors\"\"\"\n        203:    pass\n        204:\n        205:class ToolNotFoundError(ToolHandlerError):\n        206:    \"\"\"Raised when a requested tool cannot be found\"\"\"\n        207:    pass\n        208:\n        209:class ModuleLoadError(ToolHandlerError):\n        210:    \"\"\"Raised when there's an error loading a module\"\"\"\n        211:    pass\n        212:\n        213:class ToolHandler(ABC):\n        214:    \"\"\"\n        215:    Abstract base class for handling tool registration, execution, and persistence.\n        216:    Supports module-level preservation of dependencies and function contexts.\n        217:    \"\"\"\n        218:\n        219:    def __init__(self):\n        220:        self.tools: List[Dict[str, Any]] = []\n        221:        self.function_map: Dict[str, Callable] = {}\n        222:        self.requests: List[Dict[str, Any]] = []\n        223:        self.results: List[Dict[str, Any]] = []\n        224:        self.modules: Dict[str, ModuleContext] = {}\n        225:\n        226:    @abstractmethod\n        227:    def generate_tool_schema(self, func: Callable) -> Dict[str, Any]:\n        228:        \"\"\"\n        229:        Generate tool schema from callable function.\n        230:\n        231:        Args:\n        232:            func: The function to generate schema for\n        233:\n        234:        Returns:\n        235:            Dictionary containing the tool's schema\n        236:        \"\"\"\n        237:        raise NotImplementedError('You must implement this method in a subclass')\n        238:\n        239:    @abstractmethod\n        240:    def generate_request_schema(self, response: Any) -> List[Dict[str, Any]]:\n        241:        \"\"\"\n        242:        Generate request schema from response.\n        243:\n        244:        Args:\n        245:            response: Raw response from LLM service\n        246:\n        247:        Returns:\n        248:            List of request schemas (multiple requests may be in one message)\n        249:        \"\"\"\n        250:        raise NotImplementedError('You must implement this method in a subclass')\n        251:\n        252:    @abstractmethod\n        253:    def tool_name_and_input(self, request_schema: Dict[str, Any]) -> Tuple[Optional[str], Dict[str, Any]]:\n        254:        \"\"\"\n        255:        Extract tool name and input from request.\n        256:\n        257:        Args:\n        258:            request_schema: The request schema to parse\n        259:\n        260:        Returns:\n        261:            Tuple of (tool name, input kwargs). Tool name may be None if request should be skipped.\n        262:        \"\"\"\n        263:        raise NotImplementedError('You must implement this method in a subclass')\n        264:\n        265:    @abstractmethod\n        266:    def generate_response_schema(self, request: Dict[str, Any], tool_output_kwargs: Dict[str, Any]) -> Dict[str, Any]:\n        267:        \"\"\"\n        268:        Generate response schema from request and tool output.\n        269:\n        270:        Args:\n        271:            request: The original request schema\n        272:            tool_output_kwargs: The output from tool execution\n        273:\n        274:        Returns:\n        275:            Response schema dictionary\n        276:        \"\"\"\n        277:        raise NotImplementedError('You must implement this method in a subclass')\n        278:\n        279:    @abstractmethod\n        280:    def generate_error_schema(self, request_schema: Dict[str, Any], error_msg: str) -> Dict[str, Any]:\n        281:        \"\"\"\n        282:        Generate an error response schema matching the format expected by this handler.\n        283:\n        284:        Args:\n        285:            error_msg: The error message to include\n        286:            request_schema: Optional original request schema that caused the error\n        287:\n        288:        Returns:\n        289:            Dict containing the error in the correct schema format for this handler\n        290:        \"\"\"\n        291:        raise NotImplementedError('You must implement this method in a subclass')\n        292:\n        293:    def extract_requests(self, response: Any) -> List[Dict[str, Any]]:\n        294:        \"\"\"\n        295:        Extract tool requests from an LLM response.\n        296:\n        297:        Args:\n        298:            response: The raw response from the LLM service\n        299:\n        300:        Returns:\n        301:            List of request schemas\n        302:\n        303:        Side effect:\n        304:            Cl`ears self.requests and sets to return value\n        305:        \"\"\"\n        306:        self.requests = self.generate_request_schema(response)\n        307:        return self.requests\n        308:\n        309:    def exec_requests(self) -> List[Dict[str, Any]]:\n        310:        \"\"\"\n        311:        Execute tool requests and generate results.\n        312:\n        313:        Args:\n        314:            requests: List of requests as request schemas to execute\n        315:\n        316:        Returns:\n        317:            List of result schemas\n        318:\n        319:        Side effects:\n        320:            - Executes tools and produces any tool use side effects\n        321:        \"\"\"\n        322:        results = []\n        323:        requests = self.requests\n        324:        for request_schema in requests:\n        325:            tool_name, input_kwargs = self.tool_name_and_input(request_schema)\n        326:            if tool_name is None:\n        327:                continue\n        328:            try:\n        329:                if tool_name not in self.function_map:\n        330:                    raise ToolNotFoundError(f\"Tool '{tool_name}' not found in function map\")\n        331:                func = self.function_map[tool_name]\n        332:                output_kwargs = func(**input_kwargs)\n        333:                response_schema = self.generate_response_schema(request_schema, output_kwargs)\n        334:            except ToolNotFoundError as e:\n        335:                error_msg = 'Error: Tool not found.\\n\\n' + str(e)\n        336:                response_schema = self.generate_error_schema(request_schema, error_msg)\n        337:            except TypeError as e:\n        338:                error_msg = f\"Invalid arguments for tool '{tool_name}': {str(e)}\"\n        339:                response_schema = self.generate_error_schema(request_schema, error_msg)\n        340:            except Exception as e:\n        341:                error_msg = f\"Unexpected error while executing tool '{tool_name}': {str(e)}\"\n        342:                response_schema = self.generate_error_schema(request_schema, error_msg)\n        343:            self.results.append(response_schema)\n        344:            results.append(response_schema)\n        345:        return results\n        346:\n        347:    def _create_builtin_wrapper(self, func):\n        348:        \"\"\"Create a wrapper function for built-in functions\"\"\"\n        349:        source = f'def {func.__name__}(x):\\n    \"\"\"Wrapper for built-in function {func.__name__} from {func.__module__}\"\"\"\\n    import {func.__module__}\\n    return {func.__module__}.{func.__name__}(float(x))\\n'\n        350:        return source\n        351:\n        352:    def _create_dynamic_wrapper(self, func):\n        353:        \"\"\"Create a wrapper for dynamic functions\"\"\"\n        354:        source = f'def {func.__name__}{inspect.signature(func)}:\\n'\n        355:        if func.__doc__:\n        356:            source += f'    \"\"\"{func.__doc__}\"\"\"\\n'\n        357:        if hasattr(func, '__code__'):\n        358:            try:\n        359:                body = inspect.getsource(func).split('\\n', 1)[1]\n        360:                source += body\n        361:            except:\n        362:                source += f'    return func(*args, **kwargs)\\n'\n        363:        else:\n        364:            source += '    pass\\n'\n        365:        return source\n        366:\n        367:    def add_tool(self, func: Callable) -> None:\n        368:        \"\"\"\n        369:        Add a single function as a tool.\n        370:        Creates a dynamic module context if none exists.\n        371:        \"\"\"\n        372:        schema = self.generate_tool_schema(func)\n        373:        if not schema:\n        374:            raise ValueError('Schema undefined. ToolHandler.generate_tool_schema() may not be implemented.')\n        375:        if not hasattr(func, '__module_context__'):\n        376:            if inspect.isbuiltin(func) or inspect.ismethoddescriptor(func):\n        377:                source = self._create_builtin_wrapper(func)\n        378:                context = {}\n        379:            else:\n        380:                try:\n        381:                    source = inspect.getsource(func)\n        382:                    if hasattr(func, '__globals__'):\n        383:                        code = func.__code__\n        384:                        names = code.co_names\n        385:                        context = {name: func.__globals__[name] for name in names if name in func.__globals__}\n        386:                    else:\n        387:                        context = {}\n        388:                except (TypeError, OSError):\n        389:                    source = self._create_dynamic_wrapper(func)\n        390:                    context = {}\n        391:            source = _clean(source)\n        392:            module_name = f'dynamic_module_{hash(source)}'\n        393:            file_path = f'dynamic_module_{hash(str(func))}'\n        394:            module = ModuleType(module_name)\n        395:            module.__file__ = file_path\n        396:            module.__dict__.update(context)\n        397:            module_context = ModuleContext(name=module_name, source=source, file_path=file_path, namespace=module, code_hash=self._get_code_hash(source))\n        398:            exec(source, module.__dict__)\n        399:            new_func = module.__dict__[func.__name__]\n        400:            new_func.__module_context__ = module_context\n        401:            self.modules[file_path] = module_context\n        402:            func = new_func\n        403:        self.tools.append(schema)\n        404:        self.function_map[func.__name__] = func\n        405:\n        406:    def _add_tools_from_file(self, filepath: str) -> None:\n        407:        \"\"\"\n        408:        Add all non-private functions from a file as tools.\n        409:        Preserves complete module context including dependencies.\n        410:\n        411:        Args:\n        412:            filepath: Path to the Python file containing tools\n        413:\n        414:        Raises:\n        415:            FileNotFoundError: If the specified file doesn't exist\n        416:            ModuleLoadError: If there's an error loading the module\n        417:        \"\"\"\n        418:        if not os.path.exists(filepath):\n        419:            raise FileNotFoundError(f\"File '{filepath}' not found.\")\n        420:        abs_file_path = os.path.abspath(filepath)\n        421:        module_name = f'dynamic_module_{hashlib.md5(abs_file_path.encode()).hexdigest()}'\n        422:        try:\n        423:            with open(abs_file_path, 'r') as file:\n        424:                source = file.read()\n        425:            module = ModuleType(module_name)\n        426:            module.__file__ = abs_file_path\n        427:            tree = ast.parse(source)\n        428:            function_nodes = [node for node in ast.walk(tree) if isinstance(node, ast.FunctionDef)]\n        429:            sys.path.insert(0, os.path.dirname(abs_file_path))\n        430:            try:\n        431:                exec(source, module.__dict__)\n        432:            finally:\n        433:                sys.path.pop(0)\n        434:            module_context = ModuleContext(name=module_name, source=source, file_path=abs_file_path, namespace=module, code_hash=self._get_code_hash(source))\n        435:            self.modules[abs_file_path] = module_context\n        436:            for node in function_nodes:\n        437:                if not node.name.startswith('_'):\n        438:                    func = module.__dict__.get(node.name)\n        439:                    if func:\n        440:                        func.__module_context__ = module_context\n        441:                        self.add_tool(func)\n        442:        except Exception as e:\n        443:            raise ModuleLoadError(f'Error loading module from {filepath}: {str(e)}') from e\n        444:\n        445:    def _add_tools_from_module(self, module: ModuleType) -> None:\n        446:        \"\"\"\n        447:        Add all non-private functions from a module as tools.\n        448:        Module must have either a __file__ attribute or a __source__ attribute.\n        449:\n        450:        Args:\n        451:            module: Module containing the tools to add\n        452:\n        453:        Raises:\n        454:            ModuleLoadError: If module has neither __file__ nor __source__ attribute\n        455:        \"\"\"\n        456:        if hasattr(module, '__file__'):\n        457:            self._add_tools_from_file(module.__file__)\n        458:        elif hasattr(module, '__source__'):\n        459:            source = module.__source__\n        460:            module_name = f'dynamic_module_{hashlib.md5(module.__name__.encode()).hexdigest()}'\n        461:            try:\n        462:                dynamic_module = ModuleType(module_name)\n        463:                dynamic_module.__file__ = f'dynamic_module_{hash(source)}'\n        464:                exec(source, dynamic_module.__dict__)\n        465:                module_context = ModuleContext(name=module_name, source=source, file_path=dynamic_module.__file__, namespace=dynamic_module, code_hash=self._get_code_hash(source))\n        466:                self.modules[dynamic_module.__file__] = module_context\n        467:                for name, func in inspect.getmembers(dynamic_module, inspect.isfunction):\n        468:                    if not name.startswith('_'):\n        469:                        func.__module_context__ = module_context\n        470:                        self.add_tool(func)\n        471:            except Exception as e:\n        472:                raise ModuleLoadError(f'Error loading module {module.__name__}: {str(e)}') from e\n        473:        else:\n        474:            raise ModuleLoadError(f'Module {module.__name__} has neither file path nor source. Cannot load.')\n        475:\n        476:    def to_dict(self) -> Dict[str, Any]:\n        477:        \"\"\"\n        478:        Serialize the ToolHandler state to a dictionary.\n        479:        \"\"\"\n        480:        module_details = {}\n        481:        function_paths = {}\n        482:        for file_path, module_context in self.modules.items():\n        483:            module_details[file_path] = {'name': module_context.name, 'source': module_context.source, 'file_path': module_context.file_path, 'code_hash': module_context.code_hash, 'globals': {k: str(v) for k, v in module_context.namespace.__dict__.items() if not k.startswith('__')}}\n        484:        for name, func in self.function_map.items():\n        485:            module_context = getattr(func, '__module_context__', None)\n        486:            if module_context:\n        487:                function_paths[name] = module_context.file_path\n        488:            else:\n        489:                function_paths[name] = 'dynamic'\n        490:        return {'class': f'{self.__class__.__module__}.{self.__class__.__name__}', 'tools': self.tools.copy(), 'requests': self.requests.copy(), 'results': self.results.copy(), 'modules': module_details, 'function_paths': function_paths}\n        491:\n        492:    @classmethod\n        493:    def from_dict(cls, data: Dict[str, Any]) -> 'ToolHandler':\n        494:        \"\"\"\n        495:        Reconstruct a ToolHandler instance from a serialized state.\n        496:        Only restores functions that were explicitly registered as tools.\n        497:        Requests and Results are conserverved.\n        498:        \"\"\"\n        499:        handler = cls()\n        500:        handler.results = data.get('results', [])\n        501:        handler.requests = data.get('requests', [])\n        502:        handler.tools = data.get('tools', []).copy()\n        503:        function_paths = data.get('function_paths', {})\n        504:        for file_path, module_data in data.get('modules', {}).items():\n        505:            current_code_hash = cls._get_code_hash(module_data['source'])\n        506:            if current_code_hash != module_data['code_hash']:\n        507:                print(f'Warning: Code hash mismatch for module {file_path}. Skipping.')\n        508:                continue\n        509:            try:\n        510:                module = ModuleType(module_data['name'])\n        511:                module.__file__ = file_path\n        512:                source = module_data['source']\n        513:                if 'globals' in module_data:\n        514:                    module.__dict__.update(module_data['globals'])\n        515:                exec(source, module.__dict__)\n        516:                module_context = ModuleContext(name=module_data['name'], source=source, file_path=module_data['file_path'], namespace=module, code_hash=current_code_hash)\n        517:                handler.modules[module_data['file_path']] = module_context\n        518:                for func_name, path in function_paths.items():\n        519:                    if path == module_data['file_path'] and func_name in module.__dict__:\n        520:                        func = module.__dict__[func_name]\n        521:                        if callable(func):\n        522:                            func.__module_context__ = module_context\n        523:                            handler.function_map[func_name] = func\n        524:            except Exception as e:\n        525:                print(f'Warning: Failed to load module {file_path}: {str(e)}')\n        526:                continue\n        527:        return handler\n        528:\n        529:    def get_tools_json(self) -> str:\n        530:        \"\"\"Return a JSON string representation of all tools.\"\"\"\n        531:        return json.dumps(self.tools, indent=1)\n        532:\n        533:    def clear(self) -> None:\n        534:        \"\"\"Clear the stored results and requests.\"\"\"\n        535:        self.results = []\n        536:        self.requests = []\n        537:\n        538:    def add_request(self, request: Dict[str, Any]) -> None:\n        539:        \"\"\"Add a request to the stored requests.\"\"\"\n        540:        self.requests.append(request)\n        541:\n        542:    def add_result(self, result: Dict[str, Any]) -> None:\n        543:        \"\"\"Add a result to the stored results.\"\"\"\n        544:        self.results.append(result)\n        545:\n        546:    def get_results(self) -> List[Dict[str, Any]]:\n        547:        \"\"\"Get all stored results.\"\"\"\n        548:        return self.results\n        549:\n        550:    def get_requests(self) -> List[Dict[str, Any]]:\n        551:        \"\"\"Get all stored requests\"\"\"\n        552:        return self.requests\n        553:\n        554:    @staticmethod\n        555:    def _get_code_hash(code: str) -> str:\n        556:        \"\"\"Generate MD5 hash of code string.\"\"\"\n        557:        return hashlib.md5(code.encode()).hexdigest()\n        558:\n        559:    def __str__(self) -> str:\n        560:        \"\"\"String representation showing number of tools and modules.\"\"\"\n        561:        return f'ToolHandler with {len(self.tools)} tools and {len(self.modules)} modules'\n        562:\n        563:    def __repr__(self) -> str:\n        564:        \"\"\"Detailed representation including tool names.\"\"\"\n        565:        tool_names = list(self.function_map.keys())\n        566:        return f'ToolHandler(tools={tool_names}, modules={list(self.modules.keys())})'\n        567:\n        568:class Mailbox(ABC):\n        569:\n        570:    def __init__(self):\n        571:        self.log_file = 'data\\\\mailbox_log.txt'\n        572:\n        573:    def log_message(self, message: str, direction: str) -> None:\n        574:        timestamp = formatted_datetime()\n        575:        log_entry = f'[{timestamp}] {direction.upper()}:\\n{message}\\n\\n'\n        576:        with open(self.log_file, 'a', encoding='utf-8') as file:\n        577:            file.write(log_entry)\n        578:\n        579:    @abstractmethod\n        580:    def send_message(self, bot: 'Bot') -> Dict[str, Any]:\n        581:        \"\"\"\n        582:        Implement the actual message sending logic for a specific AI service.\n        583:\n        584:        This method should handle the API call to the AI service and return the raw response.\n        585:        It *may* also handle any tool results, depending on the api.\n        586:\n        587:        Parameters:\n        588:        - bot: a reference to a \"Bot\" or subclass\n        589:\n        590:        Returns:\n        591:        Dict[str, Any]: The raw response from the AI service as a Dict\n        592:\n        593:        Raises:\n        594:        Exception: If there's an error in sending the message or receiving the response.\n        595:        \"\"\"\n        596:        raise NotImplemented('You must implement this method in a subclass')\n        597:        pass\n        598:\n        599:    @abstractmethod\n        600:    def process_response(self, response: Dict[str, Any], bot: 'Bot'=None) -> Tuple[str, str, Dict[str, Any]]:\n        601:        \"\"\"\n        602:        Process the raw response from the AI service into a standardized format.\n        603:\n        604:        This method should extract the relevant information from the AI's response\n        605:        and return it in a consistent format across different AI services.\n        606:\n        607:        Note that if tool_handler has been implemented, extract_requests and results\n        608:        have already been called and are available in the tool_handler.\n        609:\n        610:        Parameters:\n        611:        - response (Dict[str, Any]): The raw response from the AI service.\n        612:        - bot (Bot): A Bot object. This is required in the case that, in processing\n        613:            a response, a new message must be sent (such as in the case of openai\n        614:            tool processing)\n        615:\n        616:        Returns:\n        617:        tuple[str, str, Dict[str, Any]]: A tuple containing:\n        618:            - The response text (str)\n        619:            - The role of the responder (str, e.g., \"assistant\")\n        620:            - Additional metadata or parsed information (Dict[str, Any])\n        621:                - This additional data will be passed to ConversationNode's kwargs\n        622:                  argument directly\n        623:                - By default, Conversation Node saves each kwarg as an attribute\n        624:        \"\"\"\n        625:        raise NotImplemented('You must implement this method in a subclass')\n        626:\n        627:    def _log_outgoing(self, conversation: ConversationNode, model: Engines, max_tokens, temperature):\n        628:        log_message = {'date': formatted_datetime(), 'messages': conversation._build_messages(), 'max_tokens': max_tokens, 'temperature': temperature, 'model': model}\n        629:        self._log_message(json.dumps(log_message, indent=1), 'OUTGOING')\n        630:\n        631:    def _log_incoming(self, processed_response):\n        632:        log_message = {'date': formatted_datetime(), 'response': processed_response}\n        633:        self._log_message(json.dumps(log_message, indent=1), 'INCOMING')\n        634:\n        635:    def _log_message(self, message: str, direction: str) -> None:\n        636:        timestamp = formatted_datetime()\n        637:        log_entry = f'[{timestamp}] {direction.upper()}:\\n{message}\\n\\n'\n        638:        with open(self.log_file, 'a', encoding='utf-8') as file:\n        639:            file.write(log_entry)\n        640:\n        641:class Bot(ABC):\n        642:    \"\"\"Abstract base class for all bot implementations.\"\"\"\n        643:\n        644:    def __init__(self, api_key: Optional[str], model_engine: Engines, max_tokens: int, temperature: float, name: str, role: str, role_description: str, conversation: Optional[ConversationNode]=ConversationNode._create_empty(), tool_handler: Optional[ToolHandler]=None, mailbox: Optional[Mailbox]=None, autosave: bool=True):\n        645:        self.api_key = api_key\n        646:        self.name = name\n        647:        self.model_engine = model_engine\n        648:        self.max_tokens = max_tokens\n        649:        self.temperature = temperature\n        650:        self.role = role\n        651:        self.role_description = role_description\n        652:        self.conversation: ConversationNode = conversation\n        653:        self.system_message = ''\n        654:        self.tool_handler = tool_handler\n        655:        self.mailbox = mailbox\n        656:        self.autosave = autosave\n        657:        if isinstance(self.model_engine, str):\n        658:            self.model_engine = Engines.get(self.model_engine)\n        659:\n        660:    def respond(self, prompt: str, role: str='user') -> str:\n        661:        \"\"\"\n        662:        Sends 'prompt' to the Bot and returns the text response\n        663:        Allows tool use\n        664:        \"\"\"\n        665:        self.conversation = self.conversation._add_reply(content=prompt, role=role)\n        666:        if self.autosave:\n        667:            self.save(f'{self.name}')\n        668:        reply, _ = self._cvsn_respond()\n        669:        if self.autosave:\n        670:            self.save(f'{self.name}')\n        671:        return reply\n        672:\n        673:    def add_tools(self, *args) -> None:\n        674:        \"\"\"Adds top level functions from a python file or module\n        675:        to the bot's toolkit. Docstring for the functions are\n        676:        sent as tool descriptions\n        677:\n        678:        Allowable args:\n        679:        1. Single or multiple file paths (str)\n        680:        2. Single or multiple modules\n        681:        3. Mixed list of files and modules\n        682:        4. Single functions\n        683:        5. Lists/tuples of any of the above\n        684:\n        685:        Examples:\n        686:            # Single file\n        687:            bot.add_tools(\"path/to/tools.py\")\n        688:\n        689:            # Multiple files\n        690:            bot.add_tools(\"tools1.py\", \"tools2.py\")\n        691:\n        692:            # Multiple modules (after import)\n        693:            bot.add_tools(code_tools, python_tools, terminal_tools)\n        694:\n        695:            # Mixed files and modules\n        696:            bot.add_tools(\"tools1.py\", code_tools, \"tools2.py\", terminal_tools)\n        697:\n        698:            # Single function\n        699:            bot.add_tools(my_function)\n        700:\n        701:            # List of any supported type\n        702:            bot.add_tools([code_tools, \"tools1.py\", my_function])\n        703:\n        704:        Args:\n        705:            *args: Variable number of arguments that can be:\n        706:                - str: Filepath to Python file containing tools\n        707:                - ModuleType: Module object containing tools\n        708:                - Callable: Single function to add as tool\n        709:                - List/Tuple: Collection of any of the above\n        710:\n        711:        Raises:\n        712:            TypeError: If an argument is not a supported type\n        713:            FileNotFoundError: If a specified file path doesn't exist\n        714:            ModuleLoadError: If there's an error loading a module\n        715:    \"\"\"\n        716:\n        717:        def process_item(item):\n        718:            if isinstance(item, str):\n        719:                self.tool_handler._add_tools_from_file(item)\n        720:            elif isinstance(item, ModuleType):\n        721:                self.tool_handler._add_tools_from_module(item)\n        722:            elif isinstance(item, Callable):\n        723:                self.tool_handler.add_tool(item)\n        724:            elif isinstance(item, (list, tuple)):\n        725:                for subitem in item:\n        726:                    process_item(subitem)\n        727:            else:\n        728:                raise TypeError(f'Unsupported type for tool addition: {type(item)}')\n        729:        for arg in args:\n        730:            process_item(arg)\n        731:\n        732:    def _cvsn_respond(self) -> Tuple[str, ConversationNode]:\n        733:        \"\"\"\n        734:        1) Requests a response based on the current conversation using send_message\n        735:        2) Extracts tool requests if tool_handler exists\n        736:        3) Processes the response using process_response\n        737:        4) Creates a new conversation node from the response and adds it to the conversation history\n        738:        5) Executes tools if any requests exist and updates node with results\n        739:        6) Returns the text of the response and the new conversation node\n        740:        \"\"\"\n        741:        try:\n        742:            self.tool_handler.clear()\n        743:            response = self.mailbox.send_message(self)\n        744:            requests = []\n        745:            results = []\n        746:            _ = self.tool_handler.extract_requests(response)\n        747:            text, role, data = self.mailbox.process_response(response, self)\n        748:            self.conversation = self.conversation._add_reply(content=text, role=role, **data)\n        749:            self.conversation._add_tool_calls(self.tool_handler.requests)\n        750:            _ = self.tool_handler.exec_requests()\n        751:            self.conversation._add_tool_results(self.tool_handler.results)\n        752:            return (text, self.conversation)\n        753:        except Exception as e:\n        754:            raise e\n        755:\n        756:    def set_system_message(self, message: str) -> None:\n        757:        self.system_message = message\n        758:\n        759:    @classmethod\n        760:    def load(cls, filepath: str, api_key=None) -> 'Bot':\n        761:        with open(filepath, 'r') as file:\n        762:            data = json.load(file)\n        763:        bot_class = Engines.get_bot_class(Engines(data['model_engine']))\n        764:        init_params = inspect.signature(bot_class.__init__).parameters\n        765:        constructor_args = {k: v for k, v in data.items() if k in init_params}\n        766:        bot = bot_class(**constructor_args)\n        767:        bot.api_key = api_key if api_key is not None else None\n        768:        if 'tool_handler' in data:\n        769:            tool_handler_class = data['tool_handler']['class']\n        770:            module_name, class_name = tool_handler_class.rsplit('.', 1)\n        771:            module = importlib.import_module(module_name)\n        772:            actual_class = getattr(module, class_name)\n        773:            bot.tool_handler = actual_class().from_dict(data['tool_handler'])\n        774:        for key, value in data.items():\n        775:            if key not in constructor_args and key not in ('conversation', 'tool_handler', 'tools'):\n        776:                setattr(bot, key, value)\n        777:        if 'conversation' in data and data['conversation']:\n        778:            node_class = Engines.get_conversation_node_class(data['conversation']['node_class'])\n        779:            bot.conversation = node_class._from_dict(data['conversation'])\n        780:            while bot.conversation.replies:\n        781:                bot.conversation = bot.conversation.replies[0]\n        782:        return bot\n        783:\n        784:    def save(self, filename: Optional[str]=None) -> str:\n        785:        if filename is None:\n        786:            now = formatted_datetime()\n        787:            filename = f'{self.name}@{now}.bot'\n        788:        elif not filename.endswith('.bot'):\n        789:            filename = filename + '.bot'\n        790:        directory = os.path.dirname(filename)\n        791:        if directory and (not os.path.exists(directory)):\n        792:            os.makedirs(directory)\n        793:        data = {key: value for key, value in self.__dict__.items() if not key.startswith('_')}\n        794:        data.pop('api_key', None)\n        795:        data.pop('mailbox', None)\n        796:        data['bot_class'] = self.__class__.__name__\n        797:        data['model_engine'] = self.model_engine.value\n        798:        data['conversation'] = self.conversation._root_dict()\n        799:        if self.tool_handler:\n        800:            data['tool_handler'] = self.tool_handler.to_dict()\n        801:        for key, value in data.items():\n        802:            if not isinstance(value, (str, int, float, bool, list, dict, type(None))):\n        803:                data[key] = str(value)\n        804:        with open(filename, 'w') as file:\n        805:            json.dump(data, file, indent=1)\n        806:        return filename\n        807:\n        808:    def chat(self):\n        809:        separator = '\\n---\\n'\n        810:        print(separator)\n        811:        print('System: Chat started. Type \"/exit\" to exit.')\n        812:        uinput = ''\n        813:        while uinput != '/exit':\n        814:            print(separator)\n        815:            uinput = input('You: ')\n        816:            if uinput is None or uinput == '/exit':\n        817:                break\n        818:            print(separator)\n        819:            print(f'{self.name}: {self.respond(uinput)}')\n        820:            print(separator)\n        821:            if self.tool_handler:\n        822:                for request in self.tool_handler.get_requests():\n        823:                    tool_name, _ = self.tool_handler.tool_name_and_input(request)\n        824:                    print(f'Used Tool: {tool_name}')\n        825:                    print(separator)\n        826:\n        827:    def __mul__(self, other):\n        828:        if isinstance(other, int):\n        829:            return [copy.deepcopy(self) for _ in range(other)]\n        830:        return NotImplemented\n        831:\n        832:    def __str__(self) -> str:\n        833:        \"\"\"Returns a formatted string representation of the Bot instance.\n        834:\n        835:        Displays:\n        836:        1. Bot metadata (name, role, model)\n        837:        2. Conversation history with indentation\n        838:        3. Tool information if available\n        839:        \"\"\"\n        840:\n        841:        def format_conversation(node, level=0):\n        842:            display_level = min(level, 5)\n        843:            indent_size = 1\n        844:            marker_size = 4\n        845:            indent = ' ' * indent_size * display_level\n        846:            available_width = max(40, 80 - display_level * indent_size - marker_size)\n        847:            messages = []\n        848:            if hasattr(node, 'role'):\n        849:                if node.role == 'user':\n        850:                    base_name = 'You'\n        851:                elif node.role == 'assistant':\n        852:                    base_name = self.name\n        853:                else:\n        854:                    base_name = node.role.title()\n        855:            else:\n        856:                base_name = 'System'\n        857:            if level > display_level:\n        858:                hidden_levels = level - display_level\n        859:                if hidden_levels <= 3:\n        860:                    depth_indicator = '>' * hidden_levels\n        861:                else:\n        862:                    depth_indicator = f'>>>({hidden_levels})'\n        863:                name_display = f'{depth_indicator} {base_name}'\n        864:            else:\n        865:                name_display = base_name\n        866:            content = node.content if hasattr(node, 'content') else str(node)\n        867:            wrapped_content = '\\n'.join(textwrap.wrap(content, width=available_width, initial_indent=indent + '\u2502 ', subsequent_indent=indent + '\u2502 '))\n        868:            tool_info = []\n        869:            if hasattr(node, 'tool_calls') and node.tool_calls:\n        870:                tool_info.append(f'{indent}\u2502 Tool Calls:')\n        871:                for call in node.tool_calls:\n        872:                    if isinstance(call, dict):\n        873:                        tool_info.append(f\"{indent}\u2502   - {call.get('name', 'unknown')}\")\n        874:            if hasattr(node, 'tool_results') and node.tool_results:\n        875:                tool_info.append(f'{indent}\u2502 Tool Results:')\n        876:                for result in node.tool_results:\n        877:                    if isinstance(result, dict):\n        878:                        tool_info.append(f\"{indent}\u2502   - {str(result.get('content', ''))[:available_width]}\")\n        879:            if hasattr(node, 'pending_results') and node.pending_results:\n        880:                tool_info.append(f'{indent}\u2502 Pending Results:')\n        881:                for result in node.pending_results:\n        882:                    if isinstance(result, dict):\n        883:                        tool_info.append(f\"{indent}\u2502   - {str(result.get('content', ''))[:available_width]}\")\n        884:                    else:\n        885:                        raise ValueError()\n        886:            tool_info_str = '\\n'.join(tool_info) if tool_info else ''\n        887:            messages.append(f'{indent}\u250c\u2500 {name_display}')\n        888:            messages.append(wrapped_content)\n        889:            if hasattr(node, 'tool_calls') and node.tool_calls:\n        890:                messages.append(f'{indent}\u2502 Tool Calls:')\n        891:                for call in node.tool_calls:\n        892:                    if isinstance(call, dict):\n        893:                        messages.append(f\"{indent}\u2502   - {call.get('name', 'unknown')}\")\n        894:            if hasattr(node, 'tool_results') and node.tool_results:\n        895:                messages.append(f'{indent}\u2502 Tool Results:')\n        896:                for result in node.tool_results:\n        897:                    if isinstance(result, dict):\n        898:                        messages.append(f\"{indent}\u2502   - {str(result.get('content', ''))[:available_width]}\")\n        899:            if hasattr(node, 'pending_results') and node.pending_results:\n        900:                messages.append(f'{indent}\u2502 Pending Results:')\n        901:                for result in node.pending_results:\n        902:                    if isinstance(result, dict):\n        903:                        messages.append(f\"{indent}\u2502   - {str(result.get('content', ''))[:available_width]}\")\n        904:            messages.append(f'{indent}\u2514' + '\u2500' * 40)\n        905:            if hasattr(node, 'replies') and node.replies:\n        906:                for reply in node.replies:\n        907:                    messages.extend(format_conversation(reply, level + 1))\n        908:            return messages\n        909:        lines = []\n        910:        lines.append('\u2554' + '\u2550' * 12)\n        911:        lines.append(f'\u2551 {self.name}')\n        912:        lines.append(f'\u2551 Role: {self.role}')\n        913:        lines.append(f'\u2551 Model: {self.model_engine.value}')\n        914:        if self.tool_handler:\n        915:            tool_count = len(self.tool_handler.tools)\n        916:            lines.append(f'\u2551 Tools Available: {tool_count}')\n        917:        lines.append('\u255a' + '\u2550' * 78 + '\u255d\\n')\n        918:        if self.conversation:\n        919:            root = self.conversation\n        920:            while hasattr(root, 'parent') and root.parent:\n        921:                if root.parent._is_empty() and len(root.parent.replies) == 1:\n        922:                    break\n        923:                root = root.parent\n        924:            lines.extend(format_conversation(root))\n        925:        return '\\n'.join(lines)"
                 }
                ],
                "node_class": "AnthropicNode",
                "replies": [
                 {
                  "content": "Now let me view functional_prompts.py:",
                  "pending_results": [],
                  "role": "assistant",
                  "tool_calls": [
                   {
                    "type": "tool_use",
                    "id": "toolu_01S86EmYZq1NPdwv8hUVYmsG",
                    "name": "view",
                    "input": {
                     "file_path": "bots/flows/functional_prompts.py"
                    }
                   }
                  ],
                  "tool_results": [],
                  "node_class": "AnthropicNode",
                  "replies": [
                   {
                    "content": "ok",
                    "pending_results": [],
                    "role": "user",
                    "tool_calls": [],
                    "tool_results": [
                     {
                      "type": "tool_result",
                      "tool_use_id": "toolu_01S86EmYZq1NPdwv8hUVYmsG",
                      "content": "\n        1:from typing import List, Callable, Any, Tuple\n        2:from bots.foundation.base import Bot\n        3:from bots.foundation.base import ConversationNode\n        4:from concurrent.futures import ThreadPoolExecutor, as_completed\n        5:import os\n        6:\n        7:\n        8:\"\"\"Custom typing for clarity (hopefully)\"\"\"\n        9:Prompt = str\n        10:Response = str\n        11:PromptNode = ConversationNode\n        12:ResponseNode = ConversationNode\n        13:Condition = Callable[[Bot], bool]\n        14:DynamicPrompt = Callable[[Any], Prompt]\n        15:RecombinatorFunction = Callable[[List[Response], List[ResponseNode]], Tuple[Response, ResponseNode]]\n        16:\"\"\"Add callbacks?\"\"\"\n        17:\n        18:\n        19:class conditions:\n        20:    \"\"\"\n        21:    A list of frequently used and helpful conditions for convenience\n        22:    \"\"\"\n        23:\n        24:    def tool_used(bot: Bot):\n        25:        return bool(bot.tool_handler.requests)\n        26:\n        27:    def tool_not_used(bot: Bot):\n        28:        return not bool(bot.tool_handler.requests)\n        29:\n        30:    def tool_not_used_debug(bot: Bot):\n        31:        print(f'{bot.name}: {bot.conversation.content}')\n        32:        return not bool(bot.tool_handler.requests)\n        33:\n        34:    def said_DONE(bot: Bot):\n        35:        return 'DONE' in bot.conversation.content\n        36:\n        37:    def said_DONE_debug(bot: Bot):\n        38:        print(f'{bot.name}: {bot.conversation.content}')\n        39:        return 'DONE' in bot.conversation.content\n        40:\n        41:\n        42:def basic(bot: Bot, prompt: Prompt) ->Tuple[Response, ResponseNode]:\n        43:    \"\"\"\n        44:    Included as a demonstration. Sends prompt to bot and returns the result.\n        45:    \"\"\"\n        46:    response = bot.respond(prompt)\n        47:    node = bot.conversation\n        48:    return response, node\n        49:\n        50:\n        51:def chain(bot: Bot, prompts: List[Prompt]) ->Tuple[List[Response], List[\n        52:    ResponseNode]]:\n        53:    \"\"\"\n        54:    Implements a chain of thought by sending a series of prompts to the bot.\n        55:\n        56:    Args:\n        57:    bot (Bot): The bot to use for the responses.\n        58:    prompts (List[Prompt]): A list of prompts to send to the bot in order.\n        59:\n        60:    Returns:\n        61:    Tuple[List[Response], List[ResponseNode]]: A tuple containing a list of response strings and a list of corresponding ConversationNodes.\n        62:    \"\"\"\n        63:    responses = []\n        64:    nodes = []\n        65:    for prompt in prompts:\n        66:        response = bot.respond(prompt)\n        67:        responses.append(response)\n        68:        nodes.append(bot.conversation)\n        69:    return responses, nodes\n        70:\n        71:\n        72:def branch(bot: Bot, prompts: List[Prompt]) ->Tuple[List[Response], List[\n        73:    ResponseNode]]:\n        74:    \"\"\"\n        75:    Creates multiple conversation branches from the current node.\n        76:    Each branch starts from the current conversation state.\n        77:\n        78:    Args:\n        79:    bot (Bot): The bot to use for the responses.\n        80:    prompts (List[Prompt]): A list of prompts to send to the bot.\n        81:\n        82:    Returns:\n        83:    Tuple[List[Response], List[ResponseNode]]: A tuple containing a\n        84:    list of response strings and a list of corresponding\n        85:    ConversationNodes. If an error occurs, 'None' is sent for both the\n        86:    response and node.\n        87:    \"\"\"\n        88:    original_conversation = bot.conversation\n        89:    responses = []\n        90:    nodes = []\n        91:    for prompt in prompts:\n        92:        bot.conversation = original_conversation\n        93:        try:\n        94:            response = bot.respond(prompt)\n        95:            node = bot.conversation\n        96:        except:\n        97:            response = None\n        98:            node = None\n        99:        finally:\n        100:            responses.append(response)\n        101:            nodes.append(node)\n        102:    return responses, nodes\n        103:\n        104:\n        105:def recombine(bot: Bot, responses: List[Response], nodes: List[ResponseNode\n        106:    ], recombinator_function: RecombinatorFunction) ->Tuple[Response,\n        107:    ResponseNode]:\n        108:    \"\"\"\n        109:    Recombines multiple conversation branches using a provided function.\n        110:\n        111:    Args:\n        112:    bot (Bot): The bot to use for the responses. (Kept for potential future use)\n        113:    responses (List[Response]): A list of response strings.\n        114:    nodes (List[ResponseNode]): A list of corresponding ConversationNodes.\n        115:    recombinator_function (RecombinatorFunction): A function that takes a list of Responses and a list of ResponseNodes and returns a single Response and ResponseNode.\n        116:\n        117:    Returns:\n        118:    Tuple[Response, ResponseNode]: A tuple containing the recombined response string and its corresponding ConversationNode.\n        119:    \"\"\"\n        120:    start_point = bot.conversation\n        121:    response, node = recombinator_function(responses, nodes)\n        122:    node.parent = start_point\n        123:    start_point.replies[-1] = node\n        124:    bot.conversation = node\n        125:    return response, node\n        126:\n        127:\n        128:def tree_of_thought(bot: Bot, prompts: List[Prompt], recombinator_function:\n        129:    RecombinatorFunction) ->Tuple[Response, ResponseNode]:\n        130:    \"\"\"\n        131:    Implements a tree of thought approach by branching into multiple\n        132:    conversation paths and then recombining the results.\n        133:\n        134:    Args:\n        135:    bot (Bot): The bot to use for the responses.\n        136:    prompts (List[Prompt]): A list of prompts to create branches with.\n        137:    recombinator_function (RecombinatorFunction): A function that takes\n        138:        a list of Responses and a list of ResponseNodes and returns a\n        139:        single Response and ResponseNode.\n        140:\n        141:    Returns:\n        142:    Tuple[Response, ResponseNode]: A tuple containing the final recombined\n        143:        response string and its corresponding ConversationNode.\n        144:    \"\"\"\n        145:    responses, nodes = branch(bot, prompts)\n        146:    final_response = recombine(bot, responses, nodes, recombinator_function)\n        147:    return final_response\n        148:\n        149:\n        150:def prompt_while(bot: Bot, first_prompt: Prompt, continue_prompt: Prompt=\n        151:    'ok', stop_condition: Condition=conditions.tool_not_used) ->Tuple[List[\n        152:    Response], List[ResponseNode]]:\n        153:    \"\"\"\n        154:    Repeatedly prompts the bot until a stop condition is met.\n        155:\n        156:    Args:\n        157:    bot (Bot): The bot to use for the responses.\n        158:    prompt (Prompt): The prompt to repeatedly send to the bot.\n        159:    stop_condition (StopCondition): A function that takes a Response and returns True if the loop should stop.\n        160:\n        161:    Returns:\n        162:    Tuple[List[Response], List[ResponseNode]]: A tuple containing a list of response strings and a list of corresponding ConversationNodes.\n        163:    \"\"\"\n        164:    responses = []\n        165:    nodes = []\n        166:    response = bot.respond(first_prompt)\n        167:    responses.append(response)\n        168:    nodes.append(bot.conversation)\n        169:    while not stop_condition(bot):\n        170:        response = bot.respond(continue_prompt)\n        171:        responses.append(response)\n        172:        nodes.append(bot.conversation)\n        173:    return responses, nodes\n        174:\n        175:\n        176:def prompt_for(bot: Bot, items: List[Any], dynamic_prompt: DynamicPrompt,\n        177:    should_branch: bool=False) ->Tuple[List[Response], List[ResponseNode]]:\n        178:    \"\"\"\n        179:    Generates prompts for a list of items and gets responses from the bot.\n        180:\n        181:    Args:\n        182:    bot (Bot): The bot to use for the responses.\n        183:    items (List[Any]): A list of items to generate prompts for.\n        184:    dynamic_prompt (DynamicPrompt): A function that takes an item and returns a prompt.\n        185:    branch (bool): If True, creates separate conversation branches for each item.\n        186:                   If False (default), processes items sequentially in the same conversation.\n        187:\n        188:    Returns:\n        189:    Tuple[List[Response], List[ResponseNode]]: A tuple containing a list of response strings and a list of corresponding ConversationNodes.\n        190:    \"\"\"\n        191:    prompts = [dynamic_prompt(item) for item in items]\n        192:    if should_branch:\n        193:        return branch(bot, prompts)\n        194:    else:\n        195:        return chain(bot, prompts)\n        196:\n        197:\n        198:def chain_while(bot: Bot, prompt_list: List[Prompt], stop_condition:\n        199:    Condition=conditions.tool_not_used, continue_prompt: str='ok') ->Tuple[\n        200:    List[Response], List[ResponseNode]]:\n        201:    \"\"\"\n        202:    Sends a series of messages. Moves to next message when stop_condition(bot) is met.\n        203:    Sends continue_prompt if condition is not met.\n        204:    Clears tool handler.\n        205:\n        206:    Args:\n        207:    bot (Bot): The bot to use for the responses.\n        208:    prompt_list (List[Prompt]): List of prompts to send in sequence\n        209:    stop_condition (Condition): Function that takes a Bot and returns True when ready to move to next prompt\n        210:    continue_prompt (str): Prompt to send when stop_condition is False\n        211:\n        212:    Returns:\n        213:    Tuple[List[Response], List[ResponseNode]]: Lists of responses and their corresponding nodes\n        214:    \"\"\"\n        215:    responses = []\n        216:    nodes = []\n        217:    for p in prompt_list:\n        218:        response = bot.respond(p)\n        219:        responses.append(response)\n        220:        nodes.append(bot.conversation)\n        221:        while not stop_condition(bot):\n        222:            response = bot.respond(continue_prompt)\n        223:            responses.append(response)\n        224:            nodes.append(bot.conversation)\n        225:    bot.tool_handler.clear()\n        226:    return responses, nodes\n        227:\n        228:\n        229:def branch_while(bot: Bot, prompt_list: List[Prompt], stop_condition:\n        230:    Condition=conditions.tool_not_used, continue_prompt: str='ok') ->Tuple[\n        231:    List[Response], List[ResponseNode]]:\n        232:    \"\"\"\n        233:    Creates parallel branches for a list of prompts, continuing each branch until its stop condition is met.\n        234:    Each branch starts from the current conversation state and develops independently.\n        235:\n        236:    Args:\n        237:    bot (Bot): The bot to use for the responses.\n        238:    prompt_list (List[Prompt]): List of prompts to create branches with\n        239:    stop_condition (Condition): Function that takes a Bot and returns True when ready to move to next prompt\n        240:    continue_prompt (str): Prompt to send when stop_condition is False\n        241:\n        242:    Returns:\n        243:    Tuple[List[Response], List[ResponseNode]]: Lists of final responses and their corresponding nodes from each branch. If an error occurs on a branch, the response and node returned are 'None'.\n        244:    \"\"\"\n        245:    original_conversation = bot.conversation\n        246:    responses = []\n        247:    nodes = []\n        248:    for initial_prompt in prompt_list:\n        249:        try:\n        250:            bot.conversation = original_conversation\n        251:            response = bot.respond(initial_prompt)\n        252:            while not stop_condition(bot):\n        253:                response = bot.respond(continue_prompt)\n        254:            node = bot.conversation\n        255:        except Exception as e:\n        256:            response = None\n        257:            node = None\n        258:        finally:\n        259:            responses.append(response)\n        260:            nodes.append(node)\n        261:    return responses, nodes\n        262:\n        263:\n        264:def par_branch(bot: Bot, prompts: List[Prompt]) ->Tuple[List[Response],\n        265:    List[ResponseNode]]:\n        266:    \"\"\"\n        267:    Creates multiple conversation branches from the current node in parallel.\n        268:    Each branch starts from the current conversation state and processes independently.\n        269:\n        270:    Args:\n        271:    bot (Bot): The bot to use for the responses.\n        272:    prompts (List[Prompt]): A list of prompts to send to the bot.\n        273:\n        274:    Returns:\n        275:    Tuple[List[Response], List[ResponseNode]]: A tuple containing a list of response\n        276:    strings and a list of corresponding ConversationNodes. If an error occurs in any\n        277:    branch, 'None' is sent for both the response and node for that branch.\n        278:    \"\"\"\n        279:    original_autosave = bot.autosave\n        280:    original_conversation = bot.conversation\n        281:    bot.autosave = False\n        282:    temp_file = 'temp_bot.bot'\n        283:    bot.save(temp_file)\n        284:    responses = [None] * len(prompts)\n        285:    nodes = [None] * len(prompts)\n        286:\n        287:    def process_prompt(index: int, prompt: str) ->Tuple[int, Response,\n        288:        ResponseNode]:\n        289:        try:\n        290:            branch_bot = Bot.load(temp_file)\n        291:            branch_bot.autosave = False\n        292:            response = branch_bot.respond(prompt)\n        293:            new_node = branch_bot.conversation\n        294:            new_node.parent = original_conversation\n        295:            original_conversation.replies.append(new_node)\n        296:            return index, response, new_node\n        297:        except:\n        298:            return index, None, None\n        299:    with ThreadPoolExecutor() as executor:\n        300:        futures = [executor.submit(process_prompt, i, prompt) for i, prompt in\n        301:            enumerate(prompts)]\n        302:        for future in as_completed(futures):\n        303:            idx, response, node = future.result()\n        304:            responses[idx] = response\n        305:            nodes[idx] = node\n        306:    bot.autosave = original_autosave\n        307:    try:\n        308:        os.remove(temp_file)\n        309:    except:\n        310:        pass\n        311:    return responses, nodes\n        312:\n        313:\n        314:def par_branch_while(bot: Bot, prompt_list: List[Prompt], stop_condition:\n        315:    Condition=conditions.tool_not_used, continue_prompt: str='ok') ->Tuple[\n        316:    List[Response], List[ResponseNode]]:\n        317:    \"\"\"\n        318:    Creates parallel branches for a list of prompts, continuing each branch until its\n        319:    stop condition is met. Each branch starts from the current conversation state and\n        320:    develops independently. Branches are processed in parallel.\n        321:\n        322:    Args:\n        323:    bot (Bot): The bot to use for the responses.\n        324:    prompt_list (List[Prompt]): List of prompts to create branches with\n        325:    stop_condition (Condition): Function that takes a Bot and returns True when ready\n        326:                              to move to next prompt\n        327:    continue_prompt (str): Prompt to send when stop_condition is False\n        328:\n        329:    Returns:\n        330:    Tuple[List[Response], List[ResponseNode]]: Lists of final responses and their\n        331:    corresponding nodes from each branch. If an error occurs on a branch, the response\n        332:    and node returned are 'None'.\n        333:    \"\"\"\n        334:    original_autosave = bot.autosave\n        335:    original_conversation = bot.conversation\n        336:    bot.autosave = False\n        337:    temp_file = 'temp_bot.bot'\n        338:    bot.save(temp_file)\n        339:    responses = [None] * len(prompt_list)\n        340:    nodes = [None] * len(prompt_list)\n        341:\n        342:    def process_branch(index: int, initial_prompt: str) ->Tuple[int,\n        343:        Response, ResponseNode]:\n        344:        try:\n        345:            branch_bot = Bot.load(temp_file)\n        346:            branch_bot.autosave = False\n        347:            first_response = branch_bot.respond(initial_prompt)\n        348:            first_node = branch_bot.conversation\n        349:            response = first_response\n        350:            while not stop_condition(branch_bot):\n        351:                response = branch_bot.respond(continue_prompt)\n        352:            first_node.parent = original_conversation\n        353:            original_conversation.replies.append(first_node)\n        354:            return index, response, first_node\n        355:        except Exception as e:\n        356:            return index, None, None\n        357:    with ThreadPoolExecutor() as executor:\n        358:        futures = [executor.submit(process_branch, i, prompt) for i, prompt in\n        359:            enumerate(prompt_list)]\n        360:        for future in as_completed(futures):\n        361:            idx, response, node = future.result()\n        362:            responses[idx] = response\n        363:            nodes[idx] = node\n        364:    bot.autosave = original_autosave\n        365:    try:\n        366:        os.remove(temp_file)\n        367:    except:\n        368:        pass\n        369:    return responses, nodes\n        370:\n        371:\n        372:def par_dispatch(bot_list: List[Bot], functional_prompt: Callable, **kwargs\n        373:    ) ->List[Tuple[Response, ResponseNode]]:\n        374:    \"\"\"\n        375:    Dispatches each bot in bot_list through functional_prompt(bot, **kwargs) in parallel.\n        376:\n        377:    Args:\n        378:        bot_list (List[Bot]): List of bots to process in parallel\n        379:        functional_prompt (Callable): A function that takes a bot and kwargs as arguments\n        380:        **kwargs: Additional arguments to pass to the functional_prompt\n        381:\n        382:    Returns:\n        383:        List[\n        384:            Tuple[\n        385:                    Optional[List[Response] Respsonse],\n        386:                    Optional[List[ResponseNode] RespsonseNode]\n        387:                ]\n        388:            ]\n        389:\n        390:        I.e. [(responses, nodes), (responses, nodes), (responses, nodes), ...]\n        391:\n        392:        List of results from each bot's functional prompt execution, in the same form\n        393:        as that functional prompt (list or node). If an error occurs for any bot, that\n        394:        position will contain (None, None).\n        395:    \"\"\"\n        396:    results = [None] * len(bot_list)\n        397:\n        398:    def process_bot(index: int, bot: Bot) ->Tuple[int, Tuple[Response,ResponseNode]]:\n        399:        try:\n        400:            result = functional_prompt(bot, **kwargs)\n        401:            return index, result\n        402:        except Exception as e:\n        403:            return index, (None, None)\n        404:    with ThreadPoolExecutor() as executor:\n        405:        futures = [executor.submit(process_bot, i, bot) for i, bot in\n        406:            enumerate(bot_list)]\n        407:        for future in as_completed(futures):\n        408:            idx, result = future.result()\n        409:            results[idx] = result\n        410:    return results"
                     }
                    ],
                    "node_class": "AnthropicNode",
                    "replies": [
                     {
                      "content": "Finally, let me view README.md:",
                      "pending_results": [],
                      "role": "assistant",
                      "tool_calls": [
                       {
                        "type": "tool_use",
                        "id": "toolu_01PbKEWmHTU87z7YWRND2ELh",
                        "name": "view",
                        "input": {
                         "file_path": "README.md"
                        }
                       }
                      ],
                      "tool_results": [],
                      "node_class": "AnthropicNode",
                      "replies": [
                       {
                        "content": "ok",
                        "pending_results": [],
                        "role": "user",
                        "tool_calls": [],
                        "tool_results": [
                         {
                          "type": "tool_result",
                          "tool_use_id": "toolu_01PbKEWmHTU87z7YWRND2ELh",
                          "content": "\n        1:# bots: making LLM tool use convenient and powerful\n        2:\n        3:## Overview\n        4:\n        5:**bots** (b\u0252ts), ***n.pl.*** : Language Models which are instruct-tuned, have the ability to use tools, and are encapsulated with model parameters, metadata, and conversation history.\n        6:\n        7:The bots library provides a structured interface for working with such agents, aiming to make LLM tools more convenient, accessible, and sharable for developers and researchers.\n        8:\n        9:## Foundation (bots.foundation)\n        10:\n        11:The core of the Bots library is built on a robust foundation:\n        12:\n        13:- Tool handling capabilities - any well-structured Python function can be used by a bot\n        14:- Simple primary interface: `bot.respond()`, with supporting operations `add_tool(s)`, `save()`, `load()`, and `chat()`\n        15:- Tree-based conversation management:\n        16:  - Implements a linked tree structure for conversation histories\n        17:  - Allows branching conversations and exploring multiple dialogue paths\n        18:  - Efficiently manages context by only sending path to root\n        19:  - Enables saving and loading specific conversation states\n        20:- Abstract base classes for wrapping LLM API interfaces into a unified 'bot' interface\n        21:- Pre-built implementations for ChatGPT and Anthropic bots\n        22:- Complete bot portability - save and share bots with their full context and tools\n        23:\n        24:## Key Features\n        25:\n        26:1. **Auto Terminal (bots.dev.auto_terminal)**\n        27:   ```bash\n        28:   python -m bots.dev.auto_terminal\n        29:   ```\n        30:   - Advanced terminal interface for autonomous coding\n        31:   - Full conversation tree navigation (/up, /down, /left, /right)\n        32:   - Autonomous mode (/auto) - bot works until task completion\n        33:   - Tool usage visibility controls (/verbose, /quiet)\n        34:   - Save/load bot states for different tasks\n        35:   - Integrated Python and PowerShell execution\n        36:\n        37:2. **Tool System (bots.tools)**\n        38:   - Standardized tool requirements:\n        39:     - Clear docstrings with usage instructions\n        40:     - Consistent error handling\n        41:     - Predictable return formats\n        42:     - Self-contained with explicit dependencies\n        43:   - Built-in tools for:\n        44:     - File operations (read, write, modify)\n        45:     - Code manipulation\n        46:     - GitHub integration\n        47:     - Terminal operations\n        48:   - Tool portability and preservation\n        49:\n        50:3. **Functional Prompts (bots.flows.functional_prompts)**\n        51:   - Core operations: chain(), branch(), tree_of_thought()\n        52:   - Composable patterns for complex tasks\n        53:   - Iteration control (prompt_while, chain_while)\n        54:   - Support for parallel exploration\n        55:   ```python\n        56:   # Example: Parallel analysis\n        57:   responses, nodes = fp.branch(bot, [\n        58:       \"Technical perspective\",\n        59:       \"User perspective\",\n        60:       \"Business perspective\"\n        61:   ])\n        62:   ```\n        63:\n        64:4. **Event System (bots.events)**\n        65:   - Schedule bot operations\n        66:   - Handle event-triggered behaviors\n        67:   - Manage long-running tasks\n        68:   - Coordinate multiple bots\n        69:   ```python\n        70:   event_system = BotEventSystem()\n        71:   event_system.schedule_bot('daily_report', bot, report_flow, cron='0 9 * * *')\n        72:   event_system.subscribe_bot('new_issue', bot, handle_issue)\n        73:   ```\n        74:\n        75:5. **Lazy Decorator (bots.lazy)**\n        76:   - Runtime code generation via LLM\n        77:   - Context-aware implementations\n        78:   ```python\n        79:   @lazy(\"Sort using a funny algorithm. Name variables as though you're a clown.\")\n        80:   def sort(arr: list[int]) -> list[int]:\n        81:       pass\n        82:   ```\n        83:\n        84:## Installation\n        85:\n        86:```bash\n        87:pip install git+https://github.com/benbuzz790/bots.git\n        88:```\n        89:\n        90:## Quick Start\n        91:\n        92:1. Set up your API key as an environment variable:\n        93:   - [OpenAI](https://platform.openai.com/docs/quickstart) or\n        94:   - [Anthropic](https://docs.anthropic.com/en/docs/initial-setup#set-your-api-key)\n        95:\n        96:2. Basic Usage:\n        97:```python\n        98:from bots import AnthropicBot\n        99:import bots.tools.code_tools as code_tools\n        100:\n        101:# Initialize and equip bot\n        102:bot = AnthropicBot()\n        103:bot.add_tools(code_tools)\n        104:\n        105:# Single response\n        106:response = bot.respond(\"Please write a basic Flask app in app.py\")\n        107:\n        108:# Interactive mode\n        109:bot.chat()\n        110:```\n        111:\n        112:3. Save/Load Bot States:\n        113:```python\n        114:# Create a bot with repository context\n        115:bot = AnthropicBot()\n        116:bot.add_tools(code_tools)\n        117:bot.chat()\n        118:  ...\n        119:  \"Read and understand our repository structure\"\n        120:  ...\n        121:  Tools used...\n        122:  ...\n        123:  /save\n        124:\n        125:# Later use\n        126:import bots\n        127:review_bot = bots.load(\"repo_context.bot\", autosave=False)\n        128:review_bot.respond(\"Review PR #123\")\n        129:```\n        130:\n        131:4. Functional Patterns:\n        132:```python\n        133:import bots.flows.functional_prompts as fp\n        134:\n        135:# Chain of thought\n        136:responses, nodes = fp.chain(bot, [\n        137:    \"Look at the directory\",\n        138:    \"Read x, y, z\",\n        139:    \"Refactor these three files to better separate concerns\"\n        140:])\n        141:\n        142:# Parallel exploration\n        143:analyses, nodes = fp.branch(bot, [\n        144:    \"Security analysis\",\n        145:    \"Performance analysis\",\n        146:    \"Usability analysis\"\n        147:])\n        148:\n        149:# Iterative refinement\n        150:fp.prompt_while(\n        151:    bot,\n        152:    \"Run tests and create issues\",\n        153:    continue_prompt=\"ok\",\n        154:    stop_condition=fp.conditions.tool_not_used\n        155:)\n        156:```\n        157:\n        158:## Advanced Usage\n        159:\n        160:### Tool Development\n        161:\n        162:Tools must follow these patterns for reliability:\n        163:\n        164:```python\n        165:def my_tool(param: type) -> str:\n        166:    \"\"\"Clear description of what the tool does.\n        167:\n        168:    Use when you need to [specific use case].\n        169:\n        170:    Parameters:\n        171:    - param (type): Parameter description\n        172:\n        173:    Returns:\n        174:    str: Description of return format\n        175:    \"\"\"\n        176:    try:\n        177:        result = do_operation()\n        178:        return json.dumps(result)  # For complex returns\n        179:    except Exception as e:\n        180:        return f'Error: {str(e)}'\n        181:```\n        182:\n        183:### Event-Driven Bots\n        184:\n        185:```python\n        186:class ProjectBot:\n        187:    def __init__(self):\n        188:        self.bot = bots.load('github.bot')\n        189:        self.event_system = BotEventSystem()\n        190:\n        191:        # Event handlers\n        192:        self.event_system.subscribe_bot('new_issue', self.bot, self.handle_issue)\n        193:        self.event_system.subscribe_bot('new_pr', self.bot, self.handle_pr)\n        194:\n        195:        # Scheduled tasks\n        196:        self.event_system.schedule_bot(\n        197:            'daily_triage',\n        198:            self.bot,\n        199:            self.daily_triage,\n        200:            cron='0 9 * * *'\n        201:        )\n        202:```\n        203:\n        204:## Future Work\n        205:\n        206:- Enhanced tool libraries:\n        207:  - Expanded GitHub integration\n        208:  - Discord bot capabilities\n        209:  - Reddit interaction tools\n        210:- Advanced conversation management:\n        211:  - Branch comparison tools\n        212:  - Context optimization\n        213:- Performance improvements:\n        214:  - Parallel tool execution\n        215:  - Batch processing\n        216:  - Rate limiting and queueing\n        217:- Documentation and examples:\n        218:  - Common patterns library\n        219:  - Best practices guide\n        220:  - More example bots\n        221:\n        222:## Contributing\n        223:\n        224:We welcome contributions! Please see our [CONTRIBUTING.md](CONTRIBUTING.md) file for guidelines.\n        225:\n        226:## License\n        227:\n        228:This project is licensed under the MIT License - see the [LICENSE.md](LICENSE.md) file for details.\n        229:\n        230:## Disclaimer\n        231:\n        232:This library is under active development. While it's being used successfully in various projects, please test thoroughly before using in production environments."
                         }
                        ],
                        "node_class": "AnthropicNode",
                        "replies": [
                         {
                          "content": "I've now viewed all the requested files. The files show this is a Python library for working with LLMs (Language Learning Models) called \"bots\", with key components:\n\n1. bot_context.txt - Design documentation explaining the architecture, goals and components of the framework\n\n2. base.py - Core classes including:\n- Bot (abstract base class for all bot implementations)\n- ConversationNode (for managing conversation history in a tree structure)\n- ToolHandler (for managing tool registration and execution)\n- Mailbox (for handling message sending/receiving)\n\n3. functional_prompts.py - Higher-level operations for structured bot interactions:\n- chain() - Sequential prompts\n- branch() - Parallel exploration paths\n- tree_of_thought() - Branching and recombining\n- Various while-loop patterns (prompt_while, chain_while, etc.)\n- Parallel execution capabilities (par_branch, par_dispatch)\n\n4. README.md - Project documentation covering:\n- Overview and key features\n- Installation instructions\n- Quick start guide\n- Advanced usage examples\n- Future work plans\n- Contributing guidelines\n\nThe framework is designed to make working with LLMs more convenient by providing:\n- Standardized tool handling\n- Conversation management\n- Bot state persistence\n- Higher-level interaction patterns\n- Event handling capabilities\n\nWould you like me to elaborate on any particular aspect of these files?",
                          "pending_results": [],
                          "role": "assistant",
                          "tool_calls": [],
                          "tool_results": [],
                          "node_class": "AnthropicNode",
                          "replies": [
                           {
                            "content": "I'd like to make more comprehensive documentation for the library. Let's update the README first, though. Would you add to the functional prompts section noting the par_* functions which are available?",
                            "pending_results": [],
                            "role": "user",
                            "tool_calls": [],
                            "tool_results": [],
                            "node_class": "AnthropicNode",
                            "replies": [
                             {
                              "content": "I'll use diff_edit to add documentation about the parallel functions to the Functional Prompts section of the README.md:",
                              "pending_results": [],
                              "role": "assistant",
                              "tool_calls": [
                               {
                                "type": "tool_use",
                                "id": "toolu_01MXNbUkBZyeN1cz32GmDbWG",
                                "name": "diff_edit",
                                "input": {
                                 "file_path": "README.md",
                                 "diff_spec": "\n            -3. **Functional Prompts (bots.flows.functional_prompts)**\n            -   - Core operations: chain(), branch(), tree_of_thought()\n            -   - Composable patterns for complex tasks\n            -   - Iteration control (prompt_while, chain_while)\n            -   - Support for parallel exploration\n            -   ```python\n            -   # Example: Parallel analysis\n            -   responses, nodes = fp.branch(bot, [\n            -       \"Technical perspective\",\n            -       \"User perspective\",\n            -       \"Business perspective\"\n            -   ])\n            -   ```\n            +3. **Functional Prompts (bots.flows.functional_prompts)**\n            +   - Core operations: chain(), branch(), tree_of_thought()\n            +   - Composable patterns for complex tasks\n            +   - Iteration control (prompt_while, chain_while)\n            +   - Support for parallel exploration\n            +   - Parallel execution functions:\n            +     - par_branch() - Like branch() but processes in parallel\n            +     - par_branch_while() - Like branch_while() but processes in parallel\n            +     - par_dispatch() - Run any functional prompt across multiple bots in parallel\n            +   ```python\n            +   # Example: Parallel analysis using branch()\n            +   responses, nodes = fp.branch(bot, [\n            +       \"Technical perspective\",\n            +       \"User perspective\",\n            +       \"Business perspective\"\n            +   ])\n            +\n            +   # Example: Parallel processing with par_branch()\n            +   responses, nodes = fp.par_branch(bot, [\n            +       \"Analyze code structure\",\n            +       \"Review documentation\",\n            +       \"Check test coverage\",\n            +       \"Audit dependencies\"\n            +   ])\n            +\n            +   # Example: Parallel dispatch across multiple bots\n            +   results = fp.par_dispatch(\n            +       bot_list=[bot1, bot2, bot3],\n            +       functional_prompt=fp.chain,\n            +       prompts=[\"Analyze this component\", \"Suggest improvements\"]\n            +   )\n            +   ```"
                                }
                               }
                              ],
                              "tool_results": [],
                              "node_class": "AnthropicNode",
                              "replies": [
                               {
                                "content": "Great. Please make suggestions for how I should go about documenting this project. I'm not a software engineer - or, consider me entry level. I'm not sure what industry best practices are.",
                                "pending_results": [],
                                "role": "user",
                                "tool_calls": [],
                                "tool_results": [
                                 {
                                  "type": "tool_result",
                                  "tool_use_id": "toolu_01MXNbUkBZyeN1cz32GmDbWG",
                                  "content": "\n        Changes made:\n        \n        Successfully applied 1 changes:"
                                 }
                                ],
                                "node_class": "AnthropicNode",
                                "replies": [
                                 {
                                  "content": "I'll help outline a documentation strategy that follows industry best practices. For a Python library like this, you'll want to create documentation at several levels:\n\n1. **Code-Level Documentation**\n   - Docstrings for all classes, methods, and functions\n   - Type hints for better IDE support\n   - Inline comments for complex logic\n   - Example usage in docstrings\n\n2. **API Documentation**\n   - Consider using Sphinx (industry standard for Python)\n   - Generate automatic documentation from docstrings\n   - Create a docs/ directory structure:\n   ```\n   docs/\n   \u251c\u2500\u2500 source/\n   \u2502   \u251c\u2500\u2500 api/           # Detailed API documentation\n   \u2502   \u251c\u2500\u2500 guides/        # How-to guides\n   \u2502   \u251c\u2500\u2500 tutorials/     # Step-by-step tutorials\n   \u2502   \u2514\u2500\u2500 examples/      # Example scripts and notebooks\n   ```\n\n3. **User Guides**\n   - Getting Started guide\n   - Installation guide\n   - Basic concepts explanation\n   - Common patterns and best practices\n   - Troubleshooting guide\n\n4. **Tutorials**\n   - Step-by-step examples\n   - Real-world use cases\n   - Jupyter notebooks with examples\n\nHere's a suggested plan of action:\n\n1. **First Phase: Basic Documentation Structure**\n   ```bash\n   docs/\n   \u251c\u2500\u2500 getting_started.md\n   \u251c\u2500\u2500 installation.md\n   \u251c\u2500\u2500 concepts/\n   \u2502   \u251c\u2500\u2500 bots.md           # What are bots, how they work\n   \u2502   \u251c\u2500\u2500 tools.md          # How tools work, how to create them\n   \u2502   \u251c\u2500\u2500 conversations.md  # Conversation management\n   \u2502   \u2514\u2500\u2500 flows.md          # Functional prompts and flows\n   \u251c\u2500\u2500 tutorials/\n   \u2502   \u251c\u2500\u2500 basic_bot.md\n   \u2502   \u251c\u2500\u2500 adding_tools.md\n   \u2502   \u2514\u2500\u2500 functional_patterns.md\n   \u2514\u2500\u2500 api_reference/\n       \u251c\u2500\u2500 base.md\n       \u251c\u2500\u2500 tools.md\n       \u2514\u2500\u2500 flows.md\n   ```\n\n2. **Second Phase: Set up Sphinx**\n   - Install Sphinx\n   - Configure automatic documentation generation\n   - Set up ReadTheDocs hosting (free for open source)\n\n3. **Third Phase: Content Creation**\n   Priority order:\n   1. Getting Started guide\n   2. Basic concepts documentation\n   3. API reference documentation\n   4. Tutorials and examples\n\nWould you like me to help you get started with any of these phases? We could:\n\n1. Create the basic documentation directory structure\n2. Start writing the Getting Started guide\n3. Improve existing docstrings in the code\n4. Create a basic tutorial\n\nWhat would you find most helpful to tackle first?",
                                  "pending_results": [],
                                  "role": "assistant",
                                  "tool_calls": [],
                                  "tool_results": [],
                                  "node_class": "AnthropicNode",
                                  "replies": [
                                   {
                                    "content": "hmm... let's use the library to our advantage, eh? Would you write a script in utils which finds all python files, and for each, dispatches a bot using chain_while telling them to read bot_context.txt, README.txt, and to make sure that the specific file they're assigned to hasappropriate code-level documentation?",
                                    "pending_results": [],
                                    "role": "user",
                                    "tool_calls": [],
                                    "tool_results": [],
                                    "node_class": "AnthropicNode",
                                    "replies": [
                                     {
                                      "content": "That's a clever approach! Let's create a script in the utils directory to automate documentation review and improvement. I'll write this script:",
                                      "pending_results": [],
                                      "role": "assistant",
                                      "tool_calls": [
                                       {
                                        "type": "tool_use",
                                        "id": "toolu_01EyADoZhKX29QR45VZSR8ne",
                                        "name": "add_function_to_file",
                                        "input": {
                                         "file_path": "bots/utils/doc_checker.py",
                                         "new_function_def": "\n            \"\"\"\n            Script to automatically review and improve code-level documentation using bots.\n            \n            This script:\n            1. Finds all Python files in the project\n            2. Creates multiple bots to review documentation in parallel\n            3. Uses chain_while to ensure thorough documentation review\n            4. Provides suggestions for documentation improvements\n            \"\"\"\n            \n            import os\n            from typing import List, Tuple\n            from bots.foundation.base import Bot, Engines\n            from bots.foundation.anthropic_bots import AnthropicBot\n            from bots.flows import functional_prompts as fp\n            from bots.tools import code_tools\n            \n            def find_python_files(start_path: str) -> List[str]:\n                \"\"\"\n                Recursively find all Python files in a directory.\n                \n                Args:\n                    start_path (str): Root directory to start search from\n                    \n                Returns:\n                    List[str]: List of paths to Python files\n                \"\"\"\n                python_files = []\n                for root, _, files in os.walk(start_path):\n                    for file in files:\n                        if file.endswith('.py'):\n                            python_files.append(os.path.join(root, file))\n                return python_files\n            \n            def create_doc_review_bot() -> Bot:\n                \"\"\"\n                Create and configure a bot for documentation review.\n                \n                Returns:\n                    Bot: Configured bot with necessary tools and context\n                \"\"\"\n                bot = AnthropicBot(\n                    model_engine=Engines.CLAUDE3_SONNET,\n                    temperature=0.7,\n                    name=\"DocReviewer\",\n                    role=\"Documentation Specialist\",\n                    role_description=\"You are an expert in Python documentation standards and best practices.\"\n                )\n                bot.add_tools(code_tools)\n                return bot\n            \n            def review_file_documentation(bot: Bot, file_path: str) -> Tuple[List[str], List[Bot.ConversationNode]]:\n                \"\"\"\n                Review documentation for a single file using chain_while pattern.\n                \n                Args:\n                    bot (Bot): Configured documentation review bot\n                    file_path (str): Path to the Python file to review\n                    \n                Returns:\n                    Tuple[List[str], List[Bot.ConversationNode]]: Responses and conversation nodes\n                \"\"\"\n                prompts = [\n                    \"First, let's read the project context. Please read bot_context.txt and README.md to understand the project.\",\n                    f\"Now, let's examine {file_path}. Please read this file and analyze its documentation.\",\n                    \"Review the file's documentation. Check for:\\n\" + \n                    \"1. Module-level docstring\\n\" +\n                    \"2. Class docstrings\\n\" +\n                    \"3. Method/function docstrings\\n\" +\n                    \"4. Type hints\\n\" +\n                    \"5. Appropriate inline comments\\n\" +\n                    \"If you find any issues, use the appropriate tools to fix them.\",\n                    \"Make any final documentation improvements needed.\"\n                ]\n                \n                return fp.chain_while(\n                    bot,\n                    prompts,\n                    stop_condition=fp.conditions.tool_not_used,\n                    continue_prompt=\"Continue reviewing and improving the documentation. Are there any other issues to address?\"\n                )\n            \n            def main():\n                \"\"\"\n                Main function to coordinate documentation review across all Python files.\n                \"\"\"\n                # Find all Python files in the project\n                project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..'))\n                python_files = find_python_files(project_root)\n                \n                # Create bots for parallel processing\n                num_bots = min(len(python_files), 4)  # Limit concurrent bots\n                bots = [create_doc_review_bot() for _ in range(num_bots)]\n                \n                # Process files in batches\n                for i in range(0, len(python_files), num_bots):\n                    batch = python_files[i:i + num_bots]\n                    batch_bots = bots[:len(batch)]\n                    \n                    # Create kwargs for each bot\n                    kwargs_list = [{'file_path': file} for file in batch]\n                    \n                    # Process batch in parallel\n                    results = fp.par_dispatch(\n                        bot_list=batch_bots,\n                        functional_prompt=review_file_documentation,\n                        **kwargs_list[0]  # Each bot will get its own file_path\n                    )\n                    \n                    # Print results for this batch\n                    for file_path, (responses, nodes) in zip(batch, results):\n                        print(f\"\\nDocumentation review completed for {file_path}\")\n                        if responses:\n                            print(\"Last response:\", responses[-1])\n            \n            if __name__ == \"__main__\":\n                main()"
                                        }
                                       }
                                      ],
                                      "tool_results": [],
                                      "node_class": "AnthropicNode",
                                      "replies": [
                                       {
                                        "content": "Don't worry about limiting the number of parallel bots. I have a rate limiter in place.",
                                        "pending_results": [],
                                        "role": "user",
                                        "tool_calls": [],
                                        "tool_results": [
                                         {
                                          "type": "tool_result",
                                          "tool_use_id": "toolu_01EyADoZhKX29QR45VZSR8ne",
                                          "content": "\n        Code with function 'find_python_files' has been added to 'C:\\Users\\benbu\\Code\\llm-utilities-git\\bots\\bots\\utils\\doc_checker.py'.\n        Code with function 'create_doc_review_bot' has been added to 'C:\\Users\\benbu\\Code\\llm-utilities-git\\bots\\bots\\utils\\doc_checker.py'.\n        Code with function 'review_file_documentation' has been added to 'C:\\Users\\benbu\\Code\\llm-utilities-git\\bots\\bots\\utils\\doc_checker.py'.\n        Code with function 'main' has been added to 'C:\\Users\\benbu\\Code\\llm-utilities-git\\bots\\bots\\utils\\doc_checker.py'.\n        Added 2 additional code blocks"
                                         }
                                        ],
                                        "node_class": "AnthropicNode",
                                        "replies": [
                                         {
                                          "content": "I'll modify the script to remove the bot number limitation and process all files in parallel:",
                                          "pending_results": [],
                                          "role": "assistant",
                                          "tool_calls": [
                                           {
                                            "type": "tool_use",
                                            "id": "toolu_01QQsJgayXbDC6oLJnQ9sZpz",
                                            "name": "diff_edit",
                                            "input": {
                                             "file_path": "bots/utils/doc_checker.py",
                                             "diff_spec": "\n            -                # Create bots for parallel processing\n            -                num_bots = min(len(python_files), 4)  # Limit concurrent bots\n            -                bots = [create_doc_review_bot() for _ in range(num_bots)]\n            -                \n            -                # Process files in batches\n            -                for i in range(0, len(python_files), num_bots):\n            -                    batch = python_files[i:i + num_bots]\n            -                    batch_bots = bots[:len(batch)]\n            -                    \n            -                    # Create kwargs for each bot\n            -                    kwargs_list = [{'file_path': file} for file in batch]\n            -                    \n            -                    # Process batch in parallel\n            -                    results = fp.par_dispatch(\n            -                        bot_list=batch_bots,\n            -                        functional_prompt=review_file_documentation,\n            -                        **kwargs_list[0]  # Each bot will get its own file_path\n            -                    )\n            -                    \n            -                    # Print results for this batch\n            -                    for file_path, (responses, nodes) in zip(batch, results):\n            -                        print(f\"\\nDocumentation review completed for {file_path}\")\n            -                        if responses:\n            -                            print(\"Last response:\", responses[-1])\n            +                # Create a bot for each Python file\n            +                bots = [create_doc_review_bot() for _ in python_files]\n            +                \n            +                # Create kwargs for each bot\n            +                kwargs_list = [{'file_path': file} for file in python_files]\n            +                \n            +                # Process all files in parallel\n            +                results = fp.par_dispatch(\n            +                    bot_list=bots,\n            +                    functional_prompt=review_file_documentation,\n            +                    **kwargs_list[0]  # Each bot will get its own file_path\n            +                )\n            +                \n            +                # Print results\n            +                for file_path, (responses, nodes) in zip(python_files, results):\n            +                    print(f\"\\nDocumentation review completed for {file_path}\")\n            +                    if responses:\n            +                        print(\"Last response:\", responses[-1])"
                                            }
                                           }
                                          ],
                                          "tool_results": [],
                                          "node_class": "AnthropicNode",
                                          "replies": [
                                           {
                                            "content": "use replace_function",
                                            "pending_results": [],
                                            "role": "user",
                                            "tool_calls": [],
                                            "tool_results": [
                                             {
                                              "type": "tool_result",
                                              "tool_use_id": "toolu_01QQsJgayXbDC6oLJnQ9sZpz",
                                              "content": "\n        Changes made:\n        \n        Failed to apply 1 changes:\n        \n        Could not find:\n                        # Create bots for parallel processing\n                        num_bots = min(len(python_files), 4)  # Limit concurrent bots\n                        bots = [create_doc_review_bot() for _ in range(num_bots)]\n                        \n                        # Process files in batches\n                        for i in range(0, len(python_files), num_bots):\n                            batch = python_files[i:i + num_bots]\n                            batch_bots = bots[:len(batch)]\n                            \n                            # Create kwargs for each bot\n                            kwargs_list = [{'file_path': file} for file in batch]\n                            \n                            # Process batch in parallel\n                            results = fp.par_dispatch(\n                                bot_list=batch_bots,\n                                functional_prompt=review_file_documentation,\n                                **kwargs_list[0]  # Each bot will get its own file_path\n                            )\n                            \n                            # Print results for this batch\n                            for file_path, (responses, nodes) in zip(batch, results):\n                                print(f\"\\nDocumentation review completed for {file_path}\")\n                                if responses:\n                                    print(\"Last response:\", responses[-1])\n        \n        \n        Nearest partial match found around:\n        44:     Returns:\n        45:         Tuple[List[str], List[Bot.ConversationNode]]: Responses and conversation nodes\n        46:     \"\"\"\n        47:     prompts = [\"First, let's read the project context. Please read bot_context.txt and README.md to understand the project.\", f\"Now, let's examine {file_path}. Please read this file and analyze its documentation.\", \"Review the file's documentation. Check for:\\n\" + '1. Module-level docstring\\n' + '2. Class docstrings\\n' + '3. Method/function docstrings\\n' + '4. Type hints\\n' + '5. Appropriate inline comments\\n' + 'If you find any issues, use the appropriate tools to fix them.', 'Make any final documentation improvements needed.']\n        48:     return fp.chain_while(bot, prompts, stop_condition=fp.conditions.tool_not_used, continue_prompt='Continue reviewing and improving the documentation. Are there any other issues to address?')\n        \n        Match score: 4.31"
                                             }
                                            ],
                                            "node_class": "AnthropicNode",
                                            "replies": [
                                             {
                                              "content": "I'll use replace_function to update the main function:",
                                              "pending_results": [],
                                              "role": "assistant",
                                              "tool_calls": [
                                               {
                                                "type": "tool_use",
                                                "id": "toolu_01CfJBZojbWfUasMn4vykThs",
                                                "name": "replace_function",
                                                "input": {
                                                 "file_path": "bots/utils/doc_checker.py",
                                                 "new_function_def": "\n            def main():\n                \"\"\"\n                Main function to coordinate documentation review across all Python files.\n                \"\"\"\n                # Find all Python files in the project\n                project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..'))\n                python_files = find_python_files(project_root)\n                \n                # Create a bot for each Python file\n                bots = [create_doc_review_bot() for _ in python_files]\n                \n                # Create kwargs for each bot\n                kwargs_list = [{'file_path': file} for file in python_files]\n                \n                # Process all files in parallel\n                results = fp.par_dispatch(\n                    bot_list=bots,\n                    functional_prompt=review_file_documentation,\n                    **kwargs_list[0]  # Each bot will get its own file_path\n                )\n                \n                # Print results\n                for file_path, (responses, nodes) in zip(python_files, results):\n                    print(f\"\\nDocumentation review completed for {file_path}\")\n                    if responses:\n                        print(\"Last response:\", responses[-1])"
                                                }
                                               }
                                              ],
                                              "tool_results": [],
                                              "node_class": "AnthropicNode",
                                              "replies": [
                                               {
                                                "content": "finally, let's exclude the tools directory, or any file with 'tool' in the name.",
                                                "pending_results": [],
                                                "role": "user",
                                                "tool_calls": [],
                                                "tool_results": [
                                                 {
                                                  "type": "tool_result",
                                                  "tool_use_id": "toolu_01CfJBZojbWfUasMn4vykThs",
                                                  "content": "Function 'main' has been replaced in file 'C:\\Users\\benbu\\Code\\llm-utilities-git\\bots\\bots\\utils\\doc_checker.py'."
                                                 }
                                                ],
                                                "node_class": "AnthropicNode",
                                                "replies": [
                                                 {
                                                  "content": "I'll modify the find_python_files function to exclude those files:",
                                                  "pending_results": [
                                                   {
                                                    "type": "tool_result",
                                                    "tool_use_id": "toolu_01TdG8bHkAbX9SmEWB3JGcQn",
                                                    "content": "Function 'find_python_files' has been replaced in file 'C:\\Users\\benbu\\Code\\llm-utilities-git\\bots\\bots\\utils\\doc_checker.py'."
                                                   }
                                                  ],
                                                  "role": "assistant",
                                                  "tool_calls": [
                                                   {
                                                    "type": "tool_use",
                                                    "id": "toolu_01TdG8bHkAbX9SmEWB3JGcQn",
                                                    "name": "replace_function",
                                                    "input": {
                                                     "file_path": "bots/utils/doc_checker.py",
                                                     "new_function_def": "def find_python_files(start_path: str) -> List[str]:\n    \"\"\"\n    Recursively find all Python files in a directory, excluding tools and files with 'tool' in the name.\n    \n    Args:\n        start_path (str): Root directory to start search from\n        \n    Returns:\n        List[str]: List of paths to Python files\n    \"\"\"\n    python_files = []\n    for root, _, files in os.walk(start_path):\n        # Skip the tools directory and any directory with 'tool' in the name\n        if 'tool' in root.lower():\n            continue\n            \n        for file in files:\n            # Skip files with 'tool' in the name\n            if file.endswith('.py') and 'tool' not in file.lower():\n                python_files.append(os.path.join(root, file))\n    return python_files"
                                                    }
                                                   }
                                                  ],
                                                  "tool_results": [],
                                                  "node_class": "AnthropicNode"
                                                 }
                                                ]
                                               }
                                              ]
                                             }
                                            ]
                                           }
                                          ]
                                         }
                                        ]
                                       }
                                      ]
                                     }
                                    ]
                                   }
                                  ]
                                 }
                                ]
                               }
                              ]
                             }
                            ]
                           }
                          ]
                         }
                        ]
                       }
                      ]
                     }
                    ]
                   }
                  ]
                 }
                ]
               }
              ]
             }
            ]
           }
          ]
         }
        ]
       }
      ]
     }
    ]
   }
  ]
 },
 "system_message": "",
 "tool_handler": {
  "class": "bots.foundation.anthropic_bots.AnthropicToolHandler",
  "tools": [
   {
    "name": "add_imports",
    "description": "Adds multiple import statements to a Python file.\nCreates the file if it doesn't exist.\nAvoids adding duplicate imports.\n\nParameters:\n- file_path (str): The path to the file where the imports will be added\n- code (str): Import statements, which can include parenthesized multi-line imports\n\nReturns a confirmation message or an error message.\n\ncost: very low",
    "input_schema": {
     "type": "object",
     "properties": {
      "file_path": {
       "type": "string"
      },
      "code": {
       "type": "string"
      }
     },
     "required": [
      "file_path",
      "code"
     ]
    }
   },
   {
    "name": "remove_import",
    "description": "Removes an import statement from a Python file.\n\nParameters:\n- file_path (str): The path to the file to modify\n- import_to_remove (str): The import statement to remove (e.g., \"import os\" or \"from typing import List\")\n    Must match the existing import statement exactly.\n\nReturns a confirmation message or an error message.\n\ncost: very low",
    "input_schema": {
     "type": "object",
     "properties": {
      "file_path": {
       "type": "string"
      },
      "import_to_remove": {
       "type": "string"
      }
     },
     "required": [
      "file_path",
      "import_to_remove"
     ]
    }
   },
   {
    "name": "replace_import",
    "description": "Replaces an existing import statement in a Python file.\n\nParameters:\n- file_path (str): The path to the file to modify\n- old_import (str): The existing import statement to replace\n- new_import (str): The new import statement\n\nReturns a confirmation message or an error message.\n\ncost: very low",
    "input_schema": {
     "type": "object",
     "properties": {
      "file_path": {
       "type": "string"
      },
      "old_import": {
       "type": "string"
      },
      "new_import": {
       "type": "string"
      }
     },
     "required": [
      "file_path",
      "old_import",
      "new_import"
     ]
    }
   },
   {
    "name": "add_class",
    "description": "Adds a new class definition to an existing Python file.\nCreates the file if it doesn't exist.\n\nParameters:\n- file_path (str): The path to the file where the new class will be added\n- class_def (str): The new class definition as a string\n\nReturns a confirmation message or an error message.\n\ncost: low",
    "input_schema": {
     "type": "object",
     "properties": {
      "file_path": {
       "type": "string"
      },
      "class_def": {
       "type": "string"
      }
     },
     "required": [
      "file_path",
      "class_def"
     ]
    }
   },
   {
    "name": "replace_class",
    "description": "Replaces a class definition in a file with a new class definition.\nCreates the file if it doesn't exist.\n\nParameters:\n- file_path (str): The path to the file to modify\n- new_class_def (str): The new class definition\n- old_class_name (str, optional): The name of the class to replace\n\nReturns a confirmation message or an error message.\n\ncost: low",
    "input_schema": {
     "type": "object",
     "properties": {
      "file_path": {
       "type": "string"
      },
      "new_class_def": {
       "type": "string"
      },
      "old_class_name": {
       "type": "string"
      }
     },
     "required": [
      "file_path",
      "new_class_def"
     ]
    }
   },
   {
    "name": "add_function_to_class",
    "description": "Adds one or more methods to an existing class in a Python file.\nCreates the file and class if they don't exist.\n\nParameters:\n- file_path (str): The path to the file to modify\n- class_name (str): The name of the class to modify\n- new_method_def (str): One or more method definitions as a string\n\nReturns a confirmation message or an error message.\n\ncost: very low",
    "input_schema": {
     "type": "object",
     "properties": {
      "file_path": {
       "type": "string"
      },
      "class_name": {
       "type": "string"
      },
      "new_method_def": {
       "type": "string"
      }
     },
     "required": [
      "file_path",
      "class_name",
      "new_method_def"
     ]
    }
   },
   {
    "name": "add_function_to_file",
    "description": "Adds one or more function definitions to an existing Python file.\nCreates the file if it doesn't exist.\n\nWhen adding complex code blocks:\n- Imports are moved to the top of the file\n- Functions are added in order of appearance\n- Non-function code (assignments, if blocks, etc.) is preserved but may be reordered\n- Comments are not preserved (limitation of AST)\n\nParameters:\n- file_path (str): The path to the file to modify\n- new_function_def (str): One or more function definitions as a string\n- class_name (str, optional): If provided, add functions to this class\n\nReturns a confirmation message or an error message.\n\ncost: very low",
    "input_schema": {
     "type": "object",
     "properties": {
      "file_path": {
       "type": "string"
      },
      "new_function_def": {
       "type": "string"
      },
      "class_name": {
       "type": "string"
      }
     },
     "required": [
      "file_path",
      "new_function_def"
     ]
    }
   },
   {
    "name": "replace_function",
    "description": "Replaces one or more function definitions in a file with new function definitions.\nCreates the file if it doesn't exist.\n\nParameters:\n- file_path (str): The path to the file to modify\n- new_function_def (str): One or more function definitions as a string\n- class_name (str, optional): If provided, only replace functions within this class\n\nReturns a confirmation message or an error message.\n\ncost: very low",
    "input_schema": {
     "type": "object",
     "properties": {
      "file_path": {
       "type": "string"
      },
      "new_function_def": {
       "type": "string"
      },
      "class_name": {
       "type": "string"
      }
     },
     "required": [
      "file_path",
      "new_function_def"
     ]
    }
   },
   {
    "name": "view",
    "description": "Display the contents of a file with line numbers.\n\nParameters:\n- file_path (str): The path to the file to be viewed.\n- max_lines (int, optional): Maximum number of lines to display. Defaults to 2500.\n\nReturns:\nA string containing the file contents with line numbers.\n\ncost: varies",
    "input_schema": {
     "type": "object",
     "properties": {
      "file_path": {
       "type": "string"
      },
      "max_lines": {
       "type": "string"
      }
     },
     "required": [
      "file_path"
     ]
    }
   },
   {
    "name": "view_dir",
    "description": "Creates a summary of the directory structure starting from the given path, writing only files \nwith specified extensions and showing venv directories without their contents.\n\nParameters:\n- start_path (str): The root directory to start scanning from.\n- output_file (str): The name of the file to optionally write the directory structure to.\n- target_extensions (str): String representation of a list of file extensions (e.g. \"['py', 'txt']\").\n\nReturns:\nstr: A formatted string containing the directory structure, with each directory and file properly indented.\n\nExample output:\nmy_project/\n    venv/\n    module1/\n        script.py\n        README.md\n    module2/\n        utils.py\n\ncost: low",
    "input_schema": {
     "type": "object",
     "properties": {
      "start_path": {
       "type": "string"
      },
      "output_file": {
       "type": "string"
      },
      "target_extensions": {
       "type": "string"
      }
     },
     "required": []
    }
   },
   {
    "name": "diff_edit",
    "description": "Diff spec editing with flexible matching.\n\nUse when you need to make precision changes in text files.\n\nParameters:\n- file_path (str): Path to the file to modify\n- diff_spec (str): Diff-style specification of changes. \nInput lines beginning with '-' are removed, and input lines \nbeginning with '+' are added at the starting index of the \nremoved lines. All lines must start with + or -, and white\nspace must be matched exactly.\n\nReturns:\nstr: Description of changes made/to be made or error message with context\n\nex) diff_spec:\n-import numpy\n+import scipy\n\ncost: medium",
    "input_schema": {
     "type": "object",
     "properties": {
      "file_path": {
       "type": "string"
      },
      "diff_spec": {
       "type": "string"
      }
     },
     "required": [
      "file_path",
      "diff_spec"
     ]
    }
   },
   {
    "name": "execute_powershell",
    "description": "Executes PowerShell commands in a stateful environment\n\nUse when you need to run PowerShell commands and capture their output. If\nyou have other tools available, you should use this as a fallback when the\nother tools fail. Coerces to utf-8.\n\nPotential use cases:\n- git commands\n- gh cli\n- other cli (which you may need to install using this tool)\n\nParameters:\n- command (str): PowerShell command to execute.\n- output_length_limit (int, optional): Maximum number of lines in the output.\n  If set, output exceeding this limit will be truncated. Default 120.\n\nReturns:\n    str: The complete output from the command execution",
    "input_schema": {
     "type": "object",
     "properties": {
      "command": {
       "type": "string"
      },
      "output_length_limit": {
       "type": "string"
      }
     },
     "required": [
      "command"
     ]
    },
    "cache_control": {
     "type": "ephemeral"
    }
   }
  ],
  "requests": [
   {
    "type": "tool_use",
    "id": "toolu_01TdG8bHkAbX9SmEWB3JGcQn",
    "name": "replace_function",
    "input": {
     "file_path": "bots/utils/doc_checker.py",
     "new_function_def": "def find_python_files(start_path: str) -> List[str]:\n    \"\"\"\n    Recursively find all Python files in a directory, excluding tools and files with 'tool' in the name.\n    \n    Args:\n        start_path (str): Root directory to start search from\n        \n    Returns:\n        List[str]: List of paths to Python files\n    \"\"\"\n    python_files = []\n    for root, _, files in os.walk(start_path):\n        # Skip the tools directory and any directory with 'tool' in the name\n        if 'tool' in root.lower():\n            continue\n            \n        for file in files:\n            # Skip files with 'tool' in the name\n            if file.endswith('.py') and 'tool' not in file.lower():\n                python_files.append(os.path.join(root, file))\n    return python_files"
    }
   }
  ],
  "results": [
   {
    "type": "tool_result",
    "tool_use_id": "toolu_01TdG8bHkAbX9SmEWB3JGcQn",
    "content": "Function 'find_python_files' has been replaced in file 'C:\\Users\\benbu\\Code\\llm-utilities-git\\bots\\bots\\utils\\doc_checker.py'."
   }
  ],
  "modules": {
   "C:\\Users\\benbu\\Code\\llm-utilities-git\\bots\\bots\\tools\\python_editing_tools.py": {
    "name": "dynamic_module_f294dc0271581cb3881a385b87e7c2f6",
    "source": "import ast\nimport os\nfrom bots.utils.helpers import _process_error, _clean, _py_ast_to_source\n\nclass NodeTransformerWithAsyncSupport(ast.NodeTransformer):\n    \"\"\"Base class for AST transformers that need to handle both sync and async functions.\"\"\"\n\n    def __init__(self):\n        self.success = False\n\n    def visit_FunctionDef(self, node):\n        return self._handle_function(node)\n\n    def visit_AsyncFunctionDef(self, node):\n        return self._handle_function(node)\n\n    def _handle_function(self, node):\n        \"\"\"Override this method in subclasses to implement specific transformation logic\"\"\"\n        raise NotImplementedError\n\n\nclass FunctionReplacer(NodeTransformerWithAsyncSupport):\n\n    def __init__(self, new_func_node):\n        super().__init__()\n        self.new_func_node = new_func_node\n\n    def _handle_function(self, node):\n        if node.name == self.new_func_node.name:\n            self.success = True\n            return self.new_func_node\n        return node\n\n\nclass MethodAdder(NodeTransformerWithAsyncSupport):\n\n    def __init__(self, class_name, new_method_node):\n        super().__init__()\n        self.class_name = class_name\n        self.new_method_node = new_method_node\n\n    def visit_ClassDef(self, node):\n        if node.name == self.class_name:\n            self.success = True\n            node.body.append(self.new_method_node)\n            return node\n        return node\n\n    def _handle_function(self, node):\n        return node\n\n\ndef add_imports(file_path: str, code: str) ->str:\n    \"\"\"\n    Adds multiple import statements to a Python file.\n    Creates the file if it doesn't exist.\n    Avoids adding duplicate imports.\n\n    Parameters:\n    - file_path (str): The path to the file where the imports will be added\n    - code (str): Import statements, which can include parenthesized multi-line imports\n\n    Returns a confirmation message or an error message.\n\n    cost: very low\n    \"\"\"\n    try:\n        abs_path = _make_file(file_path)\n        lines = code.strip().split('\\n')\n        import_blocks = []\n        current_block = []\n        in_parentheses = False\n        for line in lines:\n            stripped = line.strip()\n            if not stripped:\n                continue\n            if '(' in stripped and not stripped.endswith(')'):\n                in_parentheses = True\n                current_block.append(stripped)\n            elif ')' in stripped and in_parentheses:\n                in_parentheses = False\n                current_block.append(stripped)\n                import_blocks.append('\\n'.join(current_block))\n                current_block = []\n            elif in_parentheses:\n                current_block.append(stripped)\n            elif current_block:\n                current_block.append(stripped)\n            else:\n                import_blocks.append(stripped)\n        if current_block:\n            import_blocks.append('\\n'.join(current_block))\n        new_import_nodes = []\n        for stmt in import_blocks:\n            try:\n                node = ast.parse(_clean(stmt)).body[0]\n                if not isinstance(node, (ast.Import, ast.ImportFrom)):\n                    return _process_error(ValueError(\n                        f'Invalid import statement: {stmt}'))\n                new_import_nodes.append(node)\n            except Exception as e:\n                return _process_error(ValueError(\n                    f'Error parsing import statement \"{stmt}\": {str(e)}'))\n        try:\n            with open(abs_path, 'r', encoding='utf-8') as file:\n                content = file.read()\n        except Exception as e:\n            return _process_error(ValueError(\n                f'Error reading file {abs_path}: {str(e)}'))\n        if not content.strip():\n            with open(abs_path, 'w', encoding='utf-8') as file:\n                file.write('\\n'.join(import_blocks) + '\\n')\n            return (\n                f\"{len(import_blocks)} imports have been added to new file '{abs_path}'.\"\n                )\n        try:\n            tree = ast.parse(content)\n        except Exception as e:\n            return _process_error(ValueError(\n                f'Error parsing the file {abs_path}: {str(e)}'))\n        added_imports = []\n        existing_imports = []\n\n        def normalize_import(node):\n            \"\"\"Helper to normalize import node to string for comparison\"\"\"\n            return _py_ast_to_source(node).strip().replace(' ', '')\n        for new_node in new_import_nodes:\n            new_stmt_normalized = normalize_import(new_node)\n            is_duplicate = False\n            for existing_node in tree.body:\n                if isinstance(existing_node, (ast.Import, ast.ImportFrom)):\n                    if normalize_import(existing_node) == new_stmt_normalized:\n                        existing_imports.append(_py_ast_to_source(new_node).strip())\n                        is_duplicate = True\n                        break\n            if not is_duplicate:\n                added_imports.append(_py_ast_to_source(new_node).strip())\n        if added_imports:\n            last_import_idx = -1\n            for i, node in enumerate(tree.body):\n                if isinstance(node, (ast.Import, ast.ImportFrom)):\n                    last_import_idx = i\n            for node in new_import_nodes:\n                if _py_ast_to_source(node).strip() in added_imports:\n                    tree.body.insert(last_import_idx + 1, node)\n                    last_import_idx += 1\n            try:\n                updated_content = _py_ast_to_source(tree)\n                with open(abs_path, 'w', encoding='utf-8') as file:\n                    file.write(updated_content)\n            except Exception as e:\n                return _process_error(e)\n        result_parts = []\n        if added_imports:\n            result_parts.append(\n                f\"Added {len(added_imports)} new imports to '{abs_path}'\")\n        if existing_imports:\n            result_parts.append(\n                f'Found {len(existing_imports)} existing imports')\n        if not result_parts:\n            raise ValueError('No valid import statements found')\n        return '. '.join(result_parts) + '.'\n    except Exception as e:\n        return _process_error(e)\n\n\ndef remove_import(file_path: str, import_to_remove: str) ->str:\n    \"\"\"\n    Removes an import statement from a Python file.\n    \n    Parameters:\n    - file_path (str): The path to the file to modify\n    - import_to_remove (str): The import statement to remove (e.g., \"import os\" or \"from typing import List\")\n        Must match the existing import statement exactly.\n\n    Returns a confirmation message or an error message.\n\n    cost: very low\n    \"\"\"\n    if not os.path.exists(file_path):\n        return _process_error(ValueError(f'File {file_path} does not exist'))\n    try:\n        remove_node = ast.parse(import_to_remove).body[0]\n        if not isinstance(remove_node, (ast.Import, ast.ImportFrom)):\n            return _process_error(ValueError(\n                'Provided statement is not a valid import'))\n    except Exception as e:\n        return _process_error(ValueError(\n            f'Error parsing import statement: {str(e)}'))\n    try:\n        with open(file_path, 'r', encoding='utf-8') as file:\n            content = file.read()\n        tree = ast.parse(content)\n    except Exception as e:\n        return _process_error(ValueError(\n            f'Error parsing the file {file_path}: {str(e)}'))\n    original_length = len(tree.body)\n    new_body = []\n    found = False\n    for node in tree.body:\n        if isinstance(node, (ast.Import, ast.ImportFrom)):\n            node_str = _py_ast_to_source(node).strip()\n            if node_str == import_to_remove:\n                found = True\n                continue\n        new_body.append(node)\n    if not found:\n        return f\"Import '{import_to_remove}' not found in '{file_path}'.\"\n    tree.body = new_body\n    try:\n        updated_content = _py_ast_to_source(tree)\n        with open(file_path, 'w', encoding='utf-8') as file:\n            file.write(updated_content)\n    except Exception as e:\n        return _process_error(e)\n    return f\"Import '{import_to_remove}' has been removed from '{file_path}'.\"\n\n\ndef replace_import(file_path: str, old_import: str, new_import: str) ->str:\n    \"\"\"\n    Replaces an existing import statement in a Python file.\n    \n    Parameters:\n    - file_path (str): The path to the file to modify\n    - old_import (str): The existing import statement to replace\n    - new_import (str): The new import statement\n\n    Returns a confirmation message or an error message.\n\n    cost: very low\n    \"\"\"\n    if not os.path.exists(file_path):\n        return _process_error(ValueError(f'File {file_path} does not exist'))\n    try:\n        old_node = ast.parse(_clean(old_import)).body[0]\n        new_node = ast.parse(_clean(new_import)).body[0]\n        if not isinstance(old_node, (ast.Import, ast.ImportFrom)\n            ) or not isinstance(new_node, (ast.Import, ast.ImportFrom)):\n            return _process_error(ValueError(\n                'Both statements must be valid imports'))\n    except Exception as e:\n        return _process_error(ValueError(\n            f'Error parsing import statements: {str(e)}'))\n    try:\n        with open(file_path, 'r', encoding='utf-8') as file:\n            content = file.read()\n        tree = ast.parse(content)\n    except Exception as e:\n        return _process_error(ValueError(\n            f'Error parsing the file {file_path}: {str(e)}'))\n    found = False\n    for i, node in enumerate(tree.body):\n        if isinstance(node, (ast.Import, ast.ImportFrom)):\n            node_str = _py_ast_to_source(node).strip()\n            if node_str == old_import:\n                tree.body[i] = new_node\n                found = True\n                break\n    if not found:\n        return f\"Import '{old_import}' not found in '{file_path}'.\"\n    try:\n        updated_content = _py_ast_to_source(tree)\n        with open(file_path, 'w', encoding='utf-8') as file:\n            file.write(updated_content)\n    except Exception as e:\n        return _process_error(e)\n    return (\n        f\"Import '{old_import}' has been updated to '{new_import}' in '{file_path}'.\"\n        )\n\n\ndef add_class(file_path: str, class_def: str) ->str:\n    \"\"\"\n    Adds a new class definition to an existing Python file.\n    Creates the file if it doesn't exist.\n\n    Parameters:\n    - file_path (str): The path to the file where the new class will be added\n    - class_def (str): The new class definition as a string\n\n    Returns a confirmation message or an error message.\n\n    cost: low\n    \"\"\"\n    try:\n        abs_path = _make_file(file_path)\n        try:\n            new_tree = ast.parse(_clean(class_def))\n            new_class_node = None\n            for node in new_tree.body:\n                if isinstance(node, (ast.Import, ast.ImportFrom)):\n                    add_imports(file_path, _py_ast_to_source(node).strip())\n                elif isinstance(node, ast.ClassDef):\n                    new_class_node = node\n            if new_class_node is None:\n                return _process_error(ValueError(\n                    'No class definition found in provided code'))\n            with open(abs_path, 'r', encoding='utf-8') as file:\n                content = file.read()\n            tree = ast.parse(content)\n        except Exception as e:\n            return _process_error(ValueError(\n                f'Error processing code: {str(e)}'))\n        tree.body.append(new_class_node)\n        try:\n            updated_content = _py_ast_to_source(tree)\n            with open(abs_path, 'w', encoding='utf-8') as file:\n                file.write(updated_content)\n        except Exception as e:\n            return _process_error(e)\n        return f\"Class '{new_class_node.name}' has been added to '{abs_path}'.\"\n    except Exception as e:\n        return _process_error(e)\n\n\ndef replace_class(file_path: str, new_class_def: str, old_class_name: str=None\n    ) ->str:\n    \"\"\"\n    Replaces a class definition in a file with a new class definition.\n    Creates the file if it doesn't exist.\n\n    Parameters:\n    - file_path (str): The path to the file to modify\n    - new_class_def (str): The new class definition\n    - old_class_name (str, optional): The name of the class to replace\n\n    Returns a confirmation message or an error message.\n\n    cost: low\n    \"\"\"\n    try:\n        abs_path = _make_file(file_path)\n        try:\n            new_tree = ast.parse(_clean(new_class_def))\n            new_class_node = None\n            for node in new_tree.body:\n                if isinstance(node, (ast.Import, ast.ImportFrom)):\n                    add_imports(file_path, _py_ast_to_source(node).strip())\n                elif isinstance(node, ast.ClassDef):\n                    new_class_node = node\n                    if old_class_name is None:\n                        old_class_name = node.name\n            if new_class_node is None:\n                return _process_error(ValueError(\n                    'No class definition found in provided code'))\n            with open(abs_path, 'r', encoding='utf-8') as file:\n                content = file.read()\n            tree = ast.parse(content)\n        except Exception as e:\n            return _process_error(ValueError(\n                f'Error processing code: {str(e)}'))\n\n\n        class ClassReplacer(NodeTransformerWithAsyncSupport):\n\n            def visit_ClassDef(self, node):\n                if node.name == old_class_name:\n                    self.success = True\n                    return new_class_node\n                return node\n\n            def _handle_function(self, node):\n                return node\n        transformer = ClassReplacer()\n        tree = transformer.visit(tree)\n        if not transformer.success:\n            tree.body.append(new_class_node)\n        try:\n            updated_content = _py_ast_to_source(tree)\n            with open(abs_path, 'w', encoding='utf-8') as file:\n                file.write(updated_content)\n        except Exception as e:\n            return _process_error(e)\n        action = 'replaced in' if transformer.success else 'added to'\n        return f\"Class '{new_class_node.name}' has been {action} '{abs_path}'.\"\n    except Exception as e:\n        return _process_error(e)\n\n\ndef add_function_to_class(file_path: str, class_name: str, new_method_def: str\n    ) ->str:\n    \"\"\"\n    Adds one or more methods to an existing class in a Python file.\n    Creates the file and class if they don't exist.\n\n    Parameters:\n    - file_path (str): The path to the file to modify\n    - class_name (str): The name of the class to modify\n    - new_method_def (str): One or more method definitions as a string\n\n    Returns a confirmation message or an error message.\n\n    cost: very low\n    \"\"\"\n    try:\n        tree = ast.parse(_clean(new_method_def))\n        messages = []\n        for node in tree.body:\n            if isinstance(node, (ast.Import, ast.ImportFrom)):\n                add_imports(file_path, _py_ast_to_source(node).strip())\n        found_method = False\n        for node in tree.body:\n            if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):\n                found_method = True\n                method_source = _py_ast_to_source(node)\n                result = _add_single_function_to_class(file_path,\n                    class_name, method_source)\n                messages.append(result)\n        if not found_method:\n            return _process_error(ValueError(\n                'No method definitions found in provided code'))\n        return '\\n'.join(messages)\n    except Exception as e:\n        return _process_error(e)\n\n\ndef add_function_to_file(file_path: str, new_function_def: str, class_name:\n    str=None) ->str:\n    \"\"\"\n    Adds one or more function definitions to an existing Python file.\n    Creates the file if it doesn't exist.\n\n    When adding complex code blocks:\n    - Imports are moved to the top of the file\n    - Functions are added in order of appearance\n    - Non-function code (assignments, if blocks, etc.) is preserved but may be reordered\n    - Comments are not preserved (limitation of AST)\n\n    Parameters:\n    - file_path (str): The path to the file to modify\n    - new_function_def (str): One or more function definitions as a string\n    - class_name (str, optional): If provided, add functions to this class\n\n    Returns a confirmation message or an error message.\n\n    cost: very low\n    \"\"\"\n    try:\n        tree = ast.parse(_clean(new_function_def))\n        messages = []\n        for node in tree.body:\n            if isinstance(node, (ast.Import, ast.ImportFrom)):\n                add_imports(file_path, _py_ast_to_source(node).strip())\n        found_function = False\n        remaining_nodes = []\n        for node in tree.body:\n            if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):\n                found_function = True\n                function_source = _py_ast_to_source(node)\n                if class_name:\n                    result = add_function_to_class(file_path, class_name,\n                        function_source)\n                else:\n                    result = _add_single_function_to_file(file_path,\n                        function_source)\n                messages.append(result)\n            elif not isinstance(node, (ast.Import, ast.ImportFrom)):\n                remaining_nodes.append(node)\n        if not found_function:\n            return _process_error(ValueError(\n                'No function definitions found in provided code'))\n        if remaining_nodes:\n            with open(file_path, 'r', encoding='utf-8') as file:\n                content = file.read()\n            existing_tree = ast.parse(content)\n            existing_tree.body.extend(remaining_nodes)\n            updated_content = _py_ast_to_source(existing_tree)\n            with open(file_path, 'w', encoding='utf-8') as file:\n                file.write(updated_content)\n            messages.append(\n                f'Added {len(remaining_nodes)} additional code blocks')\n        return '\\n'.join(messages)\n    except Exception as e:\n        return _process_error(e)\n\n\ndef replace_function(file_path: str, new_function_def: str, class_name: str\n    =None) ->str:\n    \"\"\"\n    Replaces one or more function definitions in a file with new function definitions.\n    Creates the file if it doesn't exist.\n\n    Parameters:\n    - file_path (str): The path to the file to modify\n    - new_function_def (str): One or more function definitions as a string\n    - class_name (str, optional): If provided, only replace functions within this class\n\n    Returns a confirmation message or an error message.\n\n    cost: very low\n    \"\"\"\n    try:\n        tree = ast.parse(_clean(new_function_def))\n        messages = []\n        for node in tree.body:\n            if isinstance(node, (ast.Import, ast.ImportFrom)):\n                add_imports(file_path, _py_ast_to_source(node).strip())\n        found_function = False\n        for node in tree.body:\n            if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):\n                found_function = True\n                function_source = _py_ast_to_source(node)\n                result = _replace_single_function(file_path,\n                    function_source, class_name)\n                messages.append(result)\n        if not found_function:\n            return _process_error(ValueError(\n                'No function definitions found in provided code'))\n        return '\\n'.join(messages)\n    except Exception as e:\n        return _process_error(e)\n\n\ndef _make_file(file_path: str) ->str:\n    \"\"\"\n    Creates a file and its parent directories if they don't exist.\n    Converts relative paths to absolute paths.\n    \n    Parameters:\n    - file_path (str): The path to the file to be created\n    \n    Returns:\n    - str: The absolute path to the file\n    \n    Raises:\n    - ValueError: If there's an error creating the file or directories,\n                 or if the file_path is empty\n    \"\"\"\n    if not file_path:\n        raise ValueError('File path cannot be empty')\n    abs_path = os.path.abspath(file_path)\n    dir_path = os.path.dirname(abs_path)\n    if dir_path:\n        try:\n            os.makedirs(dir_path, exist_ok=True)\n        except Exception as e:\n            raise ValueError(f'Error creating directories {dir_path}: {str(e)}'\n                )\n    if not os.path.exists(abs_path):\n        try:\n            with open(abs_path, 'w', encoding='utf-8') as f:\n                f.write('')\n        except Exception as e:\n            raise ValueError(f'Error creating file {abs_path}: {str(e)}')\n    return abs_path\n\n\ndef _add_single_function_to_class(file_path: str, class_name: str,\n    new_method_def: str) ->str:\n    \"\"\"Adds a single method to a class.\"\"\"\n    try:\n        abs_path = _make_file(file_path)\n        try:\n            new_tree = ast.parse(_clean(new_method_def))\n            new_method_node = None\n            for node in new_tree.body:\n                if isinstance(node, (ast.Import, ast.ImportFrom)):\n                    add_imports(file_path, _py_ast_to_source(node).strip())\n                elif isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):\n                    new_method_node = node\n            if new_method_node is None:\n                return _process_error(ValueError(\n                    'No method definition found in provided code'))\n            with open(abs_path, 'r', encoding='utf-8') as file:\n                content = file.read()\n            if not content.strip():\n                content = f'class {class_name}:\\n    pass\\n'\n            tree = ast.parse(content)\n        except Exception as e:\n            return _process_error(ValueError(\n                f'Error processing code: {str(e)}'))\n        transformer = MethodAdder(class_name, new_method_node)\n        tree = transformer.visit(tree)\n        if not transformer.success:\n            return _process_error(ValueError(\n                f\"Class '{class_name}' not found in the file.\"))\n        try:\n            updated_content = _py_ast_to_source(tree)\n            with open(abs_path, 'w', encoding='utf-8') as file:\n                file.write(updated_content)\n        except Exception as e:\n            return _process_error(e)\n        return (\n            f\"Method '{new_method_node.name}' has been added to class '{class_name}' in '{abs_path}'.\"\n            )\n    except Exception as e:\n        return _process_error(e)\n\n\ndef _add_single_function_to_file(file_path: str, new_function_def: str) ->str:\n    \"\"\"Adds a single function and preserves all code blocks, including any code following the function.\"\"\"\n    try:\n        abs_path = _make_file(file_path)\n        try:\n            new_tree = ast.parse(_clean(new_function_def))\n            new_func_node = None\n            found_func = False\n            new_nodes = []\n            for node in new_tree.body:\n                if not found_func and isinstance(node, (ast.FunctionDef,\n                    ast.AsyncFunctionDef)):\n                    new_func_node = node\n                    found_func = True\n                elif found_func:\n                    new_nodes.append(node)\n            if not new_func_node:\n                return _process_error(ValueError(\n                    'No function definition found in provided code'))\n        except Exception as e:\n            return _process_error(ValueError(f'Error in code: {str(e)}'))\n        with open(abs_path, 'r', encoding='utf-8') as file:\n            content = file.read()\n        if not content.strip():\n            try:\n                with open(abs_path, 'w', encoding='utf-8') as file:\n                    file.write(_py_ast_to_source(new_tree))\n                return (\n                    f\"Code with function '{new_func_node.name}' has been added to new file '{abs_path}'.\"\n                    )\n            except Exception as e:\n                return _process_error(e)\n        try:\n            existing_tree = ast.parse(content)\n            combined_body = []\n            imports = []\n            for node in (existing_tree.body + new_tree.body):\n                if isinstance(node, (ast.Import, ast.ImportFrom)):\n                    imports.append(node)\n            combined_body.extend(imports)\n            for node in existing_tree.body:\n                if not isinstance(node, (ast.Import, ast.ImportFrom)):\n                    combined_body.append(node)\n            combined_body.append(new_func_node)\n            combined_body.extend(new_nodes)\n            combined_tree = ast.Module(body=combined_body, type_ignores=[])\n            updated_content = _py_ast_to_source(combined_tree)\n            with open(abs_path, 'w', encoding='utf-8') as file:\n                file.write(updated_content)\n        except Exception as e:\n            return _process_error(e)\n        return (\n            f\"Code with function '{new_func_node.name}' has been added to '{abs_path}'.\"\n            )\n    except Exception as e:\n        return _process_error(e)\n\n\ndef _replace_single_function(file_path: str, new_function_def: str,\n    class_name: str=None) ->str:\n    \"\"\"Replaces a single function in a file, optionally within a specific class.\n    \n    Args:\n        file_path: Path to the file to modify\n        new_function_def: The new function definition\n        class_name: If provided, only replace within this class\n    \"\"\"\n    try:\n        abs_path = _make_file(file_path)\n        try:\n            new_tree = ast.parse(_clean(new_function_def))\n            new_func_node = None\n            for node in new_tree.body:\n                if isinstance(node, (ast.Import, ast.ImportFrom)):\n                    add_imports(file_path, _py_ast_to_source(node).strip())\n                elif isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):\n                    new_func_node = node\n            if new_func_node is None:\n                return _process_error(ValueError(\n                    'No function definition found in provided code'))\n            with open(abs_path, 'r', encoding='utf-8') as file:\n                content = file.read()\n            tree = ast.parse(content)\n        except Exception as e:\n            return _process_error(ValueError(\n                f'Error processing code: {str(e)}'))\n\n\n        class ClassScopedFunctionReplacer(ast.NodeTransformer):\n\n            def __init__(self, new_func_node, target_class=None):\n                self.new_func_node = new_func_node\n                self.target_class = target_class\n                self.success = False\n                self.in_target_class = False\n\n            def visit_ClassDef(self, node):\n                if self.target_class is None or node.name == self.target_class:\n                    old_in_target_class = self.in_target_class\n                    self.in_target_class = True\n                    node = self.generic_visit(node)\n                    self.in_target_class = old_in_target_class\n                return node\n\n            def visit_FunctionDef(self, node):\n                if node.name == self.new_func_node.name:\n                    if self.target_class is None or self.in_target_class:\n                        self.success = True\n                        return self.new_func_node\n                return node\n\n            def visit_AsyncFunctionDef(self, node):\n                return self.visit_FunctionDef(node)\n        transformer = ClassScopedFunctionReplacer(new_func_node, class_name)\n        tree = transformer.visit(tree)\n        if not transformer.success:\n            if class_name:\n                return _process_error(ValueError(\n                    f\"Function '{new_func_node.name}' not found in class '{class_name}'\"\n                    ))\n            tree.body.append(new_func_node)\n        try:\n            updated_content = _py_ast_to_source(tree)\n            with open(abs_path, 'w', encoding='utf-8') as file:\n                file.write(updated_content)\n        except Exception as e:\n            return _process_error(e)\n        context = f\"in class '{class_name}'\" if class_name else 'in file'\n        action = 'replaced' if transformer.success else 'added'\n        return (\n            f\"Function '{new_func_node.name}' has been {action} {context} '{abs_path}'.\"\n            )\n    except Exception as e:\n        return _process_error(e)\n",
    "file_path": "C:\\Users\\benbu\\Code\\llm-utilities-git\\bots\\bots\\tools\\python_editing_tools.py",
    "code_hash": "68b3597f7d7732f436a92cebe4e651b7",
    "globals": {
     "ast": "<module 'ast' from 'C:\\\\Users\\\\benbu\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312-arm64\\\\Lib\\\\ast.py'>",
     "os": "<module 'os' (frozen)>",
     "_process_error": "<function _process_error at 0x000001DF632CFBA0>",
     "_clean": "<function _clean at 0x000001DF632E4540>",
     "_py_ast_to_source": "<function _py_ast_to_source at 0x000001DF632E6A20>",
     "NodeTransformerWithAsyncSupport": "<class 'dynamic_module_f294dc0271581cb3881a385b87e7c2f6.NodeTransformerWithAsyncSupport'>",
     "FunctionReplacer": "<class 'dynamic_module_f294dc0271581cb3881a385b87e7c2f6.FunctionReplacer'>",
     "MethodAdder": "<class 'dynamic_module_f294dc0271581cb3881a385b87e7c2f6.MethodAdder'>",
     "add_imports": "<function add_imports at 0x000001DF656E6200>",
     "remove_import": "<function remove_import at 0x000001DF656E68E0>",
     "replace_import": "<function replace_import at 0x000001DF656E6980>",
     "add_class": "<function add_class at 0x000001DF656E6A20>",
     "replace_class": "<function replace_class at 0x000001DF656E6AC0>",
     "add_function_to_class": "<function add_function_to_class at 0x000001DF656E6B60>",
     "add_function_to_file": "<function add_function_to_file at 0x000001DF656E6C00>",
     "replace_function": "<function replace_function at 0x000001DF656E6CA0>",
     "_make_file": "<function _make_file at 0x000001DF656E6D40>",
     "_add_single_function_to_class": "<function _add_single_function_to_class at 0x000001DF656E6DE0>",
     "_add_single_function_to_file": "<function _add_single_function_to_file at 0x000001DF656E6E80>",
     "_replace_single_function": "<function _replace_single_function at 0x000001DF656E6F20>"
    }
   },
   "C:\\Users\\benbu\\Code\\llm-utilities-git\\bots\\bots\\tools\\code_tools.py": {
    "name": "dynamic_module_9ed125295933273528d22ebd82cdc6ad",
    "source": "import os\nimport traceback\nimport textwrap\n\ndef view(file_path: str, max_lines: int = 2500):\n    \"\"\"\n    Display the contents of a file with line numbers.\n\n    Parameters:\n    - file_path (str): The path to the file to be viewed.\n    - max_lines (int, optional): Maximum number of lines to display. Defaults to 2500.\n\n    Returns:\n    A string containing the file contents with line numbers.\n\n    cost: varies\n    \"\"\"\n    encodings = ['utf-8', 'utf-16', 'utf-16le', 'ascii', 'cp1252', 'iso-8859-1']\n    for encoding in encodings:\n        try:\n            with open(file_path, 'r', encoding=encoding) as file:\n                lines = file.readlines()\n                if len(lines) > max_lines:\n                    return f'Error: File has {len(lines)} lines, which exceeds the maximum of {max_lines} lines.'\n                numbered_lines = [f'{i + 1}:{line.rstrip()}' for i, line in enumerate(lines)]\n                return '\\n'.join(numbered_lines)\n        except UnicodeDecodeError:\n            continue\n        except Exception as e:\n            return f'Error: {str(e)}'\n    return f\"Error: Unable to read file with any of the attempted encodings: {', '.join(encodings)}\"\n\n\ndef view_dir(start_path: str='.', output_file=None, target_extensions: str=\"['py', 'txt', '.md']\"):\n    \"\"\"\n    Creates a summary of the directory structure starting from the given path, writing only files \n    with specified extensions and showing venv directories without their contents.\n\n    Parameters:\n    - start_path (str): The root directory to start scanning from.\n    - output_file (str): The name of the file to optionally write the directory structure to.\n    - target_extensions (str): String representation of a list of file extensions (e.g. \"['py', 'txt']\").\n\n    Returns:\n    str: A formatted string containing the directory structure, with each directory and file properly indented.\n\n    Example output:\n    my_project/\n        venv/\n        module1/\n            script.py\n            README.md\n        module2/\n            utils.py\n    \n    cost: low\n    \"\"\"\n    extensions_list = [ext.strip().strip('\\'\"') for ext in target_extensions.strip('[]').split(',')]\n    extensions_list = [('.' + ext if not ext.startswith('.') else ext) for ext in extensions_list]\n    output_text = []\n\n    for root, dirs, files in os.walk(start_path):\n        level = root.replace(start_path, '').count(os.sep)\n        indent = '    ' * level\n        basename = os.path.basename(root)\n\n        # Check if current directory is a venv\n        is_venv = basename in ['venv', 'env', '.env'] or 'pyvenv.cfg' in files\n\n        if is_venv:\n            # Add venv directory without scanning its contents\n            line = f'{indent}{basename}/'\n            output_text.append(line)\n            dirs[:] = []  # Skip processing contents of venv\n            continue\n\n        has_relevant_files = False\n        for _, _, fs in os.walk(root):\n            if any(f.endswith(tuple(extensions_list)) for f in fs):\n                has_relevant_files = True\n                break\n\n        if has_relevant_files:\n            line = f'{indent}{basename}/'\n            output_text.append(line)\n            subindent = '    ' * (level + 1)\n            for file in files:\n                if file.endswith(tuple(extensions_list)):\n                    line = f'{subindent}{file}'\n                    output_text.append(line)\n\n    if output_file is not None:\n        with open(output_file, 'w') as file:\n            file.write('\\n'.join(output_text))\n            \n    return '\\n'.join(output_text)\n\ndef diff_edit(file_path: str, diff_spec: str):\n    \"\"\"Diff spec editing with flexible matching.\n\n    Use when you need to make precision changes in text files.\n\n    Parameters:\n    - file_path (str): Path to the file to modify\n    - diff_spec (str): Diff-style specification of changes. \n    Input lines beginning with '-' are removed, and input lines \n    beginning with '+' are added at the starting index of the \n    removed lines. All lines must start with + or -, and white\n    space must be matched exactly.\n\n    Returns:\n    str: Description of changes made/to be made or error message with context\n\n    ex) diff_spec:\n    -import numpy\n    +import scipy\n\n    cost: medium\n    \"\"\"\n    ignore_indentation: bool = True\n    context_lines: int = 2\n    try:\n        encodings = ['utf-8', 'utf-16', 'utf-16le', 'ascii', 'cp1252',\n            'iso-8859-1']\n        content = None\n        used_encoding = 'utf-8'\n        if not os.path.exists(file_path):\n            with open(file_path, 'w', encoding=used_encoding) as file:\n                file.write('')\n            content = ''\n        else:\n            for encoding in encodings:\n                try:\n                    with open(file_path, 'r', encoding=encoding) as file:\n                        content = file.read()\n                        used_encoding = encoding\n                        break\n                except UnicodeDecodeError:\n                    continue\n        if content is None:\n            return (\n                f\"Error: Unable to read file with any of the attempted encodings: {', '.join(encodings)}\"\n                )\n        if not diff_spec.strip():\n            return 'Error: No changes specified'\n        changes, errors = _parse_diff_spec(diff_spec=diff_spec)\n        if errors:\n            return 'Error parsing:' + '\\n'.join(errors)\n        original_lines = content.splitlines()\n        current_lines = original_lines.copy()\n        matched_changes = []\n        unmatched_changes = []\n        for remove, add in changes:\n            match_found, line_num, prev_indent, match_score, best_index = (\n                _find_matching_block(current_lines, remove, ignore_indentation)\n                )\n            if match_found:\n                indented_add = _adjust_indentation(add, prev_indent)\n                current_lines[line_num:line_num + len(remove)] = indented_add\n                matched_changes.append(('\\n'.join(remove), '\\n'.join(\n                    indented_add)))\n            else:\n                failure_context = ''\n                if match_score > 0:\n                    context = _get_context(current_lines, best_index,\n                        context_lines)\n                    failure_context = '\\nNearest partial match found around:\\n' + '\\n'.join(context) + f\"\"\"\\n\\nMatch score: {match_score:.2f}\"\"\"\n                unmatched_changes.append(('\\n'.join(remove), '\\n'.join(add), failure_context))\n        if matched_changes:\n            new_content = '\\n'.join(current_lines)\n            if not new_content.endswith('\\n'):\n                new_content += '\\n'\n            with open(file_path, 'w', encoding=used_encoding) as file:\n                file.write(new_content)\n        report = []\n        report.append('Changes made:')\n        if matched_changes:\n            report.append(\n                f'\\nSuccessfully applied {len(matched_changes)} changes:')\n            #for old, new in matched_changes:\n                #report.append(f'\\nChanged:\\n{old}\\nTo:\\n{new}')\n        if unmatched_changes:\n            report.append(\n                f'\\nFailed to apply {len(unmatched_changes)} changes:')\n            for old, new, context in unmatched_changes:\n                report.append(f'\\nCould not find:\\n{old}\\n\\n{context}')\n        return '\\n'.join(report) if report else 'No changes were applied'\n    except Exception as e:\n        return f'Error: {str(e)}\\n{traceback.format_exc()}'\n\n\ndef _parse_diff_spec(diff_spec: str):\n    changes = []\n    remove = []\n    add = []\n    errors = []\n    last_prefix = None\n    diff_spec = textwrap.dedent(diff_spec)\n    for line in diff_spec.splitlines():\n        if not line:\n            if add:\n                changes.append((remove.copy(), add.copy()))\n                remove.clear()\n                add.clear()\n                last_prefix = None\n            continue\n        if line.startswith('-'):\n            last_prefix = '-'\n            content = line[1:]\n        elif line.startswith('+'):\n            last_prefix = '+'\n            content = line[1:]\n        elif last_prefix is not None:\n            content = line\n        else:\n            errors.append(\n                f'Error: \"{line}\" does not start with + or -. All lines must start with + or -.'\n                )\n            continue\n        if last_prefix == '-':\n            remove.append(content)\n        elif last_prefix == '+':\n            add.append(content)\n    if remove or add:\n        changes.append((remove, add))\n    if not changes and not errors:\n        errors.append('Error: No valid changes found in diff spec')\n    return changes, errors\n\n\ndef _find_matching_block(current_lines, remove_lines, ignore_indentation):\n    \"\"\"Find where a block of lines matches in the current file content.\n\n    Args:\n        current_lines: List of strings representing current file content\n        remove_lines: List of strings to find in the file\n        ignore_indentation: Whether to ignore leading whitespace when matching\n\n    Returns:\n        tuple (match_found: bool, line_num: int, indent: str, match_score: float, best_index: int)\n        where:\n        - match_found indicates if an exact match was found\n        - line_num is the line where the match starts (or best partial match)\n        - indent is the indentation to preserve\n        - match_score indicates quality of best partial match (0-1)\n        - best_index is the line number of best partial match\n    \"\"\"\n    if not remove_lines:\n        return True, len(current_lines), '', 1.0, len(current_lines)\n    \n    # Filter out empty lines for matching\n    def filter_empty_lines(lines):\n        return [line for line in lines if line.strip()]\n    \n    filtered_current = filter_empty_lines(current_lines)\n    filtered_remove = filter_empty_lines(remove_lines)\n    \n    # Build index mapping from filtered to original lines\n    current_map = []\n    for i, line in enumerate(current_lines):\n        if line.strip():\n            current_map.append(i)\n    \n    if len(filtered_remove) > len(filtered_current):\n        return False, 0, '', 0.0, 0\n        \n    for i in range(len(filtered_current) - len(filtered_remove) + 1):\n        current_block = filtered_current[i:i + len(filtered_remove)]\n        if ignore_indentation:\n            match = all(c.strip() == o.strip() for c, o in zip(current_block, filtered_remove))\n        else:\n            match = all(c == o for c, o in zip(current_block, filtered_remove))\n        if match:\n            # Map back to original line number\n            orig_index = current_map[i]\n            # Find the span of lines to remove including empty lines\n            end_index = current_map[i + len(filtered_remove) - 1]\n            return True, orig_index, _get_indentation(current_lines[orig_index]), 1.0, orig_index\n            \n    best_match_score = 0\n    best_match_index = 0\n    for i in range(len(filtered_current) - len(filtered_remove) + 1):\n        current_block = filtered_current[i:i + len(filtered_remove)]\n        match_score = _calculate_block_match_score(current_block, filtered_remove, ignore_indentation)\n        if match_score > best_match_score:\n            best_match_score = match_score\n            best_match_index = current_map[i]\n    return False, best_match_index, _get_indentation(current_lines[best_match_index]), best_match_score, best_match_index\n\n\ndef _get_indentation(line):\n    \"\"\"Extract the leading whitespace from a line.\"\"\"\n    return line[:len(line) - len(line.lstrip())]\n\n\ndef _adjust_indentation(lines, target_indent):\n    \"\"\"Adjust indentation of a block of lines to match target_indent.\"\"\"\n    if not lines:\n        return lines\n    non_empty_lines = [l for l in lines if l.strip()]\n    if not non_empty_lines:\n        return lines\n    min_indent = min(len(_get_indentation(l)) for l in non_empty_lines)\n    adjusted = []\n    for line in lines:\n        if not line.strip():\n            adjusted.append(line)\n        else:\n            stripped = line[min_indent:]\n            adjusted.append(target_indent + stripped)\n    return adjusted\n\n\ndef _get_context(lines, center_idx, context_size):\n    \"\"\"Get context lines around an index with line numbers.\"\"\"\n    start = max(0, center_idx - context_size)\n    end = min(len(lines), center_idx + context_size + 1)\n    return [f'{i + 1}: {line}' for i, line in enumerate(lines[start:end],\n        start)]\n\n\ndef _calculate_block_match_score(current_block, old_lines, ignore_indentation):\n    \"\"\"Calculate how well two blocks match, returning a score and matching line indices.\"\"\"\n    if ignore_indentation:\n        current_joined = ' '.join(l.strip() for l in current_block)\n        old_joined = ' '.join(l.strip() for l in old_lines)\n        current_stripped = [c.strip() for c in current_block]\n        old_stripped = [o.strip() for o in old_lines]\n    else:\n        current_joined = ' '.join(current_block)\n        old_joined = ' '.join(old_lines)\n        current_stripped = current_block\n        old_stripped = old_lines\n    exact_matches = sum(1 for c, o in zip(current_stripped, old_stripped) if\n        c == o)\n    if current_joined == old_joined:\n        return len(current_block) * 3\n    c_words = set(current_joined.split())\n    o_words = set(old_joined.split())\n    word_matches = len(c_words.intersection(o_words))\n    partial_score = 0\n    if word_matches > 0:\n        partial_score = word_matches / max(len(c_words), len(o_words))\n        if word_matches == len(c_words) and word_matches == len(o_words):\n            partial_score *= 2\n    total_score = exact_matches * 2 + partial_score\n    return total_score\n\n\ndef _has_line_number_prefix(line: str) ->bool:\n    \"\"\"Check if a string starts with a line number format (e.g., '123:' or '  123:')\n    Args:\n        line (str): The line to check\n    Returns:\n        bool: True if the line starts with a number followed by a colon\n    \"\"\"\n    stripped = line.lstrip()\n    if ':' not in stripped:\n        return False\n    prefix = stripped.split(':', 1)[0]\n    try:\n        int(prefix)\n        return True\n    except ValueError:\n        return False\n\n\ndef _strip_line_number(line: str) ->str:\n    \"\"\"Remove line number prefix if present (e.g., '123:content' or '  123:content' becomes 'content')\n    Preserves any leading whitespace before the line number.\n    Args:\n        line (str): The line to process\n    Returns:\n        str: The line with any line number prefix removed\n    \"\"\"\n    if not _has_line_number_prefix(line):\n        return line\n    whitespace = line[:len(line) - len(line.lstrip())]\n    stripped = line.lstrip()\n    content = stripped.split(':', 1)[1]\n    return whitespace + content\n",
    "file_path": "C:\\Users\\benbu\\Code\\llm-utilities-git\\bots\\bots\\tools\\code_tools.py",
    "code_hash": "383d90bddebc5bd49c4a96558e6fe440",
    "globals": {
     "os": "<module 'os' (frozen)>",
     "traceback": "<module 'traceback' from 'C:\\\\Users\\\\benbu\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312-arm64\\\\Lib\\\\traceback.py'>",
     "textwrap": "<module 'textwrap' from 'C:\\\\Users\\\\benbu\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312-arm64\\\\Lib\\\\textwrap.py'>",
     "view": "<function view at 0x000001DF656E7380>",
     "view_dir": "<function view_dir at 0x000001DF656E7420>",
     "diff_edit": "<function diff_edit at 0x000001DF656E74C0>",
     "_parse_diff_spec": "<function _parse_diff_spec at 0x000001DF656E7560>",
     "_find_matching_block": "<function _find_matching_block at 0x000001DF656E7600>",
     "_get_indentation": "<function _get_indentation at 0x000001DF656E76A0>",
     "_adjust_indentation": "<function _adjust_indentation at 0x000001DF656E7740>",
     "_get_context": "<function _get_context at 0x000001DF656E77E0>",
     "_calculate_block_match_score": "<function _calculate_block_match_score at 0x000001DF656E7880>",
     "_has_line_number_prefix": "<function _has_line_number_prefix at 0x000001DF656E7920>",
     "_strip_line_number": "<function _strip_line_number at 0x000001DF656E79C0>"
    }
   },
   "C:\\Users\\benbu\\Code\\llm-utilities-git\\bots\\bots\\tools\\terminal_tools.py": {
    "name": "dynamic_module_d64ce3a2b8cfb34ac3eb473953440645",
    "source": "import os, subprocess, traceback, time, threading\nfrom queue import Queue, Empty\nfrom threading import Thread, Lock, local\nfrom typing import Dict, Generator\nfrom datetime import datetime\n\ndef execute_powershell(command: str, output_length_limit: str='120') -> str:\n    \"\"\"\n    Executes PowerShell commands in a stateful environment\n\n    Use when you need to run PowerShell commands and capture their output. If\n    you have other tools available, you should use this as a fallback when the\n    other tools fail. Coerces to utf-8.\n\n    Potential use cases:\n    - git commands\n    - gh cli\n    - other cli (which you may need to install using this tool)\n\n    Parameters:\n    - command (str): PowerShell command to execute.\n    - output_length_limit (int, optional): Maximum number of lines in the output.\n      If set, output exceeding this limit will be truncated. Default 120.\n\n    Returns:\n        str: The complete output from the command execution\n    \"\"\"\n    manager = PowerShellManager.get_instance()\n    output = ''.join(manager.execute(command, output_length_limit))\n    return output\n\nclass PowerShellSession:\n    \"\"\"\n    Manages a persistent PowerShell process for stateful command execution.\n    Maintains a single PowerShell process that persists between commands,\n    allowing for stateful operations like changing directories, setting\n    environment variables, or activating virtual environments.\n    \"\"\"\n\n    def __init__(self):\n        self._process = None\n        self._command_counter = 0\n        self._output_queue = Queue()\n        self._error_queue = Queue()\n        self._reader_threads = []\n        self.startupinfo = None\n        if os.name == 'nt':\n            self.startupinfo = subprocess.STARTUPINFO()\n            self.startupinfo.dwFlags |= subprocess.STARTF_USESHOWWINDOW\n\n    def _start_reader_threads(self):\n        \"\"\"Start background threads to read stdout and stderr\"\"\"\n\n        def reader_thread(pipe, queue):\n            try:\n                for line in pipe:\n                    queue.put(line.rstrip('\\n\\r'))\n            finally:\n                queue.put(None)\n        self._reader_threads = [Thread(target=reader_thread, args=(self._process.stdout, self._output_queue), daemon=True), Thread(target=reader_thread, args=(self._process.stderr, self._error_queue), daemon=True)]\n        for thread in self._reader_threads:\n            thread.start()\n\n    def __enter__(self):\n        if not self._process:\n            self._process = subprocess.Popen(['powershell', '-NoProfile', '-NoLogo', '-NonInteractive', '-Command', '-'], stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE, startupinfo=self.startupinfo, encoding='utf-8', errors='replace', bufsize=1)\n            self._start_reader_threads()\n            init_commands = [\"$VerbosePreference='SilentlyContinue'\", \"$DebugPreference='SilentlyContinue'\", \"$ProgressPreference='SilentlyContinue'\", \"$WarningPreference='SilentlyContinue'\", \"$ErrorActionPreference='Stop'\", \"function prompt { '' }\", \"$PSDefaultParameterValues['*:Encoding']='utf8'\", '[Console]::OutputEncoding=[System.Text.Encoding]::UTF8', '[Console]::InputEncoding=[System.Text.Encoding]::UTF8', '$OutputEncoding=[System.Text.Encoding]::UTF8', \"$env:PYTHONIOENCODING='utf-8'\"]\n            for cmd in init_commands:\n                self._process.stdin.write(cmd + '\\n')\n            self._process.stdin.flush()\n        return self\n\n    def __exit__(self, exc_type, exc_val, exc_tb):\n        if self._process:\n            try:\n                self._process.terminate()\n                self._process.wait(timeout=5)\n            except:\n                self._process.kill()\n            finally:\n                self._process = None\n                self._output_queue = Queue()\n                self._error_queue = Queue()\n                self._reader_threads = []\n\n    def execute(self, code: str, timeout: float=300) -> str:\n        \"\"\"\n        Execute PowerShell code and return its complete output.\n\n        Args:\n            code: The PowerShell code to execute\n            timeout: Maximum time in seconds to wait for command completion\n\n        Returns:\n            The complete output from the command(s)\n\n        Raises:\n            Exception if the process is not running or other execution errors\n            TimeoutError if command execution exceeds timeout\n        \"\"\"\n        if not self._process:\n            raise Exception('PowerShell process is not running')\n        try:\n            self._command_counter += 1\n            delimiter = f'<<<COMMAND_{self._command_counter}_COMPLETE>>>'\n            wrapped_code = f\"\\n            $ErrorActionPreference = 'Stop'\\n            \\n            # Execute in main scope\\n            {code}\\n            \\n            # Collect output after execution\\n            $output = @()\\n            try {{\\n                if ($?) {{ \\n                    # Add any output from the last command\\n                    $output += $LASTOUTPUT\\n                }}\\n            }} catch {{\\n                Write-Error $_\\n            }}\\n            $output | ForEach-Object {{ $_ }}\\n            Write-Output '{delimiter}'\\n            \"\n            while not self._output_queue.empty():\n                self._output_queue.get_nowait()\n            while not self._error_queue.empty():\n                self._error_queue.get_nowait()\n            self._process.stdin.write(wrapped_code + '\\n')\n            self._process.stdin.flush()\n            output_lines = []\n            error_output = []\n            start_time = time.time()\n            done = False\n            while not done:\n                if time.time() - start_time > timeout:\n                    raise TimeoutError(f'Command execution timed out after {timeout} seconds')\n                if self._process.poll() is not None:\n                    raise Exception('PowerShell process unexpectedly closed')\n                try:\n                    line = self._output_queue.get(timeout=0.1)\n                    if line is None:\n                        raise Exception('PowerShell process closed stdout')\n                    if line == delimiter:\n                        done = True\n                    else:\n                        output_lines.append(line)\n                except Empty:\n                    pass\n                try:\n                    while True:\n                        line = self._error_queue.get_nowait()\n                        if line is None:\n                            raise Exception('PowerShell process closed stderr')\n                        error_output.append(line)\n                except Empty:\n                    pass\n            all_output = [line for line in output_lines if line.strip()]\n            if error_output:\n                error_lines = [line for line in error_output if line.strip()]\n                if error_lines:\n                    all_output.extend(['', 'Errors:', *error_lines])\n            return '\\n'.join(all_output)\n        except Exception as e:\n            self.__exit__(type(e), e, e.__traceback__)\n            raise\n\nclass PowerShellManager:\n    \"\"\"\n    Thread-safe PowerShell session manager that maintains separate sessions.\n    Each instance automatically gets its own unique ID and isolated PowerShell session.\n    Includes session recovery logic for lost or failed sessions.\n    \"\"\"\n    _instances: Dict[str, 'PowerShellManager'] = {}\n    _lock = Lock()\n\n    @classmethod\n    def get_instance(cls, bot_id: str=None) -> 'PowerShellManager':\n        \"\"\"\n        Get or create a PowerShell manager instance for the given bot_id.\n        If no bot_id is provided, uses the current thread name.\n        \n        Args:\n            bot_id: Optional identifier for the bot instance\n            \n        Returns:\n            The PowerShell manager instance for this bot/thread\n        \"\"\"\n        if bot_id is None:\n            bot_id = threading.current_thread().name\n        with cls._lock:\n            if bot_id not in cls._instances:\n                instance = cls.__new__(cls)\n                instance.bot_id = bot_id\n                instance._thread_local = local()\n                instance.created_at = datetime.now()\n                cls._instances[bot_id] = instance\n            return cls._instances[bot_id]\n\n    def __init__(self):\n        \"\"\"\n        Private initializer - use get_instance() instead.\n        \"\"\"\n        raise RuntimeError('Use PowerShellManager.get_instance() to create or get a PowerShell manager')\n\n    @property\n    def session(self) -> PowerShellSession:\n        \"\"\"\n        Get the PowerShell session for the current thread.\n        Creates a new session if none exists or if the current session is invalid.\n        \"\"\"\n        try:\n            if not hasattr(self._thread_local, 'session'):\n                print(f'Session not found for {self.bot_id}, starting new session')\n                self._start_new_session()\n            elif not self._is_session_valid():\n                print(f'Invalid session detected for {self.bot_id}, starting new session')\n                self.cleanup()\n                self._start_new_session()\n            return self._thread_local.session\n        except Exception as e:\n            print(f'Error accessing session: {str(e)}. Starting new session.')\n            self._start_new_session()\n            return self._thread_local.session\n\n    def _start_new_session(self):\n        \"\"\"\n        Starts a new PowerShell session for the current thread.\n        \"\"\"\n        self._thread_local.session = PowerShellSession()\n        self._thread_local.session.__enter__()\n\n    def _is_session_valid(self) -> bool:\n        \"\"\"\n        Checks if the current session is valid and responsive.\n        Returns:\n            bool: True if session is valid, False otherwise\n        \"\"\"\n        try:\n            if not hasattr(self._thread_local, 'session'):\n                return False\n            session = self._thread_local.session\n            if not session._process or session._process.poll() is not None:\n                return False\n            test_output = session.execute(\"Write-Output 'test'\", timeout=5)\n            return 'test' in test_output\n        except Exception as e:\n            print(f'Session validation failed: {str(e)}')\n            return False\n\n    def execute(self, code: str, output_length_limit: str='60') -> Generator[str, None, None]:\n        \"\"\"\n        Execute PowerShell code in the session with automatic recovery.\n\n        Args:\n            code: PowerShell code to execute\n            output_length_limit: Maximum number of lines in output\n\n        Yields:\n            Command output as strings\n        \"\"\"\n        max_retries = 1\n        retry_count = 0\n\n        def _process_error(error):\n            error_message = f'Tool Failed: {str(error)}\\n'\n            error_message += f\"Traceback:\\n{''.join(traceback.format_tb(error.__traceback__))}\"\n            return error_message\n        while retry_count <= max_retries:\n            try:\n                processed_code = _process_commands(code)\n                output = self.session.execute(processed_code)\n                if output_length_limit is not None and output:\n                    output_length_limit_int = int(output_length_limit)\n                    lines = output.splitlines()\n                    if len(lines) > output_length_limit_int:\n                        half_limit = output_length_limit_int // 2\n                        start_lines = lines[:half_limit]\n                        end_lines = lines[-half_limit:]\n                        lines_omitted = len(lines) - output_length_limit_int\n                        truncated_output = '\\n'.join(start_lines)\n                        truncated_output += f'\\n\\n... {lines_omitted} lines omitted ...\\n\\n'\n                        truncated_output += '\\n'.join(end_lines)\n                        output_file = os.path.join(os.getcwd(), f'ps_output_{self.bot_id}.txt')\n                        with open(output_file, 'w', encoding='utf-8', errors='replace') as f:\n                            f.write(output)\n                        truncated_output += f'\\nFull output saved to {output_file}'\n                        yield truncated_output\n                    else:\n                        yield output\n                else:\n                    yield output\n                break\n            except Exception as e:\n                retry_count += 1\n                if retry_count <= max_retries:\n                    print(f'Command failed, attempt {retry_count} of {max_retries}. Starting new session...')\n                    self.cleanup()\n                else:\n                    yield _process_error(e)\n\n    def cleanup(self):\n        \"\"\"\n        Clean up the PowerShell session for the current thread.\n        Should be called when work is done or when a session needs to be reset.\n        \"\"\"\n        if hasattr(self._thread_local, 'session'):\n            try:\n                self._thread_local.session.__exit__(None, None, None)\n            except Exception as e:\n                print(f'Error during session cleanup: {str(e)}')\n            finally:\n                delattr(self._thread_local, 'session')\n\ndef _get_active_sessions() -> list:\n    \"\"\"\n    Get information about all active PowerShell sessions.\n\n    Returns:\n        List of dictionaries containing session information\n    \"\"\"\n    sessions = []\n    for thread in threading.enumerate():\n        if hasattr(thread, '_thread_local'):\n            local_dict = thread._thread_local.__dict__\n            if 'ps_manager' in local_dict:\n                manager = local_dict['ps_manager']\n                sessions.append({'bot_id': manager.bot_id, 'thread_name': thread.name, 'created_at': manager.created_at.isoformat(), 'active': hasattr(manager._thread_local, 'session')})\n    return sessions\n\ndef _execute_powershell_stateless(code: str, output_length_limit: str='120'):\n    \"\"\"\n    Executes PowerShell code in a stateless environment\n\n    Use when you need to run PowerShell commands and capture their output. If\n    you have other tools available, you should use this as a fallback when the\n    other tools fail. Coerces to utf-8 encoding.\n\n    Potential use cases:\n    - git commands\n    - gh cli\n    - other cli (which you may need to install using this tool)\n\n    Parameters:\n    - code (str): PowerShell code to execute.\n    - output_length_limit (int, optional): Maximum number of lines in the output.\n      If set, output exceeding this limit will be truncated. Default 60.\n\n    Returns command output or an error message.\n    \"\"\"\n\n    def _process_error(error):\n        error_message = f'Tool Failed: {str(error)}\\n'\n        error_message += f\"Traceback:\\n{''.join(traceback.format_tb(error.__traceback__))}\"\n        return error_message\n    output = ''\n    try:\n        processed_code = _process_commands(code)\n        setup_encoding = '\\n        $PSDefaultParameterValues[\\'*:Encoding\\'] = \\'utf8\\'\\n        [Console]::OutputEncoding = [System.Text.Encoding]::UTF8\\n        [Console]::InputEncoding = [System.Text.Encoding]::UTF8\\n        $OutputEncoding = [System.Text.Encoding]::UTF8\\n        $env:PYTHONIOENCODING = \"utf-8\"\\n        '\n        wrapped_code = f'{setup_encoding}; {processed_code}'\n        startupinfo = None\n        if os.name == 'nt':\n            startupinfo = subprocess.STARTUPINFO()\n            startupinfo.dwFlags |= subprocess.STARTF_USESHOWWINDOW\n        process = subprocess.Popen(['powershell', '-NoProfile', '-NonInteractive', '-Command', wrapped_code], stdout=subprocess.PIPE, stderr=subprocess.PIPE, startupinfo=startupinfo, encoding='utf-8', errors='replace')\n        stdout, stderr = process.communicate(timeout=300)\n        output = stdout\n        if stderr:\n            output += stderr\n    except subprocess.TimeoutExpired as e:\n        process.kill()\n        output += 'Error: Command execution timed out after 300 seconds.'\n    except Exception as e:\n        output += _process_error(e)\n    if output_length_limit is not None and output:\n        output_length_limit = int(output_length_limit)\n        lines = output.splitlines()\n        if len(lines) > output_length_limit:\n            half_limit = output_length_limit // 2\n            start_lines = lines[:half_limit]\n            end_lines = lines[-half_limit:]\n            lines_omitted = len(lines) - output_length_limit\n            truncated_output = '\\n'.join(start_lines)\n            truncated_output += f'\\n\\n... {lines_omitted} lines omitted ...\\n\\n'\n            truncated_output += '\\n'.join(end_lines)\n            output_file = os.path.join(os.getcwd(), 'ps_output.txt')\n            with open(output_file, 'w', encoding='utf-8', errors='replace') as f:\n                f.write(output)\n            truncated_output += f'\\nFull output saved to {output_file}'\n            return truncated_output\n    return output\n\ndef _process_commands(code: str) -> str:\n    \"\"\"\n    Process PowerShell commands separated by &&, ensuring each command only runs if the previous succeeded.\n    Uses PowerShell error handling to catch both command failures and non-existent commands.\n\n    Args:\n        code (str): The original command string with && separators\n\n    Returns:\n        str: PowerShell code with proper error checking between commands\n    \"\"\"\n    commands = code.split(' && ')\n    if len(commands) == 1:\n        return code\n    processed_commands = []\n    for cmd in commands:\n        wrapped_cmd = f'$ErrorActionPreference = \"Stop\"; try {{ {cmd}; $LastSuccess = $true }} catch {{ $LastSuccess = $false; $_ }}'\n        processed_commands.append(wrapped_cmd)\n    return '; '.join([processed_commands[0]] + [f'if ($LastSuccess) {{ {cmd} }}' for cmd in processed_commands[1:]])",
    "file_path": "C:\\Users\\benbu\\Code\\llm-utilities-git\\bots\\bots\\tools\\terminal_tools.py",
    "code_hash": "d9accdeb306b3d2057386c1d230eabff",
    "globals": {
     "os": "<module 'os' (frozen)>",
     "subprocess": "<module 'subprocess' from 'C:\\\\Users\\\\benbu\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312-arm64\\\\Lib\\\\subprocess.py'>",
     "traceback": "<module 'traceback' from 'C:\\\\Users\\\\benbu\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312-arm64\\\\Lib\\\\traceback.py'>",
     "time": "<module 'time' (built-in)>",
     "threading": "<module 'threading' from 'C:\\\\Users\\\\benbu\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312-arm64\\\\Lib\\\\threading.py'>",
     "Queue": "<class 'queue.Queue'>",
     "Empty": "<class '_queue.Empty'>",
     "Thread": "<class 'threading.Thread'>",
     "Lock": "<built-in function allocate_lock>",
     "local": "<class '_thread._local'>",
     "Dict": "typing.Dict",
     "Generator": "typing.Generator",
     "datetime": "<class 'datetime.datetime'>",
     "execute_powershell": "<function execute_powershell at 0x000001DF656E7BA0>",
     "PowerShellSession": "<class 'dynamic_module_d64ce3a2b8cfb34ac3eb473953440645.PowerShellSession'>",
     "PowerShellManager": "<class 'dynamic_module_d64ce3a2b8cfb34ac3eb473953440645.PowerShellManager'>",
     "_get_active_sessions": "<function _get_active_sessions at 0x000001DF656E7F60>",
     "_execute_powershell_stateless": "<function _execute_powershell_stateless at 0x000001DF673087C0>",
     "_process_commands": "<function _process_commands at 0x000001DF67308860>"
    }
   }
  },
  "function_paths": {
   "add_imports": "C:\\Users\\benbu\\Code\\llm-utilities-git\\bots\\bots\\tools\\python_editing_tools.py",
   "remove_import": "C:\\Users\\benbu\\Code\\llm-utilities-git\\bots\\bots\\tools\\python_editing_tools.py",
   "replace_import": "C:\\Users\\benbu\\Code\\llm-utilities-git\\bots\\bots\\tools\\python_editing_tools.py",
   "add_class": "C:\\Users\\benbu\\Code\\llm-utilities-git\\bots\\bots\\tools\\python_editing_tools.py",
   "replace_class": "C:\\Users\\benbu\\Code\\llm-utilities-git\\bots\\bots\\tools\\python_editing_tools.py",
   "add_function_to_class": "C:\\Users\\benbu\\Code\\llm-utilities-git\\bots\\bots\\tools\\python_editing_tools.py",
   "add_function_to_file": "C:\\Users\\benbu\\Code\\llm-utilities-git\\bots\\bots\\tools\\python_editing_tools.py",
   "replace_function": "C:\\Users\\benbu\\Code\\llm-utilities-git\\bots\\bots\\tools\\python_editing_tools.py",
   "view": "C:\\Users\\benbu\\Code\\llm-utilities-git\\bots\\bots\\tools\\code_tools.py",
   "view_dir": "C:\\Users\\benbu\\Code\\llm-utilities-git\\bots\\bots\\tools\\code_tools.py",
   "diff_edit": "C:\\Users\\benbu\\Code\\llm-utilities-git\\bots\\bots\\tools\\code_tools.py",
   "execute_powershell": "C:\\Users\\benbu\\Code\\llm-utilities-git\\bots\\bots\\tools\\terminal_tools.py"
  }
 },
 "autosave": true,
 "bot_class": "AnthropicBot"
}