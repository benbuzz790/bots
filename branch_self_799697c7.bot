{
 "name": "Claude",
 "model_engine": "claude-sonnet-4-20250514",
 "max_tokens": 4096,
 "temperature": 0.3,
 "role": "assistant",
 "role_description": "a friendly AI assistant",
 "conversation": {
  "content": "",
  "pending_results": [],
  "role": "empty",
  "tool_calls": [],
  "tool_results": [],
  "node_class": "AnthropicNode",
  "replies": [
   {
    "content": "Create first branch",
    "pending_results": [],
    "role": "user",
    "tool_calls": [],
    "tool_results": [],
    "node_class": "AnthropicNode",
    "replies": [
     {
      "content": "I'll create a first branch for you. Since you didn't specify what tasks or prompts you'd like the branch to work on, I'll create a simple example branch to demonstrate the functionality.",
      "labels": [
       "branch1"
      ],
      "pending_results": [
       {
        "type": "tool_result",
        "tool_use_id": "toolu_01CYrJFU3YMWPVLLvqTuCuwC",
        "content": "Successfully completed 0/1 sequential single-response branches. Recombination result:\n\nNo recombinator selected"
       }
      ],
      "role": "assistant",
      "tool_calls": [
       {
        "type": "tool_use",
        "id": "toolu_01CYrJFU3YMWPVLLvqTuCuwC",
        "name": "branch_self",
        "input": {
         "self_prompts": "['Hello! This is the first branch. Please introduce yourself and explain what you can help with.']"
        }
       }
      ],
      "tool_results": [],
      "node_class": "AnthropicNode"
     }
    ]
   },
   {
    "content": "Create second branch",
    "pending_results": [],
    "role": "user",
    "tool_calls": [],
    "tool_results": [],
    "node_class": "AnthropicNode",
    "replies": [
     {
      "content": "I'll create a second branch for you. Let me use the branch_self tool to create an additional conversation branch.",
      "labels": [
       "branch2"
      ],
      "pending_results": [
       {
        "type": "tool_result",
        "tool_use_id": "toolu_01DyTFtzz2t4jBW463B1x4YJ",
        "content": "Successfully completed 1/1 sequential single-response branches. Recombination result:\n\nCombined Result:\n\nResponse 1:\nI'll continue working by exploring the current environment and demonstrating some capabilities. Let me start by examining the directory structure to understand what we're working with."
       }
      ],
      "role": "assistant",
      "tool_calls": [
       {
        "type": "tool_use",
        "id": "toolu_01DyTFtzz2t4jBW463B1x4YJ",
        "name": "branch_self",
        "input": {
         "self_prompts": "['Continue working on the current task or explore an alternative approach']"
        }
       }
      ],
      "tool_results": [],
      "node_class": "AnthropicNode",
      "replies": [
       {
        "content": "(self-prompt): Continue working on the current task or explore an alternative approach",
        "pending_results": [],
        "role": "user",
        "tool_calls": [],
        "tool_results": [
         {
          "type": "tool_result",
          "tool_use_id": "toolu_01CYrJFU3YMWPVLLvqTuCuwC",
          "content": "Successfully completed 0/1 sequential single-response branches. Recombination result:\n\nNo recombinator selected"
         }
        ],
        "node_class": "AnthropicNode",
        "replies": [
         {
          "content": "I'll continue working by exploring the current environment and demonstrating some capabilities. Let me start by examining the directory structure to understand what we're working with.",
          "pending_results": [
           {
            "type": "tool_result",
            "tool_use_id": "toolu_014Jj4f2CSaQctdXjcrWLYSD",
            "content": "./\n    API_REFERENCE.md\n    bom_test_ascii.txt\n    bom_test_default.txt\n    bom_test_unicode.txt\n    bom_test_utf8.txt\n    bot_gui.py\n    cli_config.json\n    complex_test.txt\n    conftest.py\n    CONTRIBUTING.md\n    credentials.json\n    docker-test-guide.md\n    encoding_test_ascii.py\n    encoding_test_default.py\n    encoding_test_no_encoding.py\n    encoding_test_unicode.py\n    encoding_test_utf-8.py\n    encoding_test_utf8.py\n    fibonacci.py\n    functional_prompt_primer.md\n    GETTING_STARTED.md\n    installation_quickstart.md\n    large_refactor_tasks.md\n    LICENSE.txt\n    minimal.py\n    problematic_code.py\n    PROJECT_OVERVIEW.md\n    ps_output_MainThread.txt\n    rapid.txt\n    README.md\n    requirements.txt\n    run_development.py\n    run_tests_docker.py\n    run_tests_docker_auto.py\n    setup.py\n    simple.txt\n    test_accented_chars.txt\n    test_arrows_and_boxes.txt\n    test_ascii_quotes.txt\n    test_bom.py\n    test_docker_permissions.py\n    test_functions.py\n    test_insert.py\n    test_nested.py\n    test_output.json\n    test_python_code_chars.txt\n    test_replace_behavior.py\n    test_smart_quotes.txt\n    test_symbols.txt\n    test_utf8.txt\n    __checkcicd.py\n    .github/\n        workflows/\n            ...\n    .mypy_cache/\n        3.12/\n            ...\n    .pytest_cache/\n        README.md\n    botlib/\n        build_debug_bot.py\n        build_py_file_bot.py\n        __init__.py\n    bots/\n        prompts.json\n        __init__.py\n        dev/\n            ...\n        flows/\n            ...\n        foundation/\n            ...\n        tests/\n            ...\n        tools/\n            ...\n        utils/\n            ...\n    bots.egg-info/\n        dependency_links.txt\n        requires.txt\n        SOURCES.txt\n        top_level.txt\n    docs/\n        conf.py\n        _sources/\n            ...\n    examples/\n        bot_example.py\n        doc_checker.py\n        functional_prompt_example.py\n        lazy_example.py\n        style_fixer.py\n    tests/\n        cleanup_test_artifacts.py\n        cli_config.json\n        conftest.py\n        test_add_tools.py\n        test_add_tools_openai.py\n        test_ast_unparse.py\n        test_basic.py\n        test_bots.py\n        test_code_tools.py\n        test_comprehensive_helpers.py\n        test_decorators.py\n        test_dynamic_execution.py\n        test_handle_error_decorator.py\n        test_helpers.py\n        test_helper_preservation.py\n        test_oaibot.py\n        test_patch_edit.py\n        test_python_tools.py\n        test_save_load_anthropic.py\n        test_save_load_debug.py\n        test_save_load_gemini.py\n        test_save_load_matrix.py\n        test_save_load_openai.py\n        test_self_tools.py\n        test_specific_helper_bug.py\n        test_tool_handler.py\n        test_tool_handler_comprehensive.py\n        __init__.py\n        test_cli/\n            ...\n        test_fp/\n            ...\n        test_powershell_tool/\n            ...\n        test_python_edit/\n            ...\n    trash/\n        complex_test.txt\n        rapid.txt\n        test_bom.py\n        test_functions.py\n        test_insert.py\n        test_nested.py\n        test_output.json\n        test_replace_behavior.py\n        test_results_20250804_090108.txt\n        test_results_20250804_090457.txt\n        test_results_20250804_090735.txt\n        test_results_20250804_091132.txt\n        dir1/\n            ...\n        dir2/\n            ...\n        dir3/\n            ...\n        tmp/\n            ...\n    _work_orders/\n        dynamic_wrapper_fix_analysis.txt\n        WO001_Critical_Bug_Fixes.md\n        WO002_Navigation_System.md\n        WO003_CLI_Feature_Parity.md\n        WO004-2_Test_Infrastructure.md\n        WO004-3_Test_Infrastructure_Status.md\n        WO004-4_Test_Infrastructure_Phase1_Complete.md\n        WO004-5_Frontend_Test_Enhancement.md\n        WO004_Test_Infrastructure.md\n        WO005_Advanced_Features.md\n        WO006_Architecture_Updates.md\n        WO007_Integration_Test_Server_Connectivity.md\n        WO008_WebSocket_Response_Handling.md\n        WO009_Navigation_Integration_Advanced.md\n        WO010_Data_Structure_API_Consistency.md\n        WO011_Performance_Edge_Cases.md\n        WOALL_Common_Requirements.md"
           }
          ],
          "role": "assistant",
          "tool_calls": [
           {
            "type": "tool_use",
            "id": "toolu_014Jj4f2CSaQctdXjcrWLYSD",
            "name": "view_dir",
            "input": {
             "start_path": ".",
             "target_extensions": "['py', 'md', 'txt', 'json', 'yaml', 'yml']"
            }
           }
          ],
          "tool_results": [],
          "node_class": "AnthropicNode"
         }
        ]
       }
      ]
     }
    ]
   },
   {
    "content": "Create third branch",
    "pending_results": [],
    "role": "user",
    "tool_calls": [],
    "tool_results": [],
    "node_class": "AnthropicNode",
    "replies": [
     {
      "content": "I need more context to create a third branch. The `branch_self` tool requires at least one prompt to create branches. Could you please provide:\n\n1. What prompts/tasks you want for the branches?\n2. Are there already existing branches you're referring to?\n3. What specific work should each branch do?\n\nFor example, you could say something like:\n- \"Create 3 branches with prompts: ['analyze code', 'write tests', 'create documentation']\"\n- Or if you want to add a third branch to existing ones, let me know what the third branch should work on\n\nWhat would you like the third branch (and any other branches) to focus on?",
      "pending_results": [],
      "role": "assistant",
      "tool_calls": [],
      "tool_results": [],
      "node_class": "AnthropicNode",
      "replies": [
       {
        "content": "1",
        "pending_results": [],
        "role": "user",
        "tool_calls": [],
        "tool_results": [],
        "node_class": "AnthropicNode",
        "replies": [
         {
          "content": "I'll create a third branch with the prompt \"1\":",
          "pending_results": [],
          "role": "assistant",
          "tool_calls": [
           {
            "type": "tool_use",
            "id": "toolu_01AFs34VChPyBHoDmSr5nTJs",
            "name": "branch_self",
            "input": {
             "self_prompts": "['1', '2', '3']"
            }
           }
          ],
          "tool_results": [],
          "node_class": "AnthropicNode"
         }
        ]
       }
      ]
     }
    ]
   }
  ]
 },
 "system_message": "You're a coding agent. Please follow these rules:\n                    1. Keep edits and even writing new files to small chunks. You have a low max_token limit\n                       and will hit tool errors if you try making too big of a change.\n                    2. Avoid using cd. Your terminal is stateful and will remember if you use cd.\n                       Instead, use full relative paths.\n",
 "tool_handler": {
  "class": "bots.foundation.anthropic_bots.AnthropicToolHandler",
  "tools": [
   {
    "name": "view",
    "description": "Display the contents of a file with line numbers.\nParameters:\n- file_path (str): The path to the file to be viewed.\n- start_line (int, optional): Starting line number (1-indexed). If None, starts from beginning.\n- end_line (int, optional): Ending line number (1-indexed). If None, goes to end of file.\n- around_str_match (str, optional): String to search for. If provided, shows lines around matches.\n- dist_from_match (int, optional): Number of lines to show before and after each match. Defaults to 10.\nReturns:\nA string containing the file contents with line numbers,\nfiltered according to the specified parameters.",
    "input_schema": {
     "type": "object",
     "properties": {
      "file_path": {
       "type": "string"
      },
      "start_line": {
       "type": "string"
      },
      "end_line": {
       "type": "string"
      },
      "around_str_match": {
       "type": "string"
      },
      "dist_from_match": {
       "type": "string"
      }
     },
     "required": [
      "file_path"
     ]
    }
   },
   {
    "name": "view_dir",
    "description": "Creates a summary of the directory structure starting from the given path, writing only files\nwith specified extensions and showing venv directories without their contents.\nParameters:\n- start_path (str): The root directory to start scanning from.\n- output_file (str): The name of the file to optionally write the directory structure to.\n- target_extensions (str): String representation of a list of file extensions (e.g. \"['py', 'txt']\").\n- max_lines (int): Maximum number of lines in output. If exceeded, deepest levels are truncated. Default 500.\nReturns:\nstr: A formatted string containing the directory structure, with each directory and file properly indented.\nExample output:\nmy_project/\n    venv/\n    module1/\n        script.py\n        README.md\n    module2/\n        utils.py\ncost: low",
    "input_schema": {
     "type": "object",
     "properties": {
      "start_path": {
       "type": "string"
      },
      "output_file": {
       "type": "string"
      },
      "target_extensions": {
       "type": "string"
      },
      "max_lines": {
       "type": "string"
      }
     },
     "required": []
    }
   },
   {
    "name": "execute_powershell",
    "description": "Executes PowerShell commands in a stateful environment with automatic BOM removal\n\nUse when you need to run PowerShell commands and capture their output. If\nyou have other tools available, you should use this as a fallback when the\nother tools fail. Coerces to utf-8 (no BOM).\n\nPotential use cases:\n- git commands\n- gh cli\n- other cli (which you may need to install using this tool)\n\nParameters:\n- command (str): PowerShell command to execute.\n- output_length_limit (int, optional): Maximum number of lines in the output.\n  If set, output exceeding this limit will be truncated. Default 200.\n\nReturns:\n    str: The complete output from the command execution",
    "input_schema": {
     "type": "object",
     "properties": {
      "command": {
       "type": "string"
      },
      "output_length_limit": {
       "type": "string"
      },
      "timeout": {
       "type": "string"
      }
     },
     "required": [
      "command"
     ]
    }
   },
   {
    "name": "execute_python",
    "description": "Executes python code in a stateless environment with cross-platform\ntimeout handling.\nParameters:\n- code (str): Syntactically correct python code\n- timeout (int): Maximum execution time in seconds (default: 300)\nReturns stdout or an error message.\ncost: varies",
    "input_schema": {
     "type": "object",
     "properties": {
      "code": {
       "type": "string"
      },
      "timeout": {
       "type": "string"
      }
     },
     "required": [
      "code"
     ]
    }
   },
   {
    "name": "branch_self",
    "description": "Create multiple conversation branches to explore different approaches or tackle separate tasks.\n\nFollowing the idealized design from branch_self.md with minimal complexity:\n1. Add dummy tool result immediately for API compliance and recursion prevention\n2. Use existing sync mechanism to update results across branches\n\nArgs:\n    self_prompts (str): List of prompts as a string array, like ['task 1', 'task 2', 'task 3']\n                       Each prompt becomes a separate conversation branch\n    allow_work (str): 'True' to let each branch use tools and continue working until done\n                     'False' (default) for single-response branches\n    parallel (str): 'True' to let branches work in parallel, 'False' for sequential (default).\n    recombine (str): One of ('none', 'concatenate', 'llm_merge', 'llm_vote', 'llm_judge'), default 'concatenate'.\n                     Combines the final messages from each branch using that method.\n\nReturns:\n    str: Success message with branch count, or error details if something went wrong",
    "input_schema": {
     "type": "object",
     "properties": {
      "self_prompts": {
       "type": "string"
      },
      "allow_work": {
       "type": "string"
      },
      "parallel": {
       "type": "string"
      },
      "recombine": {
       "type": "string"
      }
     },
     "required": [
      "self_prompts"
     ]
    }
   },
   {
    "name": "web_search",
    "description": "Perform an agentic web search using Claude's internal web search capabilities",
    "input_schema": {
     "type": "object",
     "properties": {
      "question": {
       "type": "string"
      }
     },
     "required": [
      "question"
     ]
    },
    "cache_control": {
     "type": "ephemeral"
    }
   }
  ],
  "requests": [
   {
    "type": "tool_use",
    "id": "toolu_01AFs34VChPyBHoDmSr5nTJs",
    "name": "branch_self",
    "input": {
     "self_prompts": "['1', '2', '3']"
    }
   }
  ],
  "results": [
   {
    "tool_use_id": "toolu_01AFs34VChPyBHoDmSr5nTJs",
    "content": "Branching in progress..."
   }
  ],
  "modules": {
   "dynamic_module_-7047342923987625551": {
    "name": "dynamic_module_-7574630578757889338",
    "source": "from bots.utils.helpers import _process_error\n\ndef toolify(description: str = None):\n    \"\"\"\n    Convert any function into a bot tool with string-in, string-out interface.\n\n    - Converts string inputs to proper types using type hints\n    - Ensures string output (JSON for complex types)\n    - Wraps in error handling (returns error strings, never raises)\n    - Enhances docstring if description provided\n\n    Args:\n        description (str, optional): Override the function's docstring\n\n    Example:\n        @toolify()\n        def add_numbers(x: int, y: int = 0) -> int:\n            return x + y\n\n        @toolify(\"Calculate the area of a circle\")\n        def area(radius: float) -> float:\n            return 3.14159 * radius * radius\n    \"\"\"\n\n    def decorator(func):\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            try:\n                # Convert string inputs to proper types using type hints\n                converted_args, converted_kwargs = _convert_tool_inputs(func, args, kwargs)\n\n                # Call original function\n                result = func(*converted_args, **converted_kwargs)\n\n                # Convert result to string\n                return _convert_tool_output(result)\n\n            except KeyboardInterrupt as e:\n                # Convert KeyboardInterrupt to ToolExecutionError to prevent it from\n                # bubbling up to CLI and being treated as user Ctrl+C\n                from bots.utils.helpers import _process_error\n\n                # ToolExecutionError is defined in this file\n                tool_error = ToolExecutionError(f\"Tool execution interrupted: {str(e)}\")\n                return _process_error(tool_error)\n            except TypeError as e:\n                # Check if this is a missing required argument error\n                error_msg = str(e)\n                if \"missing\" in error_msg and \"required\" in error_msg and \"argument\" in error_msg:\n                    # Add special message for output token limitation\n                    enhanced_error = TypeError(\n                        f\"{error_msg} - this is usually due to running out of output tokens \"\n                        f\"before finishing the message. Try making the function parameters shorter.\"\n                    )\n                    from bots.utils.helpers import _process_error\n\n                    return _process_error(enhanced_error)\n                else:\n                    from bots.utils.helpers import _process_error\n\n                    return _process_error(e)\n            except Exception as e:\n                from bots.utils.helpers import _process_error\n\n                return _process_error(e)\n\n        # Update docstring if description provided\n        if description:\n            wrapper.__doc__ = description\n        elif not wrapper.__doc__:\n            # Generate minimal docstring from function name\n            wrapper.__doc__ = f\"Execute {func.__name__.replace('_', ' ')}\"\n\n        return wrapper\n\n    return decorator\n\n@toolify()\ndef view(file_path: str, start_line: str=None, end_line: str=None, around_str_match: str=None, dist_from_match: str='10'):\n    \"\"\"\n    Display the contents of a file with line numbers.\n    Parameters:\n    - file_path (str): The path to the file to be viewed.\n    - start_line (int, optional): Starting line number (1-indexed). If None, starts from beginning.\n    - end_line (int, optional): Ending line number (1-indexed). If None, goes to end of file.\n    - around_str_match (str, optional): String to search for. If provided, shows lines around matches.\n    - dist_from_match (int, optional): Number of lines to show before and after each match. Defaults to 10.\n    Returns:\n    A string containing the file contents with line numbers,\n    filtered according to the specified parameters.\n    \"\"\"\n    encodings = ['utf-8', 'utf-16', 'utf-16le', 'ascii', 'cp1252', 'iso-8859-1']\n    start_line = int(start_line) if start_line is not None else None\n    end_line = int(end_line) if end_line is not None else None\n    dist_from_match = int(dist_from_match) if dist_from_match is not None else None\n    for encoding in encodings:\n        try:\n            with open(file_path, 'r', encoding=encoding) as file:\n                lines = file.readlines()\n            if around_str_match:\n                matching_line_numbers = []\n                for i, line in enumerate(lines):\n                    if around_str_match in line:\n                        matching_line_numbers.append(i)\n                if not matching_line_numbers:\n                    return f\"No matches found for '{around_str_match}'\"\n                line_ranges = set()\n                for match_line in matching_line_numbers:\n                    start = max(0, match_line - dist_from_match)\n                    end = min(len(lines), match_line + dist_from_match + 1)\n                    for line_num in range(start, end):\n                        line_ranges.add(line_num)\n                sorted_lines = sorted(line_ranges)\n                numbered_lines = []\n                prev_line = None\n                for line_num in sorted_lines:\n                    if prev_line is not None and line_num > prev_line + 1:\n                        numbered_lines.append('...')\n                    numbered_lines.append(f'{line_num + 1}:{lines[line_num].rstrip()}')\n                    prev_line = line_num\n                return '\\n'.join(numbered_lines)\n            else:\n                start_idx = start_line - 1 if start_line else 0\n                end_idx = end_line if end_line else len(lines)\n                start_idx = max(0, start_idx)\n                end_idx = min(len(lines), end_idx)\n                if start_idx >= len(lines):\n                    return f'Error: start_line ({start_line}) exceeds file length ({len(lines)} lines)'\n                selected_lines = lines[start_idx:end_idx]\n                numbered_lines = [f'{i + start_idx + 1}:{line.rstrip()}' for i, line in enumerate(selected_lines)]\n                return '\\n'.join(numbered_lines)\n        except UnicodeDecodeError:\n            continue\n    return f\"Error: Unable to read file with any of the attempted encodings: {', '.join(encodings)}\"",
    "file_path": "dynamic_module_-7047342923987625551",
    "code_hash": "2fb97b31a30dc98f0db31899a076f069",
    "globals": {
     "_convert_tool_inputs": {
      "__helper_func__": true,
      "pickled": "gASVMAAAAAAAAACME2JvdHMuZGV2LmRlY29yYXRvcnOUjBRfY29udmVydF90b29sX2lucHV0c5STlC4=",
      "name": "_convert_tool_inputs"
     },
     "_convert_tool_output": {
      "__helper_func__": true,
      "pickled": "gASVMAAAAAAAAACME2JvdHMuZGV2LmRlY29yYXRvcnOUjBRfY29udmVydF90b29sX291dHB1dJSTlC4=",
      "name": "_convert_tool_output"
     },
     "ast": {
      "__module_type__": true,
      "name": "ast",
      "spec": "ast"
     },
     "datetime": {
      "__module_type__": true,
      "name": "datetime",
      "spec": "datetime"
     },
     "functools": {
      "__module_type__": true,
      "name": "functools",
      "spec": "functools"
     },
     "inspect": {
      "__module_type__": true,
      "name": "inspect",
      "spec": "inspect"
     },
     "logging": {
      "__module_type__": true,
      "name": "logging",
      "spec": "logging"
     },
     "os": {
      "__module_type__": true,
      "name": "os",
      "spec": "os"
     },
     "sys": {
      "__module_type__": true,
      "name": "sys",
      "spec": "sys"
     },
     "textwrap": {
      "__module_type__": true,
      "name": "textwrap",
      "spec": "textwrap"
     },
     "traceback": {
      "__module_type__": true,
      "name": "traceback",
      "spec": "traceback"
     },
     "_get_context": {
      "__helper_func__": true,
      "pickled": "gASVKAAAAAAAAACME2JvdHMuZGV2LmRlY29yYXRvcnOUjAxfZ2V0X2NvbnRleHSUk5Qu",
      "name": "_get_context"
     },
     "_get_py_interface": {
      "__helper_func__": true,
      "pickled": "gASVLQAAAAAAAACME2JvdHMuZGV2LmRlY29yYXRvcnOUjBFfZ2V0X3B5X2ludGVyZmFjZZSTlC4=",
      "name": "_get_py_interface"
     },
     "_convert_string_to_type": {
      "__helper_func__": true,
      "pickled": "gASVMwAAAAAAAACME2JvdHMuZGV2LmRlY29yYXRvcnOUjBdfY29udmVydF9zdHJpbmdfdG9fdHlwZZSTlC4=",
      "name": "_convert_string_to_type"
     },
     "_log_error_to_file": {
      "__helper_func__": true,
      "pickled": "gASVLgAAAAAAAACME2JvdHMuZGV2LmRlY29yYXRvcnOUjBJfbG9nX2Vycm9yX3RvX2ZpbGWUk5Qu",
      "name": "_log_error_to_file"
     },
     "difflib": {
      "__module_type__": true,
      "name": "difflib",
      "spec": "difflib"
     },
     "_read_file_bom_safe": {
      "__helper_func__": true,
      "pickled": "gASVMQAAAAAAAACMFWJvdHMudG9vbHMuY29kZV90b29sc5SME19yZWFkX2ZpbGVfYm9tX3NhZmWUk5Qu",
      "name": "_read_file_bom_safe"
     },
     "_write_file_bom_safe": {
      "__helper_func__": true,
      "pickled": "gASVMgAAAAAAAACMFWJvdHMudG9vbHMuY29kZV90b29sc5SMFF93cml0ZV9maWxlX2JvbV9zYWZllJOULg==",
      "name": "_write_file_bom_safe"
     },
     "_remove_bom_from_content": {
      "__helper_func__": true,
      "pickled": "gASVNgAAAAAAAACMFWJvdHMudG9vbHMuY29kZV90b29sc5SMGF9yZW1vdmVfYm9tX2Zyb21fY29udGVudJSTlC4=",
      "name": "_remove_bom_from_content"
     },
     "_find_match_with_hierarchy": {
      "__helper_func__": true,
      "pickled": "gASVOAAAAAAAAACMFWJvdHMudG9vbHMuY29kZV90b29sc5SMGl9maW5kX21hdGNoX3dpdGhfaGllcmFyY2h5lJOULg==",
      "name": "_find_match_with_hierarchy"
     },
     "_check_exact_match_at_position": {
      "__helper_func__": true,
      "pickled": "gASVPAAAAAAAAACMFWJvdHMudG9vbHMuY29kZV90b29sc5SMHl9jaGVja19leGFjdF9tYXRjaF9hdF9wb3NpdGlvbpSTlC4=",
      "name": "_check_exact_match_at_position"
     },
     "_find_exact_match_anywhere": {
      "__helper_func__": true,
      "pickled": "gASVOAAAAAAAAACMFWJvdHMudG9vbHMuY29kZV90b29sc5SMGl9maW5kX2V4YWN0X21hdGNoX2FueXdoZXJllJOULg==",
      "name": "_find_exact_match_anywhere"
     },
     "_check_whitespace_match_at_position": {
      "__helper_func__": true,
      "pickled": "gASVQQAAAAAAAACMFWJvdHMudG9vbHMuY29kZV90b29sc5SMI19jaGVja193aGl0ZXNwYWNlX21hdGNoX2F0X3Bvc2l0aW9ulJOULg==",
      "name": "_check_whitespace_match_at_position"
     },
     "_find_whitespace_match_anywhere": {
      "__helper_func__": true,
      "pickled": "gASVPQAAAAAAAACMFWJvdHMudG9vbHMuY29kZV90b29sc5SMH19maW5kX3doaXRlc3BhY2VfbWF0Y2hfYW55d2hlcmWUk5Qu",
      "name": "_find_whitespace_match_anywhere"
     },
     "_adjust_additions_to_context": {
      "__helper_func__": true,
      "pickled": "gASVOgAAAAAAAACMFWJvdHMudG9vbHMuY29kZV90b29sc5SMHF9hZGp1c3RfYWRkaXRpb25zX3RvX2NvbnRleHSUk5Qu",
      "name": "_adjust_additions_to_context"
     },
     "_find_block_in_content": {
      "__helper_func__": true,
      "pickled": "gASVNAAAAAAAAACMFWJvdHMudG9vbHMuY29kZV90b29sc5SMFl9maW5kX2Jsb2NrX2luX2NvbnRlbnSUk5Qu",
      "name": "_find_block_in_content"
     },
     "_get_line_indentation": {
      "__helper_func__": true,
      "pickled": "gASVMwAAAAAAAACMFWJvdHMudG9vbHMuY29kZV90b29sc5SMFV9nZXRfbGluZV9pbmRlbnRhdGlvbpSTlC4=",
      "name": "_get_line_indentation"
     },
     "_normalize_path": {
      "__helper_func__": true,
      "pickled": "gASVLQAAAAAAAACMFWJvdHMudG9vbHMuY29kZV90b29sc5SMD19ub3JtYWxpemVfcGF0aJSTlC4=",
      "name": "_normalize_path"
     },
     "_normalize_header_lines": {
      "__helper_func__": true,
      "pickled": "gASVNQAAAAAAAACMFWJvdHMudG9vbHMuY29kZV90b29sc5SMF19ub3JtYWxpemVfaGVhZGVyX2xpbmVzlJOULg==",
      "name": "_normalize_header_lines"
     }
    }
   },
   "dynamic_module_4887809669875189212": {
    "name": "dynamic_module_-5632645250801145583",
    "source": "from bots.utils.helpers import _process_error\n\ndef toolify(description: str = None):\n    \"\"\"\n    Convert any function into a bot tool with string-in, string-out interface.\n\n    - Converts string inputs to proper types using type hints\n    - Ensures string output (JSON for complex types)\n    - Wraps in error handling (returns error strings, never raises)\n    - Enhances docstring if description provided\n\n    Args:\n        description (str, optional): Override the function's docstring\n\n    Example:\n        @toolify()\n        def add_numbers(x: int, y: int = 0) -> int:\n            return x + y\n\n        @toolify(\"Calculate the area of a circle\")\n        def area(radius: float) -> float:\n            return 3.14159 * radius * radius\n    \"\"\"\n\n    def decorator(func):\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            try:\n                # Convert string inputs to proper types using type hints\n                converted_args, converted_kwargs = _convert_tool_inputs(func, args, kwargs)\n\n                # Call original function\n                result = func(*converted_args, **converted_kwargs)\n\n                # Convert result to string\n                return _convert_tool_output(result)\n\n            except KeyboardInterrupt as e:\n                # Convert KeyboardInterrupt to ToolExecutionError to prevent it from\n                # bubbling up to CLI and being treated as user Ctrl+C\n                from bots.utils.helpers import _process_error\n\n                # ToolExecutionError is defined in this file\n                tool_error = ToolExecutionError(f\"Tool execution interrupted: {str(e)}\")\n                return _process_error(tool_error)\n            except TypeError as e:\n                # Check if this is a missing required argument error\n                error_msg = str(e)\n                if \"missing\" in error_msg and \"required\" in error_msg and \"argument\" in error_msg:\n                    # Add special message for output token limitation\n                    enhanced_error = TypeError(\n                        f\"{error_msg} - this is usually due to running out of output tokens \"\n                        f\"before finishing the message. Try making the function parameters shorter.\"\n                    )\n                    from bots.utils.helpers import _process_error\n\n                    return _process_error(enhanced_error)\n                else:\n                    from bots.utils.helpers import _process_error\n\n                    return _process_error(e)\n            except Exception as e:\n                from bots.utils.helpers import _process_error\n\n                return _process_error(e)\n\n        # Update docstring if description provided\n        if description:\n            wrapper.__doc__ = description\n        elif not wrapper.__doc__:\n            # Generate minimal docstring from function name\n            wrapper.__doc__ = f\"Execute {func.__name__.replace('_', ' ')}\"\n\n        return wrapper\n\n    return decorator\n\n@toolify()\ndef view_dir(start_path: str='.', output_file=None, target_extensions: str=\"['py', 'txt', 'md']\", max_lines: int=500):\n    \"\"\"\n    Creates a summary of the directory structure starting from the given path, writing only files\n    with specified extensions and showing venv directories without their contents.\n    Parameters:\n    - start_path (str): The root directory to start scanning from.\n    - output_file (str): The name of the file to optionally write the directory structure to.\n    - target_extensions (str): String representation of a list of file extensions (e.g. \"['py', 'txt']\").\n    - max_lines (int): Maximum number of lines in output. If exceeded, deepest levels are truncated. Default 500.\n    Returns:\n    str: A formatted string containing the directory structure, with each directory and file properly indented.\n    Example output:\n    my_project/\n        venv/\n        module1/\n            script.py\n            README.md\n        module2/\n            utils.py\n    cost: low\n    \"\"\"\n    if max_lines:\n        max_lines = int(max_lines)\n    extensions_list = [ext.strip().strip('\\'\"') for ext in target_extensions.strip('[]').split(',')]\n    extensions_list = ['.' + ext if not ext.startswith('.') else ext for ext in extensions_list]\n    dir_entries = []\n    max_level = 0\n    for root, dirs, files in os.walk(start_path):\n        level = root.replace(start_path, '').count(os.sep)\n        indent = '    ' * level\n        basename = os.path.basename(root)\n        is_venv = basename in ['venv', 'env', '.env'] or 'pyvenv.cfg' in files\n        if is_venv:\n            dir_entries.append((level, f'{indent}{basename}/'))\n            max_level = max(max_level, level)\n            dirs[:] = []\n            continue\n        has_relevant_files = False\n        for _, _, fs in os.walk(root):\n            if any((f.endswith(tuple(extensions_list)) for f in fs)):\n                has_relevant_files = True\n                break\n        if has_relevant_files:\n            dir_entries.append((level, f'{indent}{basename}/'))\n            max_level = max(max_level, level)\n            subindent = '    ' * (level + 1)\n            for file in files:\n                if file.endswith(tuple(extensions_list)):\n                    dir_entries.append((level + 1, f'{subindent}{file}'))\n                    max_level = max(max_level, level + 1)\n    current_level_limit = max_level\n    while current_level_limit >= 0:\n        filtered_entries = [(level, line) for level, line in dir_entries if level <= current_level_limit]\n        truncated_dirs = set()\n        for level, line in dir_entries:\n            if level > current_level_limit and level == current_level_limit + 1:\n                parent_level = level - 1\n                for parent_level_check, parent_line in filtered_entries:\n                    if parent_level_check == parent_level and parent_line.endswith('/'):\n                        truncated_dirs.add(parent_line)\n        final_entries = []\n        for level, line in filtered_entries:\n            final_entries.append(line)\n            if line in truncated_dirs:\n                truncation_indent = '    ' * (level + 1)\n                final_entries.append(f'{truncation_indent}...')\n        if len(final_entries) <= max_lines:\n            output_text = final_entries\n            break\n        current_level_limit -= 1\n    else:\n        output_text = [f'Project too large (>{max_lines} lines). Showing root level only:', f'{os.path.basename(start_path) or start_path}/', '    ...']\n    if output_file is not None:\n        with open(output_file, 'w') as file:\n            file.write('\\n'.join(output_text))\n    return '\\n'.join(output_text)",
    "file_path": "dynamic_module_4887809669875189212",
    "code_hash": "4bd787273c2262b6b402da88b977d48e",
    "globals": {
     "_convert_tool_inputs": {
      "__helper_func__": true,
      "pickled": "gASVMAAAAAAAAACME2JvdHMuZGV2LmRlY29yYXRvcnOUjBRfY29udmVydF90b29sX2lucHV0c5STlC4=",
      "name": "_convert_tool_inputs"
     },
     "_convert_tool_output": {
      "__helper_func__": true,
      "pickled": "gASVMAAAAAAAAACME2JvdHMuZGV2LmRlY29yYXRvcnOUjBRfY29udmVydF90b29sX291dHB1dJSTlC4=",
      "name": "_convert_tool_output"
     },
     "ast": {
      "__module_type__": true,
      "name": "ast",
      "spec": "ast"
     },
     "datetime": {
      "__module_type__": true,
      "name": "datetime",
      "spec": "datetime"
     },
     "functools": {
      "__module_type__": true,
      "name": "functools",
      "spec": "functools"
     },
     "inspect": {
      "__module_type__": true,
      "name": "inspect",
      "spec": "inspect"
     },
     "logging": {
      "__module_type__": true,
      "name": "logging",
      "spec": "logging"
     },
     "os": {
      "__module_type__": true,
      "name": "os",
      "spec": "os"
     },
     "sys": {
      "__module_type__": true,
      "name": "sys",
      "spec": "sys"
     },
     "textwrap": {
      "__module_type__": true,
      "name": "textwrap",
      "spec": "textwrap"
     },
     "traceback": {
      "__module_type__": true,
      "name": "traceback",
      "spec": "traceback"
     },
     "_get_context": {
      "__helper_func__": true,
      "pickled": "gASVKAAAAAAAAACME2JvdHMuZGV2LmRlY29yYXRvcnOUjAxfZ2V0X2NvbnRleHSUk5Qu",
      "name": "_get_context"
     },
     "_get_py_interface": {
      "__helper_func__": true,
      "pickled": "gASVLQAAAAAAAACME2JvdHMuZGV2LmRlY29yYXRvcnOUjBFfZ2V0X3B5X2ludGVyZmFjZZSTlC4=",
      "name": "_get_py_interface"
     },
     "_convert_string_to_type": {
      "__helper_func__": true,
      "pickled": "gASVMwAAAAAAAACME2JvdHMuZGV2LmRlY29yYXRvcnOUjBdfY29udmVydF9zdHJpbmdfdG9fdHlwZZSTlC4=",
      "name": "_convert_string_to_type"
     },
     "_log_error_to_file": {
      "__helper_func__": true,
      "pickled": "gASVLgAAAAAAAACME2JvdHMuZGV2LmRlY29yYXRvcnOUjBJfbG9nX2Vycm9yX3RvX2ZpbGWUk5Qu",
      "name": "_log_error_to_file"
     },
     "difflib": {
      "__module_type__": true,
      "name": "difflib",
      "spec": "difflib"
     },
     "_read_file_bom_safe": {
      "__helper_func__": true,
      "pickled": "gASVMQAAAAAAAACMFWJvdHMudG9vbHMuY29kZV90b29sc5SME19yZWFkX2ZpbGVfYm9tX3NhZmWUk5Qu",
      "name": "_read_file_bom_safe"
     },
     "_write_file_bom_safe": {
      "__helper_func__": true,
      "pickled": "gASVMgAAAAAAAACMFWJvdHMudG9vbHMuY29kZV90b29sc5SMFF93cml0ZV9maWxlX2JvbV9zYWZllJOULg==",
      "name": "_write_file_bom_safe"
     },
     "_remove_bom_from_content": {
      "__helper_func__": true,
      "pickled": "gASVNgAAAAAAAACMFWJvdHMudG9vbHMuY29kZV90b29sc5SMGF9yZW1vdmVfYm9tX2Zyb21fY29udGVudJSTlC4=",
      "name": "_remove_bom_from_content"
     },
     "_find_match_with_hierarchy": {
      "__helper_func__": true,
      "pickled": "gASVOAAAAAAAAACMFWJvdHMudG9vbHMuY29kZV90b29sc5SMGl9maW5kX21hdGNoX3dpdGhfaGllcmFyY2h5lJOULg==",
      "name": "_find_match_with_hierarchy"
     },
     "_check_exact_match_at_position": {
      "__helper_func__": true,
      "pickled": "gASVPAAAAAAAAACMFWJvdHMudG9vbHMuY29kZV90b29sc5SMHl9jaGVja19leGFjdF9tYXRjaF9hdF9wb3NpdGlvbpSTlC4=",
      "name": "_check_exact_match_at_position"
     },
     "_find_exact_match_anywhere": {
      "__helper_func__": true,
      "pickled": "gASVOAAAAAAAAACMFWJvdHMudG9vbHMuY29kZV90b29sc5SMGl9maW5kX2V4YWN0X21hdGNoX2FueXdoZXJllJOULg==",
      "name": "_find_exact_match_anywhere"
     },
     "_check_whitespace_match_at_position": {
      "__helper_func__": true,
      "pickled": "gASVQQAAAAAAAACMFWJvdHMudG9vbHMuY29kZV90b29sc5SMI19jaGVja193aGl0ZXNwYWNlX21hdGNoX2F0X3Bvc2l0aW9ulJOULg==",
      "name": "_check_whitespace_match_at_position"
     },
     "_find_whitespace_match_anywhere": {
      "__helper_func__": true,
      "pickled": "gASVPQAAAAAAAACMFWJvdHMudG9vbHMuY29kZV90b29sc5SMH19maW5kX3doaXRlc3BhY2VfbWF0Y2hfYW55d2hlcmWUk5Qu",
      "name": "_find_whitespace_match_anywhere"
     },
     "_adjust_additions_to_context": {
      "__helper_func__": true,
      "pickled": "gASVOgAAAAAAAACMFWJvdHMudG9vbHMuY29kZV90b29sc5SMHF9hZGp1c3RfYWRkaXRpb25zX3RvX2NvbnRleHSUk5Qu",
      "name": "_adjust_additions_to_context"
     },
     "_find_block_in_content": {
      "__helper_func__": true,
      "pickled": "gASVNAAAAAAAAACMFWJvdHMudG9vbHMuY29kZV90b29sc5SMFl9maW5kX2Jsb2NrX2luX2NvbnRlbnSUk5Qu",
      "name": "_find_block_in_content"
     },
     "_get_line_indentation": {
      "__helper_func__": true,
      "pickled": "gASVMwAAAAAAAACMFWJvdHMudG9vbHMuY29kZV90b29sc5SMFV9nZXRfbGluZV9pbmRlbnRhdGlvbpSTlC4=",
      "name": "_get_line_indentation"
     },
     "_normalize_path": {
      "__helper_func__": true,
      "pickled": "gASVLQAAAAAAAACMFWJvdHMudG9vbHMuY29kZV90b29sc5SMD19ub3JtYWxpemVfcGF0aJSTlC4=",
      "name": "_normalize_path"
     },
     "_normalize_header_lines": {
      "__helper_func__": true,
      "pickled": "gASVNQAAAAAAAACMFWJvdHMudG9vbHMuY29kZV90b29sc5SMF19ub3JtYWxpemVfaGVhZGVyX2xpbmVzlJOULg==",
      "name": "_normalize_header_lines"
     }
    }
   },
   "dynamic_module_-4563580932223110958": {
    "name": "dynamic_module_5799915576945322326",
    "source": "from bots.utils.helpers import _process_error\nfrom typing import Any, Callable\nfrom functools import wraps\n\ndef toolify(description: str = None):\n    \"\"\"\n    Convert any function into a bot tool with string-in, string-out interface.\n\n    - Converts string inputs to proper types using type hints\n    - Ensures string output (JSON for complex types)\n    - Wraps in error handling (returns error strings, never raises)\n    - Enhances docstring if description provided\n\n    Args:\n        description (str, optional): Override the function's docstring\n\n    Example:\n        @toolify()\n        def add_numbers(x: int, y: int = 0) -> int:\n            return x + y\n\n        @toolify(\"Calculate the area of a circle\")\n        def area(radius: float) -> float:\n            return 3.14159 * radius * radius\n    \"\"\"\n\n    def decorator(func):\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            try:\n                # Convert string inputs to proper types using type hints\n                converted_args, converted_kwargs = _convert_tool_inputs(func, args, kwargs)\n\n                # Call original function\n                result = func(*converted_args, **converted_kwargs)\n\n                # Convert result to string\n                return _convert_tool_output(result)\n\n            except KeyboardInterrupt as e:\n                # Convert KeyboardInterrupt to ToolExecutionError to prevent it from\n                # bubbling up to CLI and being treated as user Ctrl+C\n                from bots.utils.helpers import _process_error\n\n                # ToolExecutionError is defined in this file\n                tool_error = ToolExecutionError(f\"Tool execution interrupted: {str(e)}\")\n                return _process_error(tool_error)\n            except TypeError as e:\n                # Check if this is a missing required argument error\n                error_msg = str(e)\n                if \"missing\" in error_msg and \"required\" in error_msg and \"argument\" in error_msg:\n                    # Add special message for output token limitation\n                    enhanced_error = TypeError(\n                        f\"{error_msg} - this is usually due to running out of output tokens \"\n                        f\"before finishing the message. Try making the function parameters shorter.\"\n                    )\n                    from bots.utils.helpers import _process_error\n\n                    return _process_error(enhanced_error)\n                else:\n                    from bots.utils.helpers import _process_error\n\n                    return _process_error(e)\n            except Exception as e:\n                from bots.utils.helpers import _process_error\n\n                return _process_error(e)\n\n        # Update docstring if description provided\n        if description:\n            wrapper.__doc__ = description\n        elif not wrapper.__doc__:\n            # Generate minimal docstring from function name\n            wrapper.__doc__ = f\"Execute {func.__name__.replace('_', ' ')}\"\n\n        return wrapper\n\n    return decorator\n\ndef log_errors(func: Callable) -> Callable:\n    \"\"\"Decorator that logs errors to a file when a function raises an exception or returns an error message.\n\n    This decorator captures both exceptions and return values that contain \"Error\" in the first few words,\n    logging them to 'error_log.txt' in the same directory as this decorators file.\n\n    Parameters:\n        func (Callable): The function to wrap with error logging capabilities\n\n    Returns:\n        Callable: A wrapped version of the function that logs errors\n\n    Example:\n        @log_errors\n        def risky_function():\n            # Any exceptions or \"Error\" messages will be logged\n            return \"Error: Something went wrong\"\n    \"\"\"\n\n    @wraps(func)\n    def wrapper(*args: Any, **kwargs: Any) -> Any:\n        try:\n            result = func(*args, **kwargs)\n\n            # Check if result is a string that starts with \"Tool Failed:\" (the specific format from handle_errors)\n            if isinstance(result, str) and result.startswith(\"Tool Failed:\"):\n                _log_error_to_file(func.__name__, f\"Function returned error message: {result}\", args, kwargs)\n\n            return result\n\n        except Exception as e:\n            # Log the exception\n            error_msg = f\"Exception in {func.__name__}: {str(e)}\\nTraceback:\\n{traceback.format_exc()}\"\n            _log_error_to_file(func.__name__, error_msg, args, kwargs)\n            # Re-raise the exception\n            raise\n\n    return wrapper\n\n@log_errors\n@toolify()\ndef execute_powershell(command: str, output_length_limit: str='1000', timeout: str='60') -> str:\n    \"\"\"\n    Executes PowerShell commands in a stateful environment with automatic BOM removal\n\n    Use when you need to run PowerShell commands and capture their output. If\n    you have other tools available, you should use this as a fallback when the\n    other tools fail. Coerces to utf-8 (no BOM).\n\n    Potential use cases:\n    - git commands\n    - gh cli\n    - other cli (which you may need to install using this tool)\n\n    Parameters:\n    - command (str): PowerShell command to execute.\n    - output_length_limit (int, optional): Maximum number of lines in the output.\n      If set, output exceeding this limit will be truncated. Default 200.\n\n    Returns:\n        str: The complete output from the command execution\n    \"\"\"\n    manager = PowerShellManager.get_instance()\n    output = ''.join(manager.execute(command, int(output_length_limit), float(timeout)))\n    return output",
    "file_path": "dynamic_module_-4563580932223110958",
    "code_hash": "f03b364c08ed3483827d1bdc7a6fd674",
    "globals": {
     "_log_error_to_file": {
      "__helper_func__": true,
      "pickled": "gASVLgAAAAAAAACME2JvdHMuZGV2LmRlY29yYXRvcnOUjBJfbG9nX2Vycm9yX3RvX2ZpbGWUk5Qu",
      "name": "_log_error_to_file"
     },
     "traceback": {
      "__module_type__": true,
      "name": "traceback",
      "spec": "traceback"
     },
     "ast": {
      "__module_type__": true,
      "name": "ast",
      "spec": "ast"
     },
     "datetime": {
      "__module_type__": true,
      "name": "datetime",
      "spec": "datetime"
     },
     "functools": {
      "__module_type__": true,
      "name": "functools",
      "spec": "functools"
     },
     "inspect": {
      "__module_type__": true,
      "name": "inspect",
      "spec": "inspect"
     },
     "logging": {
      "__module_type__": true,
      "name": "logging",
      "spec": "logging"
     },
     "os": {
      "__module_type__": true,
      "name": "os",
      "spec": "os"
     },
     "sys": {
      "__module_type__": true,
      "name": "sys",
      "spec": "sys"
     },
     "textwrap": {
      "__module_type__": true,
      "name": "textwrap",
      "spec": "textwrap"
     },
     "_get_context": {
      "__helper_func__": true,
      "pickled": "gASVKAAAAAAAAACME2JvdHMuZGV2LmRlY29yYXRvcnOUjAxfZ2V0X2NvbnRleHSUk5Qu",
      "name": "_get_context"
     },
     "_get_py_interface": {
      "__helper_func__": true,
      "pickled": "gASVLQAAAAAAAACME2JvdHMuZGV2LmRlY29yYXRvcnOUjBFfZ2V0X3B5X2ludGVyZmFjZZSTlC4=",
      "name": "_get_py_interface"
     },
     "_convert_tool_inputs": {
      "__helper_func__": true,
      "pickled": "gASVMAAAAAAAAACME2JvdHMuZGV2LmRlY29yYXRvcnOUjBRfY29udmVydF90b29sX2lucHV0c5STlC4=",
      "name": "_convert_tool_inputs"
     },
     "_convert_string_to_type": {
      "__helper_func__": true,
      "pickled": "gASVMwAAAAAAAACME2JvdHMuZGV2LmRlY29yYXRvcnOUjBdfY29udmVydF9zdHJpbmdfdG9fdHlwZZSTlC4=",
      "name": "_convert_string_to_type"
     },
     "_convert_tool_output": {
      "__helper_func__": true,
      "pickled": "gASVMAAAAAAAAACME2JvdHMuZGV2LmRlY29yYXRvcnOUjBRfY29udmVydF90b29sX291dHB1dJSTlC4=",
      "name": "_convert_tool_output"
     },
     "codecs": {
      "__module_type__": true,
      "name": "codecs",
      "spec": "codecs"
     },
     "glob": {
      "__module_type__": true,
      "name": "glob",
      "spec": "glob"
     },
     "subprocess": {
      "__module_type__": true,
      "name": "subprocess",
      "spec": "subprocess"
     },
     "threading": {
      "__module_type__": true,
      "name": "threading",
      "spec": "threading"
     },
     "time": {
      "__module_type__": true,
      "name": "time",
      "spec": "time"
     },
     "_get_active_sessions": {
      "__helper_func__": true,
      "pickled": "gASVNgAAAAAAAACMGWJvdHMudG9vbHMudGVybWluYWxfdG9vbHOUjBRfZ2V0X2FjdGl2ZV9zZXNzaW9uc5STlC4=",
      "name": "_get_active_sessions"
     },
     "_process_commands": {
      "__helper_func__": true,
      "pickled": "gASVMwAAAAAAAACMGWJvdHMudG9vbHMudGVybWluYWxfdG9vbHOUjBFfcHJvY2Vzc19jb21tYW5kc5STlC4=",
      "name": "_process_commands"
     },
     "_remove_bom_from_current_directory": {
      "__helper_func__": true,
      "pickled": "gASVRAAAAAAAAACMGWJvdHMudG9vbHMudGVybWluYWxfdG9vbHOUjCJfcmVtb3ZlX2JvbV9mcm9tX2N1cnJlbnRfZGlyZWN0b3J5lJOULg==",
      "name": "_remove_bom_from_current_directory"
     }
    }
   },
   "dynamic_module_3952325291086529150": {
    "name": "dynamic_module_8056094869481904228",
    "source": "from bots.utils.helpers import _process_error\n\ndef toolify(description: str = None):\n    \"\"\"\n    Convert any function into a bot tool with string-in, string-out interface.\n\n    - Converts string inputs to proper types using type hints\n    - Ensures string output (JSON for complex types)\n    - Wraps in error handling (returns error strings, never raises)\n    - Enhances docstring if description provided\n\n    Args:\n        description (str, optional): Override the function's docstring\n\n    Example:\n        @toolify()\n        def add_numbers(x: int, y: int = 0) -> int:\n            return x + y\n\n        @toolify(\"Calculate the area of a circle\")\n        def area(radius: float) -> float:\n            return 3.14159 * radius * radius\n    \"\"\"\n\n    def decorator(func):\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            try:\n                # Convert string inputs to proper types using type hints\n                converted_args, converted_kwargs = _convert_tool_inputs(func, args, kwargs)\n\n                # Call original function\n                result = func(*converted_args, **converted_kwargs)\n\n                # Convert result to string\n                return _convert_tool_output(result)\n\n            except KeyboardInterrupt as e:\n                # Convert KeyboardInterrupt to ToolExecutionError to prevent it from\n                # bubbling up to CLI and being treated as user Ctrl+C\n                from bots.utils.helpers import _process_error\n\n                # ToolExecutionError is defined in this file\n                tool_error = ToolExecutionError(f\"Tool execution interrupted: {str(e)}\")\n                return _process_error(tool_error)\n            except TypeError as e:\n                # Check if this is a missing required argument error\n                error_msg = str(e)\n                if \"missing\" in error_msg and \"required\" in error_msg and \"argument\" in error_msg:\n                    # Add special message for output token limitation\n                    enhanced_error = TypeError(\n                        f\"{error_msg} - this is usually due to running out of output tokens \"\n                        f\"before finishing the message. Try making the function parameters shorter.\"\n                    )\n                    from bots.utils.helpers import _process_error\n\n                    return _process_error(enhanced_error)\n                else:\n                    from bots.utils.helpers import _process_error\n\n                    return _process_error(e)\n            except Exception as e:\n                from bots.utils.helpers import _process_error\n\n                return _process_error(e)\n\n        # Update docstring if description provided\n        if description:\n            wrapper.__doc__ = description\n        elif not wrapper.__doc__:\n            # Generate minimal docstring from function name\n            wrapper.__doc__ = f\"Execute {func.__name__.replace('_', ' ')}\"\n\n        return wrapper\n\n    return decorator\n\n@toolify()\ndef execute_python(code: str, timeout: int=300) -> str:\n    \"\"\"\n    Executes python code in a stateless environment with cross-platform\n    timeout handling.\n    Parameters:\n    - code (str): Syntactically correct python code\n    - timeout (int): Maximum execution time in seconds (default: 300)\n    Returns stdout or an error message.\n    cost: varies\n    \"\"\"\n\n    def create_wrapper_ast():\n        wrapper_code = textwrap.dedent('\\n            import os\\n            import sys\\n            import traceback\\n            import time\\n            sys.path.append(os.path.dirname(os.path.dirname(\\n                os.path.abspath(__file__))))\\n            if sys.platform == \\'win32\\':\\n                import codecs\\n                sys.stdout = codecs.getwriter(\\'utf-8\\')(\\n                    sys.stdout.buffer, \\'strict\\')\\n                sys.stderr = codecs.getwriter(\\'utf-8\\')(\\n                    sys.stderr.buffer, \\'strict\\')\\n            def main():\\n                pass  # Placeholder for user code\\n            if __name__ == \\'__main__\\':\\n                try:\\n                    main()\\n                except Exception as error:\\n                    print(f\"An error occurred: {str(error)}\", file=sys.stderr)\\n                    traceback.print_exc(file=sys.stderr)\\n                    sys.exit(1)\\n            ')\n        return ast.parse(wrapper_code)\n\n    def insert_code_into_wrapper(wrapper_ast, code_ast, timeout_value):\n\n        def is_main_func(node):\n            return isinstance(node, ast.FunctionDef) and node.name == 'main'\n        nodes = wrapper_ast.body\n        main_func = next((node for node in nodes if is_main_func(node)))\n        main_func.body = code_ast.body\n        return wrapper_ast\n    if not isinstance(timeout, int) or timeout <= 0:\n        raise ValueError('Timeout must be a positive integer')\n    clean_code = textwrap.dedent(code).strip()\n    code_ast = ast.parse(clean_code)\n    wrapper_ast = create_wrapper_ast()\n    combined_ast = insert_code_into_wrapper(wrapper_ast, code_ast, timeout)\n    final_code = _py_ast_to_source(combined_ast)\n    temp_file_name = os.path.join(tempfile.gettempdir(), _get_unique_filename('temp_script', 'py'))\n    with open(temp_file_name, 'w', encoding='utf-8') as temp_file:\n        temp_file.write(final_code)\n        temp_file.flush()\n        os.fsync(temp_file.fileno())\n    env = os.environ.copy()\n    env['PYTHONIOENCODING'] = 'utf-8'\n    process = subprocess.Popen(['python', temp_file_name], stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True, encoding='utf-8', creationflags=subprocess.CREATE_NO_WINDOW if os.name == 'nt' else 0, env=env)\n    stdout, stderr = process.communicate(timeout=timeout)\n    if os.path.exists(temp_file_name):\n        os.remove(temp_file_name)\n    if process.returncode != 0:\n        return stderr or 'Process failed with no error message'\n    return stdout + stderr\n\ndef _get_unique_filename(base_name, extension=''):\n    \"\"\"Generate a unique filename using process ID and timestamp.\"\"\"\n    timestamp = int(time.time() * 1000)\n    pid = os.getpid()\n    if extension and (not extension.startswith('.')):\n        extension = '.' + extension\n    return f'{base_name}_{pid}_{timestamp}{extension}'",
    "file_path": "dynamic_module_3952325291086529150",
    "code_hash": "231d12d19fc69d89610fb9acef60257e",
    "globals": {
     "_convert_tool_inputs": {
      "__helper_func__": true,
      "pickled": "gASVMAAAAAAAAACME2JvdHMuZGV2LmRlY29yYXRvcnOUjBRfY29udmVydF90b29sX2lucHV0c5STlC4=",
      "name": "_convert_tool_inputs"
     },
     "_convert_tool_output": {
      "__helper_func__": true,
      "pickled": "gASVMAAAAAAAAACME2JvdHMuZGV2LmRlY29yYXRvcnOUjBRfY29udmVydF90b29sX291dHB1dJSTlC4=",
      "name": "_convert_tool_output"
     },
     "ast": {
      "__module_type__": true,
      "name": "ast",
      "spec": "ast"
     },
     "datetime": {
      "__module_type__": true,
      "name": "datetime",
      "spec": "datetime"
     },
     "functools": {
      "__module_type__": true,
      "name": "functools",
      "spec": "functools"
     },
     "inspect": {
      "__module_type__": true,
      "name": "inspect",
      "spec": "inspect"
     },
     "logging": {
      "__module_type__": true,
      "name": "logging",
      "spec": "logging"
     },
     "os": {
      "__module_type__": true,
      "name": "os",
      "spec": "os"
     },
     "sys": {
      "__module_type__": true,
      "name": "sys",
      "spec": "sys"
     },
     "textwrap": {
      "__module_type__": true,
      "name": "textwrap",
      "spec": "textwrap"
     },
     "traceback": {
      "__module_type__": true,
      "name": "traceback",
      "spec": "traceback"
     },
     "_get_context": {
      "__helper_func__": true,
      "pickled": "gASVKAAAAAAAAACME2JvdHMuZGV2LmRlY29yYXRvcnOUjAxfZ2V0X2NvbnRleHSUk5Qu",
      "name": "_get_context"
     },
     "_get_py_interface": {
      "__helper_func__": true,
      "pickled": "gASVLQAAAAAAAACME2JvdHMuZGV2LmRlY29yYXRvcnOUjBFfZ2V0X3B5X2ludGVyZmFjZZSTlC4=",
      "name": "_get_py_interface"
     },
     "_convert_string_to_type": {
      "__helper_func__": true,
      "pickled": "gASVMwAAAAAAAACME2JvdHMuZGV2LmRlY29yYXRvcnOUjBdfY29udmVydF9zdHJpbmdfdG9fdHlwZZSTlC4=",
      "name": "_convert_string_to_type"
     },
     "_log_error_to_file": {
      "__helper_func__": true,
      "pickled": "gASVLgAAAAAAAACME2JvdHMuZGV2LmRlY29yYXRvcnOUjBJfbG9nX2Vycm9yX3RvX2ZpbGWUk5Qu",
      "name": "_log_error_to_file"
     },
     "subprocess": {
      "__module_type__": true,
      "name": "subprocess",
      "spec": "subprocess"
     },
     "tempfile": {
      "__module_type__": true,
      "name": "tempfile",
      "spec": "tempfile"
     },
     "time": {
      "__module_type__": true,
      "name": "time",
      "spec": "time"
     },
     "_py_ast_to_source": {
      "__helper_func__": true,
      "pickled": "gASVLAAAAAAAAACMEmJvdHMudXRpbHMuaGVscGVyc5SMEV9weV9hc3RfdG9fc291cmNllJOULg==",
      "name": "_py_ast_to_source"
     }
    }
   },
   "dynamic_module_-951869828414421806": {
    "name": "dynamic_module_-5080140807950334524",
    "source": "import os\nfrom concurrent.futures import ThreadPoolExecutor, as_completed\nfrom bots.flows import functional_prompts as fp\nfrom bots.foundation.base import Bot\nimport traceback\nfrom bots.flows.recombinators import recombinators as recomb\nfrom bots.utils.helpers import _process_error\nfrom typing import List, Optional\n\ndef toolify(description: str = None):\n    \"\"\"\n    Convert any function into a bot tool with string-in, string-out interface.\n\n    - Converts string inputs to proper types using type hints\n    - Ensures string output (JSON for complex types)\n    - Wraps in error handling (returns error strings, never raises)\n    - Enhances docstring if description provided\n\n    Args:\n        description (str, optional): Override the function's docstring\n\n    Example:\n        @toolify()\n        def add_numbers(x: int, y: int = 0) -> int:\n            return x + y\n\n        @toolify(\"Calculate the area of a circle\")\n        def area(radius: float) -> float:\n            return 3.14159 * radius * radius\n    \"\"\"\n\n    def decorator(func):\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            try:\n                # Convert string inputs to proper types using type hints\n                converted_args, converted_kwargs = _convert_tool_inputs(func, args, kwargs)\n\n                # Call original function\n                result = func(*converted_args, **converted_kwargs)\n\n                # Convert result to string\n                return _convert_tool_output(result)\n\n            except KeyboardInterrupt as e:\n                # Convert KeyboardInterrupt to ToolExecutionError to prevent it from\n                # bubbling up to CLI and being treated as user Ctrl+C\n                from bots.utils.helpers import _process_error\n\n                # ToolExecutionError is defined in this file\n                tool_error = ToolExecutionError(f\"Tool execution interrupted: {str(e)}\")\n                return _process_error(tool_error)\n            except TypeError as e:\n                # Check if this is a missing required argument error\n                error_msg = str(e)\n                if \"missing\" in error_msg and \"required\" in error_msg and \"argument\" in error_msg:\n                    # Add special message for output token limitation\n                    enhanced_error = TypeError(\n                        f\"{error_msg} - this is usually due to running out of output tokens \"\n                        f\"before finishing the message. Try making the function parameters shorter.\"\n                    )\n                    from bots.utils.helpers import _process_error\n\n                    return _process_error(enhanced_error)\n                else:\n                    from bots.utils.helpers import _process_error\n\n                    return _process_error(e)\n            except Exception as e:\n                from bots.utils.helpers import _process_error\n\n                return _process_error(e)\n\n        # Update docstring if description provided\n        if description:\n            wrapper.__doc__ = description\n        elif not wrapper.__doc__:\n            # Generate minimal docstring from function name\n            wrapper.__doc__ = f\"Execute {func.__name__.replace('_', ' ')}\"\n\n        return wrapper\n\n    return decorator\n\n@toolify()\ndef branch_self(self_prompts: str, allow_work: str='False', parallel: str='False', recombine: str='concatenate') -> str:\n    \"\"\"Create multiple conversation branches to explore different approaches or tackle separate tasks.\n\n    Following the idealized design from branch_self.md with minimal complexity:\n    1. Add dummy tool result immediately for API compliance and recursion prevention\n    2. Use existing sync mechanism to update results across branches\n\n    Args:\n        self_prompts (str): List of prompts as a string array, like ['task 1', 'task 2', 'task 3']\n                           Each prompt becomes a separate conversation branch\n        allow_work (str): 'True' to let each branch use tools and continue working until done\n                         'False' (default) for single-response branches\n        parallel (str): 'True' to let branches work in parallel, 'False' for sequential (default).\n        recombine (str): One of ('none', 'concatenate', 'llm_merge', 'llm_vote', 'llm_judge'), default 'concatenate'.\n                         Combines the final messages from each branch using that method.\n\n    Returns:\n        str: Success message with branch count, or error details if something went wrong\n    \"\"\"\n    import os\n    from concurrent.futures import ThreadPoolExecutor, as_completed\n    from bots.flows import functional_prompts as fp\n    from bots.foundation.base import Bot\n    bot = _get_calling_bot()\n    if not bot:\n        return 'Error: Could not find calling bot'\n    allow_work = allow_work.lower() == 'true'\n    parallel = parallel.lower() == 'true'\n    recombine = recombine.lower()\n    valid_recombine_options = ['none', 'concatenate', 'llm_judge', 'llm_vote', 'llm_merge']\n    if recombine not in valid_recombine_options:\n        return f'Error: Invalid recombine option. Valid: {valid_recombine_options}'\n    try:\n        message_list = _process_string_array(self_prompts)\n        if not message_list:\n            return 'Error: No valid messages provided'\n    except Exception as e:\n        return f'Error parsing prompts: {str(e)}'\n    prefixed_prompts = [f'(self-prompt): {prompt}' for prompt in message_list]\n    try:\n        original_node = bot.conversation\n        tool_call_id = None\n        if original_node.tool_calls:\n            for tc in original_node.tool_calls:\n                if tc.get('name') == 'branch_self':\n                    tool_call_id = tc['id']\n                    break\n        if not tool_call_id:\n            return 'Error: Could not find branch_self tool call'\n        dummy_content = 'Branching in progress...'\n        dummy_result = {'tool_use_id': tool_call_id, 'content': dummy_content}\n        if not hasattr(bot.tool_handler, 'results'):\n            bot.tool_handler.results = []\n        bot.tool_handler.results.append(dummy_result)\n        original_autosave = bot.autosave\n        bot.autosave = False\n        temp_id = str(uuid.uuid4())[:8]\n        temp_file = f'branch_self_{temp_id}.bot'\n        bot.save(temp_file)\n\n        def execute_branch(prompt, parent_bot_node):\n            \"\"\"Execute a single branch with the given prompt.\"\"\"\n            try:\n                branch_bot = Bot.load(temp_file)\n                branch_bot.autosave = False\n                branching_node = branch_bot.conversation\n                if allow_work:\n                    response = branch_bot.respond(prompt)\n                    while not fp.conditions.tool_not_used(branch_bot):\n                        response = branch_bot.respond('ok')\n                else:\n                    response = branch_bot.respond(prompt)\n                parent_bot_node.replies.extend(branching_node.replies)\n                for node in branching_node.replies:\n                    node.parent = parent_bot_node\n                return (response, branch_bot.conversation)\n            except Exception:\n                import traceback\n                traceback.print_exc()\n                return (None, None)\n        responses = []\n        branch_nodes = []\n        if parallel:\n            with ThreadPoolExecutor() as executor:\n                futures = [executor.submit(execute_branch, prompt, original_node) for prompt in prefixed_prompts]\n                for future in as_completed(futures):\n                    response, node = future.result()\n                    responses.append(response)\n                    branch_nodes.append(node)\n        else:\n            for prompt in prefixed_prompts:\n                response, node = execute_branch(prompt, original_node)\n                responses.append(response)\n                branch_nodes.append(node)\n        bot.autosave = original_autosave\n        try:\n            os.remove(temp_file)\n        except OSError:\n            pass\n        success_count = sum((1 for r in responses if r is not None))\n        combined = 'No recombinator selected'\n        if recombine != 'none' and responses:\n            valid_responses = [r for r in responses if r is not None]\n            if valid_responses:\n                from bots.flows.recombinators import recombinators as recomb\n                if recombine == 'concatenate':\n                    combined, _ = recomb.concatenate(valid_responses, [])\n                elif recombine == 'llm_judge':\n                    combined, _ = recomb.llm_judge(valid_responses, [], judge_bot=bot)\n                elif recombine == 'llm_vote':\n                    combined, _ = recomb.llm_vote(valid_responses, [], vote_bot=bot)\n                elif recombine == 'llm_merge':\n                    combined, _ = recomb.llm_merge(valid_responses, [], merge_bot=bot)\n                else:\n                    combined = 'Unknown recombination method'\n        exec_type = 'parallel' if parallel else 'sequential'\n        work_type = 'iterative' if allow_work else 'single-response'\n        result_content = f'Successfully completed {success_count}/{len(message_list)} {exec_type} {work_type} branches. Recombination result:\\n\\n{combined}'\n        return result_content\n    except Exception as e:\n        import traceback\n        traceback.print_exc()\n        return f'Error in branch_self: {str(e)}'\n\ndef _process_string_array(input_str: str) -> List[str]:\n    \"\"\"Parse a string representation of an array into a list of strings.\n    Only works with properly formatted Python list literals.\n    Args:\n        input_str (str): String representation of a Python list literal\n    Returns:\n        List[str]: List of parsed strings\n    Raises:\n        ValueError: If the input is not a valid Python list literal\n    \"\"\"\n    result = ast.literal_eval(input_str)\n    if not isinstance(result, list) or not all((isinstance(x, str) for x in result)):\n        raise ValueError('Input must evaluate to a list of strings')\n    return result\n\ndef _get_calling_bot() -> Optional[Bot]:\n    \"\"\"Helper function to get a reference to the calling bot.\n    Returns:\n        Optional[Bot]: Reference to the calling bot or None if not found\n    \"\"\"\n    frame = inspect.currentframe()\n    while frame:\n        if frame.f_code.co_name == '_cvsn_respond' and 'self' in frame.f_locals:\n            potential_bot = frame.f_locals['self']\n            if isinstance(potential_bot, Bot):\n                return potential_bot\n        frame = frame.f_back\n    return None",
    "file_path": "dynamic_module_-951869828414421806",
    "code_hash": "e2d5648eeac65061d2dec6a8d456835f",
    "globals": {
     "_convert_tool_inputs": {
      "__helper_func__": true,
      "pickled": "gASVMAAAAAAAAACME2JvdHMuZGV2LmRlY29yYXRvcnOUjBRfY29udmVydF90b29sX2lucHV0c5STlC4=",
      "name": "_convert_tool_inputs"
     },
     "_convert_tool_output": {
      "__helper_func__": true,
      "pickled": "gASVMAAAAAAAAACME2JvdHMuZGV2LmRlY29yYXRvcnOUjBRfY29udmVydF90b29sX291dHB1dJSTlC4=",
      "name": "_convert_tool_output"
     },
     "ast": {
      "__module_type__": true,
      "name": "ast",
      "spec": "ast"
     },
     "datetime": {
      "__module_type__": true,
      "name": "datetime",
      "spec": "datetime"
     },
     "functools": {
      "__module_type__": true,
      "name": "functools",
      "spec": "functools"
     },
     "inspect": {
      "__module_type__": true,
      "name": "inspect",
      "spec": "inspect"
     },
     "logging": {
      "__module_type__": true,
      "name": "logging",
      "spec": "logging"
     },
     "os": {
      "__module_type__": true,
      "name": "os",
      "spec": "os"
     },
     "sys": {
      "__module_type__": true,
      "name": "sys",
      "spec": "sys"
     },
     "textwrap": {
      "__module_type__": true,
      "name": "textwrap",
      "spec": "textwrap"
     },
     "traceback": {
      "__module_type__": true,
      "name": "traceback",
      "spec": "traceback"
     },
     "_get_context": {
      "__helper_func__": true,
      "pickled": "gASVKAAAAAAAAACME2JvdHMuZGV2LmRlY29yYXRvcnOUjAxfZ2V0X2NvbnRleHSUk5Qu",
      "name": "_get_context"
     },
     "_get_py_interface": {
      "__helper_func__": true,
      "pickled": "gASVLQAAAAAAAACME2JvdHMuZGV2LmRlY29yYXRvcnOUjBFfZ2V0X3B5X2ludGVyZmFjZZSTlC4=",
      "name": "_get_py_interface"
     },
     "_convert_string_to_type": {
      "__helper_func__": true,
      "pickled": "gASVMwAAAAAAAACME2JvdHMuZGV2LmRlY29yYXRvcnOUjBdfY29udmVydF9zdHJpbmdfdG9fdHlwZZSTlC4=",
      "name": "_convert_string_to_type"
     },
     "_log_error_to_file": {
      "__helper_func__": true,
      "pickled": "gASVLgAAAAAAAACME2JvdHMuZGV2LmRlY29yYXRvcnOUjBJfbG9nX2Vycm9yX3RvX2ZpbGWUk5Qu",
      "name": "_log_error_to_file"
     },
     "json": {
      "__module_type__": true,
      "name": "json",
      "spec": "json"
     },
     "uuid": {
      "__module_type__": true,
      "name": "uuid",
      "spec": "uuid"
     },
     "_modify_own_settings": {
      "__helper_func__": true,
      "pickled": "gASVMgAAAAAAAACMFWJvdHMudG9vbHMuc2VsZl90b29sc5SMFF9tb2RpZnlfb3duX3NldHRpbmdzlJOULg==",
      "name": "_modify_own_settings"
     },
     "_verbose_callback": {
      "__helper_func__": true,
      "pickled": "gASVLwAAAAAAAACMFWJvdHMudG9vbHMuc2VsZl90b29sc5SMEV92ZXJib3NlX2NhbGxiYWNrlJOULg==",
      "name": "_verbose_callback"
     },
     "_remove_dummy_from_tree": {
      "__helper_func__": true,
      "pickled": "gASVNQAAAAAAAACMFWJvdHMudG9vbHMuc2VsZl90b29sc5SMF19yZW1vdmVfZHVtbXlfZnJvbV90cmVllJOULg==",
      "name": "_remove_dummy_from_tree"
     }
    }
   },
   "dynamic_module_8547092287490962196": {
    "name": "dynamic_module_2596252440300776733",
    "source": "from bots.utils.helpers import _process_error\n\ndef toolify(description: str = None):\n    \"\"\"\n    Convert any function into a bot tool with string-in, string-out interface.\n\n    - Converts string inputs to proper types using type hints\n    - Ensures string output (JSON for complex types)\n    - Wraps in error handling (returns error strings, never raises)\n    - Enhances docstring if description provided\n\n    Args:\n        description (str, optional): Override the function's docstring\n\n    Example:\n        @toolify()\n        def add_numbers(x: int, y: int = 0) -> int:\n            return x + y\n\n        @toolify(\"Calculate the area of a circle\")\n        def area(radius: float) -> float:\n            return 3.14159 * radius * radius\n    \"\"\"\n\n    def decorator(func):\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            try:\n                # Convert string inputs to proper types using type hints\n                converted_args, converted_kwargs = _convert_tool_inputs(func, args, kwargs)\n\n                # Call original function\n                result = func(*converted_args, **converted_kwargs)\n\n                # Convert result to string\n                return _convert_tool_output(result)\n\n            except KeyboardInterrupt as e:\n                # Convert KeyboardInterrupt to ToolExecutionError to prevent it from\n                # bubbling up to CLI and being treated as user Ctrl+C\n                from bots.utils.helpers import _process_error\n\n                # ToolExecutionError is defined in this file\n                tool_error = ToolExecutionError(f\"Tool execution interrupted: {str(e)}\")\n                return _process_error(tool_error)\n            except TypeError as e:\n                # Check if this is a missing required argument error\n                error_msg = str(e)\n                if \"missing\" in error_msg and \"required\" in error_msg and \"argument\" in error_msg:\n                    # Add special message for output token limitation\n                    enhanced_error = TypeError(\n                        f\"{error_msg} - this is usually due to running out of output tokens \"\n                        f\"before finishing the message. Try making the function parameters shorter.\"\n                    )\n                    from bots.utils.helpers import _process_error\n\n                    return _process_error(enhanced_error)\n                else:\n                    from bots.utils.helpers import _process_error\n\n                    return _process_error(e)\n            except Exception as e:\n                from bots.utils.helpers import _process_error\n\n                return _process_error(e)\n\n        # Update docstring if description provided\n        if description:\n            wrapper.__doc__ = description\n        elif not wrapper.__doc__:\n            # Generate minimal docstring from function name\n            wrapper.__doc__ = f\"Execute {func.__name__.replace('_', ' ')}\"\n\n        return wrapper\n\n    return decorator\n\n@toolify(\"Perform an agentic web search using Claude's internal web search capabilities\")\ndef web_search(question: str) -> str:\n    \"\"\"Perform an intelligent web search and return raw API results.\n\n    This tool uses Claude's built-in web search functionality to perform searches\n    and returns the complete raw API response, including all search results,\n    metadata, and processing information.\n\n    Args:\n        question (str): The search goal framed as a question.\n        Good examples:\n            \"Who is Ben Rinauto?\"\n            \"What is the connection between Paris, France and Buffalo, NY?\"\n        Bad examples:\n            \"Ben R wrestling\"\n            \"paris buffalo\"\n\n    Returns:\n        str: Raw API response from the web search as a string\n    \"\"\"\n    try:\n        api_key = os.getenv('ANTHROPIC_API_KEY')\n        if not api_key:\n            return 'Error: ANTHROPIC_API_KEY environment variable not set'\n        client = anthropic.Anthropic(api_key=api_key)\n        tools = [{'type': 'web_search_20250305', 'name': 'web_search', 'max_uses': 10}]\n        search_prompt = f'I need you to search the web answers to this question: \"{question}\"\\n\\n        Please use the web search tool to find current, relevant information to precisely and\\n        accurately answer this question.'\n        response = client.messages.create(model='claude-opus-4-1', max_tokens=16384, temperature=0.3, tools=tools, messages=[{'role': 'user', 'content': search_prompt}])\n        raw_response_str = str(response)\n        return f'Raw API Response:\\n{raw_response_str}'\n    except Exception as e:\n        return f'Web search failed: {str(e)}'",
    "file_path": "dynamic_module_8547092287490962196",
    "code_hash": "1734cd0086b45960b334015d5a349ba6",
    "globals": {
     "_convert_tool_inputs": {
      "__helper_func__": true,
      "pickled": "gASVMAAAAAAAAACME2JvdHMuZGV2LmRlY29yYXRvcnOUjBRfY29udmVydF90b29sX2lucHV0c5STlC4=",
      "name": "_convert_tool_inputs"
     },
     "_convert_tool_output": {
      "__helper_func__": true,
      "pickled": "gASVMAAAAAAAAACME2JvdHMuZGV2LmRlY29yYXRvcnOUjBRfY29udmVydF90b29sX291dHB1dJSTlC4=",
      "name": "_convert_tool_output"
     },
     "ast": {
      "__module_type__": true,
      "name": "ast",
      "spec": "ast"
     },
     "datetime": {
      "__module_type__": true,
      "name": "datetime",
      "spec": "datetime"
     },
     "functools": {
      "__module_type__": true,
      "name": "functools",
      "spec": "functools"
     },
     "inspect": {
      "__module_type__": true,
      "name": "inspect",
      "spec": "inspect"
     },
     "logging": {
      "__module_type__": true,
      "name": "logging",
      "spec": "logging"
     },
     "os": {
      "__module_type__": true,
      "name": "os",
      "spec": "os"
     },
     "sys": {
      "__module_type__": true,
      "name": "sys",
      "spec": "sys"
     },
     "textwrap": {
      "__module_type__": true,
      "name": "textwrap",
      "spec": "textwrap"
     },
     "traceback": {
      "__module_type__": true,
      "name": "traceback",
      "spec": "traceback"
     },
     "_get_context": {
      "__helper_func__": true,
      "pickled": "gASVKAAAAAAAAACME2JvdHMuZGV2LmRlY29yYXRvcnOUjAxfZ2V0X2NvbnRleHSUk5Qu",
      "name": "_get_context"
     },
     "_get_py_interface": {
      "__helper_func__": true,
      "pickled": "gASVLQAAAAAAAACME2JvdHMuZGV2LmRlY29yYXRvcnOUjBFfZ2V0X3B5X2ludGVyZmFjZZSTlC4=",
      "name": "_get_py_interface"
     },
     "_convert_string_to_type": {
      "__helper_func__": true,
      "pickled": "gASVMwAAAAAAAACME2JvdHMuZGV2LmRlY29yYXRvcnOUjBdfY29udmVydF9zdHJpbmdfdG9fdHlwZZSTlC4=",
      "name": "_convert_string_to_type"
     },
     "_log_error_to_file": {
      "__helper_func__": true,
      "pickled": "gASVLgAAAAAAAACME2JvdHMuZGV2LmRlY29yYXRvcnOUjBJfbG9nX2Vycm9yX3RvX2ZpbGWUk5Qu",
      "name": "_log_error_to_file"
     },
     "anthropic": {
      "__module_type__": true,
      "name": "anthropic",
      "spec": "anthropic"
     }
    }
   }
  },
  "function_paths": {
   "view": "dynamic_module_-7047342923987625551",
   "view_dir": "dynamic_module_4887809669875189212",
   "execute_powershell": "dynamic_module_-4563580932223110958",
   "execute_python": "dynamic_module_3952325291086529150",
   "branch_self": "dynamic_module_-951869828414421806",
   "web_search": "dynamic_module_8547092287490962196"
  }
 },
 "autosave": false,
 "bot_class": "AnthropicBot"
}